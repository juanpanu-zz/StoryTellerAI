{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "storyTellerAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanpanu/StoryTellerAI/blob/main/storyTellerAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbs4k0MJifjA",
        "outputId": "4a3a1930-3cf8-4691-a7ab-2db46a6cd507",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#read-PDF imports here\n",
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "\n",
        "#pre-processing imports here\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 29.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 18.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 19.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 7.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-cp36-none-any.whl size=61086 sha256=885fd41733627bf0979bad091adb1ea48f3af222a32006674339744e94cd7d44\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBKuc_dR-Fgt",
        "outputId": "d9395e0d-ef54-4686-c010-94fbd201f4dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhwcUudNChx8"
      },
      "source": [
        "#file locations on drive\n",
        "grimm_url = '/content/drive/My Drive/StoryTellerAI/FairytalesByTheBrothersGrimm.txt'\n",
        "coraline_url = '/content/drive/My Drive/StoryTellerAI/Coraline.pdf'\n",
        "alice_url = '/content/drive/My Drive/StoryTellerAI/AlicesAdvanturesInWonderland.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIIx1pysjBnD"
      },
      "source": [
        "#load punctuation symbols\n",
        "punct = string.punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r7JQDi3iz14"
      },
      "source": [
        "# **Pre-processing Coraline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vand5igZEP5l",
        "outputId": "42ae74b5-d749-4401-939b-4928a7f62942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#a function to pre process Coraline by Neil Gaiman\n",
        "\n",
        "def preprocess_coraline(book):\n",
        "  '''\n",
        "  param book: url od a PDF book file\n",
        "  '''\n",
        "  output = \"\"\n",
        "  data = open(book, 'rb')\n",
        "  data = PyPDF2.PdfFileReader(book)\n",
        "  npages = data.getNumPages()\n",
        "  for i in range(npages):\n",
        "    page_i = data.getPage(i).extractText()\n",
        "    output += page_i\n",
        "  output = output[1227:]\n",
        "  output = output.lower()\n",
        "  for word in output:\n",
        "    for char in word:\n",
        "        if char in punct:\n",
        "            word = word.replace(char, \"\")\n",
        "  remove_punct = \"\".join([word for word in output if word not in punct])\n",
        "  # book_edit = re.sub('[\\d]','',remove_punct)\n",
        "  # processed = word_tokenize(book_edit)\n",
        "  processed = word_tokenize(remove_punct)\n",
        "\n",
        "  print('Coraline database includes {} tokens, and {} unique tokens after editing'.format(len(processed), len(set(processed)))) \n",
        "  return processed\n",
        "\n",
        "coraline = preprocess_coraline(coraline_url) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coraline database includes 30835 tokens, and 3471 unique tokens after editing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRDl2y87jh1w"
      },
      "source": [
        "## **Preprocessing Alice in Wonderland**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6xyaeRuiMnk",
        "outputId": "9567850f-398a-49be-c9f1-85e311b52d28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#a function to pre process Alice's Advantures in Wonderland by Lewis Carroll\n",
        "\n",
        "def load_alice(text_file, punct, not_a_word):\n",
        "    '''\n",
        "    param text_file: url to Project Gutenberg's text file for Alice's Advantures in Wonderland by Lewis Carroll\n",
        "    param punct: a string of punctuation characters we'd like to filter\n",
        "    param not_a_word: a list of words we'd like to filter\n",
        "    '''\n",
        "    book = open(text_file, 'r')\n",
        "    book = book.read()\n",
        "    book = book[715:145060]\n",
        "    book_edit = re.sub('[+]', '', book)\n",
        "    book_edit = re.sub(r'(CHAPTER \\w+.\\s)', '', book_edit)\n",
        "    # book_edit = re.sub('[\\d]','',book_edit)###\n",
        "    words = word_tokenize(book_edit.lower())\n",
        "    \n",
        "    word_list = []\n",
        "    \n",
        "    # filtering punctuation and non-words\n",
        "    for word in words:\n",
        "        for char in word:\n",
        "            if char in punct:\n",
        "                word = word.replace(char, \"\")\n",
        "        if word not in punct and word not in not_a_word:\n",
        "            word_list.append(word)\n",
        "\n",
        "    print('Alice database includes {} tokens, and {} unique tokens after editing'.format(len(word_list), len(set(word_list)))) \n",
        "    return word_list\n",
        "\n",
        "alice = load_alice(alice_url, (punct.replace('-', \"\") + '’' + '‘'), ['s', '--', 'nt', 've', 'll', 'd'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alice database includes 26612 tokens, and 2596 unique tokens after editing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HcUOknolEWm"
      },
      "source": [
        "# **Preprocessing Grimm**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTG-MTfsEgNu",
        "outputId": "dec7709d-ece6-42a3-8036-a8407a42b39a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def load_fairytales(text_file):\n",
        "    '''\n",
        "    param text_file: url to Project Gutenberg's text file for Fairytales by The Brothers Grimm\n",
        "    '''\n",
        "    book = open(text_file, encoding='cp1252')\n",
        "    book = book.read()\n",
        "    book = book[2376:519859]\n",
        "    book_edit = re.sub('[(+*)]', '', book)\n",
        "    # book_edit = re.sub('[\\d]','',book_edit)####\n",
        "    words = word_tokenize(book_edit.lower())\n",
        "\n",
        "    # filtering punctuation inside tokens (example: didn't or wow!)\n",
        "    for word in words:\n",
        "        for char in word:\n",
        "            if char in punct:\n",
        "                word = word.replace(char, \"\")\n",
        "\n",
        "    # filtering punctuation as alone standing tokens(example: \\ or ,)\n",
        "    words = [word for word in words if word not in punct]\n",
        "\n",
        "    print('Fairytales database includes {} tokens, and {} unique tokens after editing'.format(len(words), len(set(words))))            \n",
        "    return words\n",
        "\n",
        "brothers_grimm = load_fairytales(grimm_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fairytales database includes 106324 tokens, and 5335 unique tokens after editing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM8boZfBhTaw"
      },
      "source": [
        "# **Combined database including all books**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROjnov9uWSbe",
        "outputId": "0b19c45f-7d46-4530-a916-bca5b425887f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = coraline + alice + brothers_grimm\n",
        "data[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['coraline',\n",
              " 'discovered',\n",
              " 'the',\n",
              " 'door',\n",
              " 'a',\n",
              " 'little',\n",
              " 'while',\n",
              " 'after',\n",
              " 'they',\n",
              " 'moved']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84kEdfzunnVY"
      },
      "source": [
        "# **Convert Data into Numeric Values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH5YsCDlm6jq"
      },
      "source": [
        "vocab = set(data)\n",
        "vocab_size = len(data)\n",
        "\n",
        "# word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "# data = [word_to_index[word] for word in data]\n",
        "# data[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecdp_fFoL4cG",
        "outputId": "3327e26b-01dc-4c18-c6d7-a8e6341b0f47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163771"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIQgvVS3RDos"
      },
      "source": [
        "# word_to_index['coraline']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_IEytwGn0jC"
      },
      "source": [
        "# **Batching Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP5qnVKWn5gW",
        "outputId": "9f2d174c-9ede-4c49-b1c0-bbf55b3f98b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 5 #Looking first 5 words, network is going to guess the 6\n",
        "\n",
        "train_data = [([data[i],\n",
        "                data[i+1],\n",
        "                data[i+2],\n",
        "                data[i+3],\n",
        "                data[i+4]],\n",
        "                data[i+5])\n",
        "             for i in range(vocab_size-batch_size)]\n",
        "\n",
        "train_data[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['coraline', 'discovered', 'the', 'door', 'a'], 'little'),\n",
              " (['discovered', 'the', 'door', 'a', 'little'], 'while'),\n",
              " (['the', 'door', 'a', 'little', 'while'], 'after'),\n",
              " (['door', 'a', 'little', 'while', 'after'], 'they'),\n",
              " (['a', 'little', 'while', 'after', 'they'], 'moved'),\n",
              " (['little', 'while', 'after', 'they', 'moved'], 'into'),\n",
              " (['while', 'after', 'they', 'moved', 'into'], 'the'),\n",
              " (['after', 'they', 'moved', 'into', 'the'], 'house'),\n",
              " (['they', 'moved', 'into', 'the', 'house'], 'it'),\n",
              " (['moved', 'into', 'the', 'house', 'it'], 'was')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU2YCOBVn6RU"
      },
      "source": [
        "# **Defining the Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMpb7olaoASw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "embedding_dim = 15\n",
        "\n",
        "#Structuring the Neural Network\n",
        "class StoryTeller(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, n_features):\n",
        "        super(StoryTeller, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(n_features * embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, 768)   \n",
        "        self.linear3 = nn.Linear(768, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((1, -1))\n",
        "        out = F.relu(self.linear1(embeds))\n",
        "        out = F.relu(self.linear2(out))\n",
        "        out = self.linear3(out)\n",
        "        log_probs = F.log_softmax(out, dim=1)\n",
        "        return log_probs\n",
        "\n",
        "#         self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "#         self.linear1 = nn.Linear(n_features * embedding_dim, 192)\n",
        "#         self.linear2 = nn.Linear(192, 1152)   \n",
        "#         self.linear3 = nn.Linear(1152, vocab_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqcBctDGoA_5"
      },
      "source": [
        "# **Defining Training Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj_jF78uoGqy"
      },
      "source": [
        "#Training Function\n",
        "def train(model, train_data, epochs, word_to_idx): \n",
        "    #checking for available GPU \n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda:0\")\n",
        "        print('Training on GPU...')\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print('No GPU available: Training on CPU...')\n",
        "    model.to(device)  \n",
        "\n",
        "    #training begins\n",
        "    for e in range(epochs):\n",
        "        model.train()\n",
        "        steps = 0\n",
        "        print_every = 100\n",
        "        running_loss = 0\n",
        "        for feature, target in train_data:\n",
        "            feature_idx = torch.tensor([word_to_idx[word] for word in feature], dtype=torch.long)\n",
        "            feature_idx = feature_idx.to(device)\n",
        "            steps += 1\n",
        "            model.zero_grad()\n",
        "            log_probs = model(feature_idx)\n",
        "            target_tensor = torch.tensor([word_to_idx[target]], dtype=torch.long)\n",
        "            target_tensor = target_tensor.to(device)\n",
        "            loss = criterion(log_probs, target_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if steps % print_every == 0:\n",
        "              model.eval()  \n",
        "              average_loss.append(running_loss/print_every)\n",
        "              #Printing Training information    \n",
        "              print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                    \"Running Loss: {:.3f}.. \".format(running_loss/print_every))        \n",
        "              running_loss = 0\n",
        "              model.train()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kc2ysQGoJZU"
      },
      "source": [
        "# **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUYN20PVoMvn",
        "outputId": "6e6767b1-2885-4dd7-b9f4-e19235d443c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Vocabulary\n",
        "vocab = set(data)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Word Mappings\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx_to_word = {i: word for i, word in enumerate(vocab)}\n",
        "\n",
        "# Training Parameters\n",
        "model = StoryTeller(vocab_size, embedding_dim, batch_size)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 30\n",
        "average_loss = []\n",
        "device = 0\n",
        "\n",
        "start_time = time.time()\n",
        "model = train(model, train_data, epochs, word_to_idx)  \n",
        "\n",
        "# Training Summary\n",
        "print('-----------------------------------------------------\\n TRAINING END \\n-----------------------------------------------------')\n",
        "print('Training Took {} Minutes'.format(round((time.time() - start_time)/60), 2))\n",
        "print('Highest Loss Value: {} / Lowest Loss Value: {}'.format(max(average_loss), min(average_loss)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "Epoch: 27/30..  Running Loss: 2.763.. \n",
            "Epoch: 27/30..  Running Loss: 2.392.. \n",
            "Epoch: 27/30..  Running Loss: 2.553.. \n",
            "Epoch: 27/30..  Running Loss: 2.316.. \n",
            "Epoch: 27/30..  Running Loss: 2.883.. \n",
            "Epoch: 27/30..  Running Loss: 2.502.. \n",
            "Epoch: 27/30..  Running Loss: 2.731.. \n",
            "Epoch: 27/30..  Running Loss: 2.741.. \n",
            "Epoch: 27/30..  Running Loss: 2.327.. \n",
            "Epoch: 27/30..  Running Loss: 2.217.. \n",
            "Epoch: 27/30..  Running Loss: 2.445.. \n",
            "Epoch: 27/30..  Running Loss: 2.804.. \n",
            "Epoch: 27/30..  Running Loss: 2.604.. \n",
            "Epoch: 27/30..  Running Loss: 2.572.. \n",
            "Epoch: 27/30..  Running Loss: 2.207.. \n",
            "Epoch: 27/30..  Running Loss: 2.852.. \n",
            "Epoch: 27/30..  Running Loss: 2.511.. \n",
            "Epoch: 27/30..  Running Loss: 2.417.. \n",
            "Epoch: 27/30..  Running Loss: 2.871.. \n",
            "Epoch: 27/30..  Running Loss: 2.159.. \n",
            "Epoch: 27/30..  Running Loss: 2.580.. \n",
            "Epoch: 27/30..  Running Loss: 2.238.. \n",
            "Epoch: 27/30..  Running Loss: 2.602.. \n",
            "Epoch: 27/30..  Running Loss: 2.481.. \n",
            "Epoch: 27/30..  Running Loss: 2.334.. \n",
            "Epoch: 27/30..  Running Loss: 2.105.. \n",
            "Epoch: 27/30..  Running Loss: 2.510.. \n",
            "Epoch: 27/30..  Running Loss: 2.511.. \n",
            "Epoch: 27/30..  Running Loss: 2.676.. \n",
            "Epoch: 27/30..  Running Loss: 2.537.. \n",
            "Epoch: 27/30..  Running Loss: 2.213.. \n",
            "Epoch: 27/30..  Running Loss: 2.741.. \n",
            "Epoch: 27/30..  Running Loss: 2.294.. \n",
            "Epoch: 27/30..  Running Loss: 2.476.. \n",
            "Epoch: 27/30..  Running Loss: 2.437.. \n",
            "Epoch: 27/30..  Running Loss: 2.400.. \n",
            "Epoch: 27/30..  Running Loss: 2.546.. \n",
            "Epoch: 27/30..  Running Loss: 2.374.. \n",
            "Epoch: 27/30..  Running Loss: 2.425.. \n",
            "Epoch: 27/30..  Running Loss: 2.703.. \n",
            "Epoch: 27/30..  Running Loss: 2.396.. \n",
            "Epoch: 27/30..  Running Loss: 2.735.. \n",
            "Epoch: 27/30..  Running Loss: 2.323.. \n",
            "Epoch: 27/30..  Running Loss: 2.703.. \n",
            "Epoch: 27/30..  Running Loss: 2.541.. \n",
            "Epoch: 27/30..  Running Loss: 2.601.. \n",
            "Epoch: 27/30..  Running Loss: 2.575.. \n",
            "Epoch: 27/30..  Running Loss: 2.383.. \n",
            "Epoch: 27/30..  Running Loss: 2.596.. \n",
            "Epoch: 27/30..  Running Loss: 2.236.. \n",
            "Epoch: 27/30..  Running Loss: 2.878.. \n",
            "Epoch: 27/30..  Running Loss: 2.414.. \n",
            "Epoch: 27/30..  Running Loss: 2.198.. \n",
            "Epoch: 27/30..  Running Loss: 1.970.. \n",
            "Epoch: 27/30..  Running Loss: 2.491.. \n",
            "Epoch: 27/30..  Running Loss: 2.558.. \n",
            "Epoch: 27/30..  Running Loss: 2.436.. \n",
            "Epoch: 27/30..  Running Loss: 2.448.. \n",
            "Epoch: 27/30..  Running Loss: 2.255.. \n",
            "Epoch: 27/30..  Running Loss: 2.833.. \n",
            "Epoch: 27/30..  Running Loss: 2.718.. \n",
            "Epoch: 27/30..  Running Loss: 2.631.. \n",
            "Epoch: 27/30..  Running Loss: 2.386.. \n",
            "Epoch: 27/30..  Running Loss: 2.544.. \n",
            "Epoch: 27/30..  Running Loss: 2.568.. \n",
            "Epoch: 27/30..  Running Loss: 2.342.. \n",
            "Epoch: 27/30..  Running Loss: 2.550.. \n",
            "Epoch: 27/30..  Running Loss: 2.474.. \n",
            "Epoch: 27/30..  Running Loss: 2.362.. \n",
            "Epoch: 27/30..  Running Loss: 2.560.. \n",
            "Epoch: 27/30..  Running Loss: 2.502.. \n",
            "Epoch: 27/30..  Running Loss: 2.469.. \n",
            "Epoch: 27/30..  Running Loss: 2.600.. \n",
            "Epoch: 27/30..  Running Loss: 2.479.. \n",
            "Epoch: 27/30..  Running Loss: 2.224.. \n",
            "Epoch: 27/30..  Running Loss: 2.302.. \n",
            "Epoch: 27/30..  Running Loss: 2.583.. \n",
            "Epoch: 27/30..  Running Loss: 2.544.. \n",
            "Epoch: 27/30..  Running Loss: 2.558.. \n",
            "Epoch: 27/30..  Running Loss: 2.455.. \n",
            "Epoch: 27/30..  Running Loss: 2.583.. \n",
            "Epoch: 27/30..  Running Loss: 2.449.. \n",
            "Epoch: 27/30..  Running Loss: 2.599.. \n",
            "Epoch: 27/30..  Running Loss: 2.880.. \n",
            "Epoch: 28/30..  Running Loss: 2.700.. \n",
            "Epoch: 28/30..  Running Loss: 2.535.. \n",
            "Epoch: 28/30..  Running Loss: 2.871.. \n",
            "Epoch: 28/30..  Running Loss: 2.452.. \n",
            "Epoch: 28/30..  Running Loss: 2.396.. \n",
            "Epoch: 28/30..  Running Loss: 2.223.. \n",
            "Epoch: 28/30..  Running Loss: 2.766.. \n",
            "Epoch: 28/30..  Running Loss: 2.634.. \n",
            "Epoch: 28/30..  Running Loss: 2.562.. \n",
            "Epoch: 28/30..  Running Loss: 2.774.. \n",
            "Epoch: 28/30..  Running Loss: 2.339.. \n",
            "Epoch: 28/30..  Running Loss: 2.222.. \n",
            "Epoch: 28/30..  Running Loss: 2.319.. \n",
            "Epoch: 28/30..  Running Loss: 2.740.. \n",
            "Epoch: 28/30..  Running Loss: 2.339.. \n",
            "Epoch: 28/30..  Running Loss: 2.561.. \n",
            "Epoch: 28/30..  Running Loss: 2.327.. \n",
            "Epoch: 28/30..  Running Loss: 2.268.. \n",
            "Epoch: 28/30..  Running Loss: 2.238.. \n",
            "Epoch: 28/30..  Running Loss: 2.267.. \n",
            "Epoch: 28/30..  Running Loss: 2.500.. \n",
            "Epoch: 28/30..  Running Loss: 2.497.. \n",
            "Epoch: 28/30..  Running Loss: 2.734.. \n",
            "Epoch: 28/30..  Running Loss: 2.381.. \n",
            "Epoch: 28/30..  Running Loss: 2.247.. \n",
            "Epoch: 28/30..  Running Loss: 2.388.. \n",
            "Epoch: 28/30..  Running Loss: 2.491.. \n",
            "Epoch: 28/30..  Running Loss: 2.450.. \n",
            "Epoch: 28/30..  Running Loss: 2.042.. \n",
            "Epoch: 28/30..  Running Loss: 2.149.. \n",
            "Epoch: 28/30..  Running Loss: 2.382.. \n",
            "Epoch: 28/30..  Running Loss: 2.141.. \n",
            "Epoch: 28/30..  Running Loss: 2.440.. \n",
            "Epoch: 28/30..  Running Loss: 2.196.. \n",
            "Epoch: 28/30..  Running Loss: 2.226.. \n",
            "Epoch: 28/30..  Running Loss: 2.821.. \n",
            "Epoch: 28/30..  Running Loss: 2.893.. \n",
            "Epoch: 28/30..  Running Loss: 2.071.. \n",
            "Epoch: 28/30..  Running Loss: 2.337.. \n",
            "Epoch: 28/30..  Running Loss: 2.341.. \n",
            "Epoch: 28/30..  Running Loss: 2.369.. \n",
            "Epoch: 28/30..  Running Loss: 2.579.. \n",
            "Epoch: 28/30..  Running Loss: 2.337.. \n",
            "Epoch: 28/30..  Running Loss: 2.782.. \n",
            "Epoch: 28/30..  Running Loss: 2.877.. \n",
            "Epoch: 28/30..  Running Loss: 2.311.. \n",
            "Epoch: 28/30..  Running Loss: 2.579.. \n",
            "Epoch: 28/30..  Running Loss: 2.494.. \n",
            "Epoch: 28/30..  Running Loss: 2.334.. \n",
            "Epoch: 28/30..  Running Loss: 2.632.. \n",
            "Epoch: 28/30..  Running Loss: 2.143.. \n",
            "Epoch: 28/30..  Running Loss: 2.385.. \n",
            "Epoch: 28/30..  Running Loss: 2.508.. \n",
            "Epoch: 28/30..  Running Loss: 2.450.. \n",
            "Epoch: 28/30..  Running Loss: 2.347.. \n",
            "Epoch: 28/30..  Running Loss: 2.490.. \n",
            "Epoch: 28/30..  Running Loss: 2.656.. \n",
            "Epoch: 28/30..  Running Loss: 2.507.. \n",
            "Epoch: 28/30..  Running Loss: 1.949.. \n",
            "Epoch: 28/30..  Running Loss: 2.427.. \n",
            "Epoch: 28/30..  Running Loss: 2.679.. \n",
            "Epoch: 28/30..  Running Loss: 2.553.. \n",
            "Epoch: 28/30..  Running Loss: 2.287.. \n",
            "Epoch: 28/30..  Running Loss: 2.299.. \n",
            "Epoch: 28/30..  Running Loss: 2.308.. \n",
            "Epoch: 28/30..  Running Loss: 2.054.. \n",
            "Epoch: 28/30..  Running Loss: 2.234.. \n",
            "Epoch: 28/30..  Running Loss: 2.733.. \n",
            "Epoch: 28/30..  Running Loss: 2.351.. \n",
            "Epoch: 28/30..  Running Loss: 2.311.. \n",
            "Epoch: 28/30..  Running Loss: 2.268.. \n",
            "Epoch: 28/30..  Running Loss: 2.378.. \n",
            "Epoch: 28/30..  Running Loss: 2.578.. \n",
            "Epoch: 28/30..  Running Loss: 2.627.. \n",
            "Epoch: 28/30..  Running Loss: 2.347.. \n",
            "Epoch: 28/30..  Running Loss: 2.622.. \n",
            "Epoch: 28/30..  Running Loss: 2.146.. \n",
            "Epoch: 28/30..  Running Loss: 2.110.. \n",
            "Epoch: 28/30..  Running Loss: 2.012.. \n",
            "Epoch: 28/30..  Running Loss: 2.375.. \n",
            "Epoch: 28/30..  Running Loss: 2.450.. \n",
            "Epoch: 28/30..  Running Loss: 2.294.. \n",
            "Epoch: 28/30..  Running Loss: 2.463.. \n",
            "Epoch: 28/30..  Running Loss: 2.344.. \n",
            "Epoch: 28/30..  Running Loss: 2.483.. \n",
            "Epoch: 28/30..  Running Loss: 2.334.. \n",
            "Epoch: 28/30..  Running Loss: 2.711.. \n",
            "Epoch: 28/30..  Running Loss: 2.891.. \n",
            "Epoch: 28/30..  Running Loss: 2.121.. \n",
            "Epoch: 28/30..  Running Loss: 2.808.. \n",
            "Epoch: 28/30..  Running Loss: 2.465.. \n",
            "Epoch: 28/30..  Running Loss: 2.705.. \n",
            "Epoch: 28/30..  Running Loss: 2.955.. \n",
            "Epoch: 28/30..  Running Loss: 2.354.. \n",
            "Epoch: 28/30..  Running Loss: 2.077.. \n",
            "Epoch: 28/30..  Running Loss: 2.706.. \n",
            "Epoch: 28/30..  Running Loss: 2.859.. \n",
            "Epoch: 28/30..  Running Loss: 2.432.. \n",
            "Epoch: 28/30..  Running Loss: 2.188.. \n",
            "Epoch: 28/30..  Running Loss: 2.913.. \n",
            "Epoch: 28/30..  Running Loss: 2.379.. \n",
            "Epoch: 28/30..  Running Loss: 2.403.. \n",
            "Epoch: 28/30..  Running Loss: 2.828.. \n",
            "Epoch: 28/30..  Running Loss: 2.579.. \n",
            "Epoch: 28/30..  Running Loss: 2.783.. \n",
            "Epoch: 28/30..  Running Loss: 2.490.. \n",
            "Epoch: 28/30..  Running Loss: 2.315.. \n",
            "Epoch: 28/30..  Running Loss: 2.746.. \n",
            "Epoch: 28/30..  Running Loss: 2.397.. \n",
            "Epoch: 28/30..  Running Loss: 3.217.. \n",
            "Epoch: 28/30..  Running Loss: 2.478.. \n",
            "Epoch: 28/30..  Running Loss: 2.552.. \n",
            "Epoch: 28/30..  Running Loss: 2.356.. \n",
            "Epoch: 28/30..  Running Loss: 2.156.. \n",
            "Epoch: 28/30..  Running Loss: 2.525.. \n",
            "Epoch: 28/30..  Running Loss: 2.702.. \n",
            "Epoch: 28/30..  Running Loss: 2.770.. \n",
            "Epoch: 28/30..  Running Loss: 2.525.. \n",
            "Epoch: 28/30..  Running Loss: 2.370.. \n",
            "Epoch: 28/30..  Running Loss: 2.254.. \n",
            "Epoch: 28/30..  Running Loss: 2.708.. \n",
            "Epoch: 28/30..  Running Loss: 2.472.. \n",
            "Epoch: 28/30..  Running Loss: 1.993.. \n",
            "Epoch: 28/30..  Running Loss: 2.572.. \n",
            "Epoch: 28/30..  Running Loss: 2.517.. \n",
            "Epoch: 28/30..  Running Loss: 2.831.. \n",
            "Epoch: 28/30..  Running Loss: 2.455.. \n",
            "Epoch: 28/30..  Running Loss: 2.909.. \n",
            "Epoch: 28/30..  Running Loss: 2.584.. \n",
            "Epoch: 28/30..  Running Loss: 2.470.. \n",
            "Epoch: 28/30..  Running Loss: 2.342.. \n",
            "Epoch: 28/30..  Running Loss: 2.753.. \n",
            "Epoch: 28/30..  Running Loss: 2.495.. \n",
            "Epoch: 28/30..  Running Loss: 2.559.. \n",
            "Epoch: 28/30..  Running Loss: 2.645.. \n",
            "Epoch: 28/30..  Running Loss: 2.970.. \n",
            "Epoch: 28/30..  Running Loss: 2.121.. \n",
            "Epoch: 28/30..  Running Loss: 2.721.. \n",
            "Epoch: 28/30..  Running Loss: 2.341.. \n",
            "Epoch: 28/30..  Running Loss: 2.359.. \n",
            "Epoch: 28/30..  Running Loss: 2.550.. \n",
            "Epoch: 28/30..  Running Loss: 2.192.. \n",
            "Epoch: 28/30..  Running Loss: 2.660.. \n",
            "Epoch: 28/30..  Running Loss: 2.375.. \n",
            "Epoch: 28/30..  Running Loss: 2.317.. \n",
            "Epoch: 28/30..  Running Loss: 2.568.. \n",
            "Epoch: 28/30..  Running Loss: 2.521.. \n",
            "Epoch: 28/30..  Running Loss: 2.600.. \n",
            "Epoch: 28/30..  Running Loss: 2.600.. \n",
            "Epoch: 28/30..  Running Loss: 2.678.. \n",
            "Epoch: 28/30..  Running Loss: 2.987.. \n",
            "Epoch: 28/30..  Running Loss: 2.406.. \n",
            "Epoch: 28/30..  Running Loss: 2.488.. \n",
            "Epoch: 28/30..  Running Loss: 2.582.. \n",
            "Epoch: 28/30..  Running Loss: 2.842.. \n",
            "Epoch: 28/30..  Running Loss: 2.524.. \n",
            "Epoch: 28/30..  Running Loss: 2.420.. \n",
            "Epoch: 28/30..  Running Loss: 2.482.. \n",
            "Epoch: 28/30..  Running Loss: 2.401.. \n",
            "Epoch: 28/30..  Running Loss: 2.441.. \n",
            "Epoch: 28/30..  Running Loss: 2.730.. \n",
            "Epoch: 28/30..  Running Loss: 2.392.. \n",
            "Epoch: 28/30..  Running Loss: 1.923.. \n",
            "Epoch: 28/30..  Running Loss: 2.338.. \n",
            "Epoch: 28/30..  Running Loss: 2.401.. \n",
            "Epoch: 28/30..  Running Loss: 2.242.. \n",
            "Epoch: 28/30..  Running Loss: 2.652.. \n",
            "Epoch: 28/30..  Running Loss: 2.440.. \n",
            "Epoch: 28/30..  Running Loss: 2.676.. \n",
            "Epoch: 28/30..  Running Loss: 2.241.. \n",
            "Epoch: 28/30..  Running Loss: 2.220.. \n",
            "Epoch: 28/30..  Running Loss: 2.343.. \n",
            "Epoch: 28/30..  Running Loss: 2.158.. \n",
            "Epoch: 28/30..  Running Loss: 2.356.. \n",
            "Epoch: 28/30..  Running Loss: 2.114.. \n",
            "Epoch: 28/30..  Running Loss: 2.318.. \n",
            "Epoch: 28/30..  Running Loss: 2.154.. \n",
            "Epoch: 28/30..  Running Loss: 1.940.. \n",
            "Epoch: 28/30..  Running Loss: 2.719.. \n",
            "Epoch: 28/30..  Running Loss: 2.291.. \n",
            "Epoch: 28/30..  Running Loss: 2.340.. \n",
            "Epoch: 28/30..  Running Loss: 2.543.. \n",
            "Epoch: 28/30..  Running Loss: 2.002.. \n",
            "Epoch: 28/30..  Running Loss: 2.207.. \n",
            "Epoch: 28/30..  Running Loss: 1.947.. \n",
            "Epoch: 28/30..  Running Loss: 2.252.. \n",
            "Epoch: 28/30..  Running Loss: 2.394.. \n",
            "Epoch: 28/30..  Running Loss: 2.329.. \n",
            "Epoch: 28/30..  Running Loss: 1.921.. \n",
            "Epoch: 28/30..  Running Loss: 2.319.. \n",
            "Epoch: 28/30..  Running Loss: 2.585.. \n",
            "Epoch: 28/30..  Running Loss: 2.533.. \n",
            "Epoch: 28/30..  Running Loss: 2.773.. \n",
            "Epoch: 28/30..  Running Loss: 2.477.. \n",
            "Epoch: 28/30..  Running Loss: 2.450.. \n",
            "Epoch: 28/30..  Running Loss: 2.625.. \n",
            "Epoch: 28/30..  Running Loss: 2.542.. \n",
            "Epoch: 28/30..  Running Loss: 2.200.. \n",
            "Epoch: 28/30..  Running Loss: 2.222.. \n",
            "Epoch: 28/30..  Running Loss: 2.365.. \n",
            "Epoch: 28/30..  Running Loss: 2.303.. \n",
            "Epoch: 28/30..  Running Loss: 2.153.. \n",
            "Epoch: 28/30..  Running Loss: 2.399.. \n",
            "Epoch: 28/30..  Running Loss: 1.998.. \n",
            "Epoch: 28/30..  Running Loss: 2.538.. \n",
            "Epoch: 28/30..  Running Loss: 2.338.. \n",
            "Epoch: 28/30..  Running Loss: 2.781.. \n",
            "Epoch: 28/30..  Running Loss: 2.484.. \n",
            "Epoch: 28/30..  Running Loss: 2.865.. \n",
            "Epoch: 28/30..  Running Loss: 2.501.. \n",
            "Epoch: 28/30..  Running Loss: 2.378.. \n",
            "Epoch: 28/30..  Running Loss: 2.239.. \n",
            "Epoch: 28/30..  Running Loss: 2.365.. \n",
            "Epoch: 28/30..  Running Loss: 2.656.. \n",
            "Epoch: 28/30..  Running Loss: 2.436.. \n",
            "Epoch: 28/30..  Running Loss: 2.524.. \n",
            "Epoch: 28/30..  Running Loss: 2.451.. \n",
            "Epoch: 28/30..  Running Loss: 2.199.. \n",
            "Epoch: 28/30..  Running Loss: 2.199.. \n",
            "Epoch: 28/30..  Running Loss: 2.664.. \n",
            "Epoch: 28/30..  Running Loss: 2.740.. \n",
            "Epoch: 28/30..  Running Loss: 2.732.. \n",
            "Epoch: 28/30..  Running Loss: 2.193.. \n",
            "Epoch: 28/30..  Running Loss: 2.106.. \n",
            "Epoch: 28/30..  Running Loss: 2.319.. \n",
            "Epoch: 28/30..  Running Loss: 2.015.. \n",
            "Epoch: 28/30..  Running Loss: 2.370.. \n",
            "Epoch: 28/30..  Running Loss: 2.667.. \n",
            "Epoch: 28/30..  Running Loss: 2.435.. \n",
            "Epoch: 28/30..  Running Loss: 2.584.. \n",
            "Epoch: 28/30..  Running Loss: 2.529.. \n",
            "Epoch: 28/30..  Running Loss: 2.460.. \n",
            "Epoch: 28/30..  Running Loss: 2.506.. \n",
            "Epoch: 28/30..  Running Loss: 2.585.. \n",
            "Epoch: 28/30..  Running Loss: 2.513.. \n",
            "Epoch: 28/30..  Running Loss: 2.300.. \n",
            "Epoch: 28/30..  Running Loss: 2.547.. \n",
            "Epoch: 28/30..  Running Loss: 2.431.. \n",
            "Epoch: 28/30..  Running Loss: 2.544.. \n",
            "Epoch: 28/30..  Running Loss: 2.338.. \n",
            "Epoch: 28/30..  Running Loss: 2.058.. \n",
            "Epoch: 28/30..  Running Loss: 2.290.. \n",
            "Epoch: 28/30..  Running Loss: 2.354.. \n",
            "Epoch: 28/30..  Running Loss: 2.524.. \n",
            "Epoch: 28/30..  Running Loss: 2.400.. \n",
            "Epoch: 28/30..  Running Loss: 2.737.. \n",
            "Epoch: 28/30..  Running Loss: 2.502.. \n",
            "Epoch: 28/30..  Running Loss: 2.249.. \n",
            "Epoch: 28/30..  Running Loss: 2.167.. \n",
            "Epoch: 28/30..  Running Loss: 2.368.. \n",
            "Epoch: 28/30..  Running Loss: 2.635.. \n",
            "Epoch: 28/30..  Running Loss: 2.707.. \n",
            "Epoch: 28/30..  Running Loss: 2.426.. \n",
            "Epoch: 28/30..  Running Loss: 2.342.. \n",
            "Epoch: 28/30..  Running Loss: 2.245.. \n",
            "Epoch: 28/30..  Running Loss: 2.560.. \n",
            "Epoch: 28/30..  Running Loss: 2.295.. \n",
            "Epoch: 28/30..  Running Loss: 2.106.. \n",
            "Epoch: 28/30..  Running Loss: 2.405.. \n",
            "Epoch: 28/30..  Running Loss: 2.575.. \n",
            "Epoch: 28/30..  Running Loss: 2.514.. \n",
            "Epoch: 28/30..  Running Loss: 2.064.. \n",
            "Epoch: 28/30..  Running Loss: 2.100.. \n",
            "Epoch: 28/30..  Running Loss: 3.112.. \n",
            "Epoch: 28/30..  Running Loss: 2.437.. \n",
            "Epoch: 28/30..  Running Loss: 2.100.. \n",
            "Epoch: 28/30..  Running Loss: 2.842.. \n",
            "Epoch: 28/30..  Running Loss: 2.272.. \n",
            "Epoch: 28/30..  Running Loss: 2.281.. \n",
            "Epoch: 28/30..  Running Loss: 2.566.. \n",
            "Epoch: 28/30..  Running Loss: 2.665.. \n",
            "Epoch: 28/30..  Running Loss: 2.813.. \n",
            "Epoch: 28/30..  Running Loss: 2.625.. \n",
            "Epoch: 28/30..  Running Loss: 2.734.. \n",
            "Epoch: 28/30..  Running Loss: 2.746.. \n",
            "Epoch: 28/30..  Running Loss: 2.502.. \n",
            "Epoch: 28/30..  Running Loss: 2.430.. \n",
            "Epoch: 28/30..  Running Loss: 1.950.. \n",
            "Epoch: 28/30..  Running Loss: 2.371.. \n",
            "Epoch: 28/30..  Running Loss: 2.406.. \n",
            "Epoch: 28/30..  Running Loss: 2.655.. \n",
            "Epoch: 28/30..  Running Loss: 2.530.. \n",
            "Epoch: 28/30..  Running Loss: 2.115.. \n",
            "Epoch: 28/30..  Running Loss: 2.702.. \n",
            "Epoch: 28/30..  Running Loss: 2.435.. \n",
            "Epoch: 28/30..  Running Loss: 2.569.. \n",
            "Epoch: 28/30..  Running Loss: 2.454.. \n",
            "Epoch: 28/30..  Running Loss: 2.391.. \n",
            "Epoch: 28/30..  Running Loss: 2.638.. \n",
            "Epoch: 28/30..  Running Loss: 2.491.. \n",
            "Epoch: 28/30..  Running Loss: 2.286.. \n",
            "Epoch: 28/30..  Running Loss: 2.160.. \n",
            "Epoch: 28/30..  Running Loss: 2.256.. \n",
            "Epoch: 28/30..  Running Loss: 2.430.. \n",
            "Epoch: 28/30..  Running Loss: 2.857.. \n",
            "Epoch: 28/30..  Running Loss: 2.089.. \n",
            "Epoch: 28/30..  Running Loss: 2.487.. \n",
            "Epoch: 28/30..  Running Loss: 1.909.. \n",
            "Epoch: 28/30..  Running Loss: 2.320.. \n",
            "Epoch: 28/30..  Running Loss: 2.079.. \n",
            "Epoch: 28/30..  Running Loss: 1.867.. \n",
            "Epoch: 28/30..  Running Loss: 2.261.. \n",
            "Epoch: 28/30..  Running Loss: 2.137.. \n",
            "Epoch: 28/30..  Running Loss: 2.158.. \n",
            "Epoch: 28/30..  Running Loss: 2.985.. \n",
            "Epoch: 28/30..  Running Loss: 2.441.. \n",
            "Epoch: 28/30..  Running Loss: 2.429.. \n",
            "Epoch: 28/30..  Running Loss: 2.450.. \n",
            "Epoch: 28/30..  Running Loss: 3.055.. \n",
            "Epoch: 28/30..  Running Loss: 2.670.. \n",
            "Epoch: 28/30..  Running Loss: 2.728.. \n",
            "Epoch: 28/30..  Running Loss: 2.520.. \n",
            "Epoch: 28/30..  Running Loss: 2.395.. \n",
            "Epoch: 28/30..  Running Loss: 2.753.. \n",
            "Epoch: 28/30..  Running Loss: 2.552.. \n",
            "Epoch: 28/30..  Running Loss: 2.687.. \n",
            "Epoch: 28/30..  Running Loss: 2.797.. \n",
            "Epoch: 28/30..  Running Loss: 2.592.. \n",
            "Epoch: 28/30..  Running Loss: 2.597.. \n",
            "Epoch: 28/30..  Running Loss: 2.678.. \n",
            "Epoch: 28/30..  Running Loss: 2.797.. \n",
            "Epoch: 28/30..  Running Loss: 2.800.. \n",
            "Epoch: 28/30..  Running Loss: 2.474.. \n",
            "Epoch: 28/30..  Running Loss: 3.072.. \n",
            "Epoch: 28/30..  Running Loss: 2.329.. \n",
            "Epoch: 28/30..  Running Loss: 2.605.. \n",
            "Epoch: 28/30..  Running Loss: 2.313.. \n",
            "Epoch: 28/30..  Running Loss: 2.822.. \n",
            "Epoch: 28/30..  Running Loss: 2.558.. \n",
            "Epoch: 28/30..  Running Loss: 2.835.. \n",
            "Epoch: 28/30..  Running Loss: 2.731.. \n",
            "Epoch: 28/30..  Running Loss: 2.638.. \n",
            "Epoch: 28/30..  Running Loss: 2.714.. \n",
            "Epoch: 28/30..  Running Loss: 2.655.. \n",
            "Epoch: 28/30..  Running Loss: 2.319.. \n",
            "Epoch: 28/30..  Running Loss: 2.941.. \n",
            "Epoch: 28/30..  Running Loss: 2.652.. \n",
            "Epoch: 28/30..  Running Loss: 2.167.. \n",
            "Epoch: 28/30..  Running Loss: 2.851.. \n",
            "Epoch: 28/30..  Running Loss: 2.712.. \n",
            "Epoch: 28/30..  Running Loss: 2.701.. \n",
            "Epoch: 28/30..  Running Loss: 2.655.. \n",
            "Epoch: 28/30..  Running Loss: 2.616.. \n",
            "Epoch: 28/30..  Running Loss: 2.198.. \n",
            "Epoch: 28/30..  Running Loss: 2.498.. \n",
            "Epoch: 28/30..  Running Loss: 2.255.. \n",
            "Epoch: 28/30..  Running Loss: 2.360.. \n",
            "Epoch: 28/30..  Running Loss: 2.314.. \n",
            "Epoch: 28/30..  Running Loss: 2.539.. \n",
            "Epoch: 28/30..  Running Loss: 2.428.. \n",
            "Epoch: 28/30..  Running Loss: 2.484.. \n",
            "Epoch: 28/30..  Running Loss: 2.650.. \n",
            "Epoch: 28/30..  Running Loss: 3.022.. \n",
            "Epoch: 28/30..  Running Loss: 2.408.. \n",
            "Epoch: 28/30..  Running Loss: 2.362.. \n",
            "Epoch: 28/30..  Running Loss: 2.122.. \n",
            "Epoch: 28/30..  Running Loss: 2.646.. \n",
            "Epoch: 28/30..  Running Loss: 2.992.. \n",
            "Epoch: 28/30..  Running Loss: 2.877.. \n",
            "Epoch: 28/30..  Running Loss: 2.536.. \n",
            "Epoch: 28/30..  Running Loss: 2.334.. \n",
            "Epoch: 28/30..  Running Loss: 2.295.. \n",
            "Epoch: 28/30..  Running Loss: 2.567.. \n",
            "Epoch: 28/30..  Running Loss: 2.321.. \n",
            "Epoch: 28/30..  Running Loss: 2.350.. \n",
            "Epoch: 28/30..  Running Loss: 2.223.. \n",
            "Epoch: 28/30..  Running Loss: 2.623.. \n",
            "Epoch: 28/30..  Running Loss: 2.268.. \n",
            "Epoch: 28/30..  Running Loss: 2.283.. \n",
            "Epoch: 28/30..  Running Loss: 2.539.. \n",
            "Epoch: 28/30..  Running Loss: 2.968.. \n",
            "Epoch: 28/30..  Running Loss: 2.505.. \n",
            "Epoch: 28/30..  Running Loss: 2.589.. \n",
            "Epoch: 28/30..  Running Loss: 2.513.. \n",
            "Epoch: 28/30..  Running Loss: 2.559.. \n",
            "Epoch: 28/30..  Running Loss: 2.711.. \n",
            "Epoch: 28/30..  Running Loss: 2.593.. \n",
            "Epoch: 28/30..  Running Loss: 2.342.. \n",
            "Epoch: 28/30..  Running Loss: 2.698.. \n",
            "Epoch: 28/30..  Running Loss: 2.487.. \n",
            "Epoch: 28/30..  Running Loss: 2.638.. \n",
            "Epoch: 28/30..  Running Loss: 2.617.. \n",
            "Epoch: 28/30..  Running Loss: 2.746.. \n",
            "Epoch: 28/30..  Running Loss: 2.872.. \n",
            "Epoch: 28/30..  Running Loss: 2.904.. \n",
            "Epoch: 28/30..  Running Loss: 2.498.. \n",
            "Epoch: 28/30..  Running Loss: 2.870.. \n",
            "Epoch: 28/30..  Running Loss: 2.587.. \n",
            "Epoch: 28/30..  Running Loss: 2.681.. \n",
            "Epoch: 28/30..  Running Loss: 2.528.. \n",
            "Epoch: 28/30..  Running Loss: 2.526.. \n",
            "Epoch: 28/30..  Running Loss: 2.405.. \n",
            "Epoch: 28/30..  Running Loss: 2.313.. \n",
            "Epoch: 28/30..  Running Loss: 2.730.. \n",
            "Epoch: 28/30..  Running Loss: 2.200.. \n",
            "Epoch: 28/30..  Running Loss: 2.297.. \n",
            "Epoch: 28/30..  Running Loss: 2.949.. \n",
            "Epoch: 28/30..  Running Loss: 2.586.. \n",
            "Epoch: 28/30..  Running Loss: 2.468.. \n",
            "Epoch: 28/30..  Running Loss: 2.540.. \n",
            "Epoch: 28/30..  Running Loss: 2.816.. \n",
            "Epoch: 28/30..  Running Loss: 2.463.. \n",
            "Epoch: 28/30..  Running Loss: 2.702.. \n",
            "Epoch: 28/30..  Running Loss: 2.152.. \n",
            "Epoch: 28/30..  Running Loss: 2.316.. \n",
            "Epoch: 28/30..  Running Loss: 2.524.. \n",
            "Epoch: 28/30..  Running Loss: 2.315.. \n",
            "Epoch: 28/30..  Running Loss: 2.787.. \n",
            "Epoch: 28/30..  Running Loss: 2.400.. \n",
            "Epoch: 28/30..  Running Loss: 2.372.. \n",
            "Epoch: 28/30..  Running Loss: 2.390.. \n",
            "Epoch: 28/30..  Running Loss: 2.266.. \n",
            "Epoch: 28/30..  Running Loss: 2.564.. \n",
            "Epoch: 28/30..  Running Loss: 2.364.. \n",
            "Epoch: 28/30..  Running Loss: 2.339.. \n",
            "Epoch: 28/30..  Running Loss: 2.658.. \n",
            "Epoch: 28/30..  Running Loss: 2.424.. \n",
            "Epoch: 28/30..  Running Loss: 2.631.. \n",
            "Epoch: 28/30..  Running Loss: 2.722.. \n",
            "Epoch: 28/30..  Running Loss: 2.101.. \n",
            "Epoch: 28/30..  Running Loss: 2.650.. \n",
            "Epoch: 28/30..  Running Loss: 2.370.. \n",
            "Epoch: 28/30..  Running Loss: 2.665.. \n",
            "Epoch: 28/30..  Running Loss: 2.208.. \n",
            "Epoch: 28/30..  Running Loss: 2.655.. \n",
            "Epoch: 28/30..  Running Loss: 2.559.. \n",
            "Epoch: 28/30..  Running Loss: 2.402.. \n",
            "Epoch: 28/30..  Running Loss: 2.376.. \n",
            "Epoch: 28/30..  Running Loss: 2.755.. \n",
            "Epoch: 28/30..  Running Loss: 2.295.. \n",
            "Epoch: 28/30..  Running Loss: 2.456.. \n",
            "Epoch: 28/30..  Running Loss: 2.648.. \n",
            "Epoch: 28/30..  Running Loss: 2.520.. \n",
            "Epoch: 28/30..  Running Loss: 2.598.. \n",
            "Epoch: 28/30..  Running Loss: 2.620.. \n",
            "Epoch: 28/30..  Running Loss: 2.399.. \n",
            "Epoch: 28/30..  Running Loss: 2.795.. \n",
            "Epoch: 28/30..  Running Loss: 2.096.. \n",
            "Epoch: 28/30..  Running Loss: 2.445.. \n",
            "Epoch: 28/30..  Running Loss: 2.297.. \n",
            "Epoch: 28/30..  Running Loss: 2.567.. \n",
            "Epoch: 28/30..  Running Loss: 2.497.. \n",
            "Epoch: 28/30..  Running Loss: 2.416.. \n",
            "Epoch: 28/30..  Running Loss: 2.925.. \n",
            "Epoch: 28/30..  Running Loss: 2.418.. \n",
            "Epoch: 28/30..  Running Loss: 2.796.. \n",
            "Epoch: 28/30..  Running Loss: 2.093.. \n",
            "Epoch: 28/30..  Running Loss: 2.340.. \n",
            "Epoch: 28/30..  Running Loss: 2.691.. \n",
            "Epoch: 28/30..  Running Loss: 2.320.. \n",
            "Epoch: 28/30..  Running Loss: 2.181.. \n",
            "Epoch: 28/30..  Running Loss: 2.741.. \n",
            "Epoch: 28/30..  Running Loss: 2.850.. \n",
            "Epoch: 28/30..  Running Loss: 2.633.. \n",
            "Epoch: 28/30..  Running Loss: 2.408.. \n",
            "Epoch: 28/30..  Running Loss: 2.714.. \n",
            "Epoch: 28/30..  Running Loss: 2.722.. \n",
            "Epoch: 28/30..  Running Loss: 2.329.. \n",
            "Epoch: 28/30..  Running Loss: 2.541.. \n",
            "Epoch: 28/30..  Running Loss: 2.158.. \n",
            "Epoch: 28/30..  Running Loss: 2.392.. \n",
            "Epoch: 28/30..  Running Loss: 2.536.. \n",
            "Epoch: 28/30..  Running Loss: 2.541.. \n",
            "Epoch: 28/30..  Running Loss: 2.792.. \n",
            "Epoch: 28/30..  Running Loss: 2.939.. \n",
            "Epoch: 28/30..  Running Loss: 2.600.. \n",
            "Epoch: 28/30..  Running Loss: 2.977.. \n",
            "Epoch: 28/30..  Running Loss: 2.776.. \n",
            "Epoch: 28/30..  Running Loss: 2.647.. \n",
            "Epoch: 28/30..  Running Loss: 2.388.. \n",
            "Epoch: 28/30..  Running Loss: 2.601.. \n",
            "Epoch: 28/30..  Running Loss: 2.398.. \n",
            "Epoch: 28/30..  Running Loss: 2.264.. \n",
            "Epoch: 28/30..  Running Loss: 2.820.. \n",
            "Epoch: 28/30..  Running Loss: 2.091.. \n",
            "Epoch: 28/30..  Running Loss: 2.337.. \n",
            "Epoch: 28/30..  Running Loss: 2.354.. \n",
            "Epoch: 28/30..  Running Loss: 2.137.. \n",
            "Epoch: 28/30..  Running Loss: 2.441.. \n",
            "Epoch: 28/30..  Running Loss: 2.485.. \n",
            "Epoch: 28/30..  Running Loss: 2.490.. \n",
            "Epoch: 28/30..  Running Loss: 2.824.. \n",
            "Epoch: 28/30..  Running Loss: 2.590.. \n",
            "Epoch: 28/30..  Running Loss: 2.506.. \n",
            "Epoch: 28/30..  Running Loss: 2.984.. \n",
            "Epoch: 28/30..  Running Loss: 2.388.. \n",
            "Epoch: 28/30..  Running Loss: 2.410.. \n",
            "Epoch: 28/30..  Running Loss: 2.529.. \n",
            "Epoch: 28/30..  Running Loss: 2.730.. \n",
            "Epoch: 28/30..  Running Loss: 2.878.. \n",
            "Epoch: 28/30..  Running Loss: 2.673.. \n",
            "Epoch: 28/30..  Running Loss: 2.384.. \n",
            "Epoch: 28/30..  Running Loss: 2.738.. \n",
            "Epoch: 28/30..  Running Loss: 2.223.. \n",
            "Epoch: 28/30..  Running Loss: 2.137.. \n",
            "Epoch: 28/30..  Running Loss: 2.205.. \n",
            "Epoch: 28/30..  Running Loss: 2.534.. \n",
            "Epoch: 28/30..  Running Loss: 2.714.. \n",
            "Epoch: 28/30..  Running Loss: 2.589.. \n",
            "Epoch: 28/30..  Running Loss: 2.503.. \n",
            "Epoch: 28/30..  Running Loss: 2.460.. \n",
            "Epoch: 28/30..  Running Loss: 2.890.. \n",
            "Epoch: 28/30..  Running Loss: 2.526.. \n",
            "Epoch: 28/30..  Running Loss: 2.626.. \n",
            "Epoch: 28/30..  Running Loss: 2.350.. \n",
            "Epoch: 28/30..  Running Loss: 2.683.. \n",
            "Epoch: 28/30..  Running Loss: 2.472.. \n",
            "Epoch: 28/30..  Running Loss: 2.234.. \n",
            "Epoch: 28/30..  Running Loss: 2.395.. \n",
            "Epoch: 28/30..  Running Loss: 2.137.. \n",
            "Epoch: 28/30..  Running Loss: 2.050.. \n",
            "Epoch: 28/30..  Running Loss: 2.366.. \n",
            "Epoch: 28/30..  Running Loss: 2.697.. \n",
            "Epoch: 28/30..  Running Loss: 2.042.. \n",
            "Epoch: 28/30..  Running Loss: 2.262.. \n",
            "Epoch: 28/30..  Running Loss: 2.245.. \n",
            "Epoch: 28/30..  Running Loss: 2.549.. \n",
            "Epoch: 28/30..  Running Loss: 2.284.. \n",
            "Epoch: 28/30..  Running Loss: 2.043.. \n",
            "Epoch: 28/30..  Running Loss: 2.149.. \n",
            "Epoch: 28/30..  Running Loss: 2.224.. \n",
            "Epoch: 28/30..  Running Loss: 2.359.. \n",
            "Epoch: 28/30..  Running Loss: 2.233.. \n",
            "Epoch: 28/30..  Running Loss: 2.408.. \n",
            "Epoch: 28/30..  Running Loss: 2.775.. \n",
            "Epoch: 28/30..  Running Loss: 2.545.. \n",
            "Epoch: 28/30..  Running Loss: 2.553.. \n",
            "Epoch: 28/30..  Running Loss: 2.393.. \n",
            "Epoch: 28/30..  Running Loss: 2.518.. \n",
            "Epoch: 28/30..  Running Loss: 2.273.. \n",
            "Epoch: 28/30..  Running Loss: 1.869.. \n",
            "Epoch: 28/30..  Running Loss: 2.294.. \n",
            "Epoch: 28/30..  Running Loss: 1.818.. \n",
            "Epoch: 28/30..  Running Loss: 2.270.. \n",
            "Epoch: 28/30..  Running Loss: 2.349.. \n",
            "Epoch: 28/30..  Running Loss: 2.885.. \n",
            "Epoch: 28/30..  Running Loss: 2.952.. \n",
            "Epoch: 28/30..  Running Loss: 2.246.. \n",
            "Epoch: 28/30..  Running Loss: 2.303.. \n",
            "Epoch: 28/30..  Running Loss: 2.710.. \n",
            "Epoch: 28/30..  Running Loss: 2.327.. \n",
            "Epoch: 28/30..  Running Loss: 2.472.. \n",
            "Epoch: 28/30..  Running Loss: 2.257.. \n",
            "Epoch: 28/30..  Running Loss: 2.464.. \n",
            "Epoch: 28/30..  Running Loss: 2.561.. \n",
            "Epoch: 28/30..  Running Loss: 2.284.. \n",
            "Epoch: 28/30..  Running Loss: 2.372.. \n",
            "Epoch: 28/30..  Running Loss: 2.417.. \n",
            "Epoch: 28/30..  Running Loss: 2.268.. \n",
            "Epoch: 28/30..  Running Loss: 2.384.. \n",
            "Epoch: 28/30..  Running Loss: 2.548.. \n",
            "Epoch: 28/30..  Running Loss: 2.474.. \n",
            "Epoch: 28/30..  Running Loss: 2.208.. \n",
            "Epoch: 28/30..  Running Loss: 2.274.. \n",
            "Epoch: 28/30..  Running Loss: 2.542.. \n",
            "Epoch: 28/30..  Running Loss: 3.075.. \n",
            "Epoch: 28/30..  Running Loss: 2.349.. \n",
            "Epoch: 28/30..  Running Loss: 2.349.. \n",
            "Epoch: 28/30..  Running Loss: 2.350.. \n",
            "Epoch: 28/30..  Running Loss: 2.249.. \n",
            "Epoch: 28/30..  Running Loss: 2.295.. \n",
            "Epoch: 28/30..  Running Loss: 2.577.. \n",
            "Epoch: 28/30..  Running Loss: 2.987.. \n",
            "Epoch: 28/30..  Running Loss: 2.968.. \n",
            "Epoch: 28/30..  Running Loss: 2.180.. \n",
            "Epoch: 28/30..  Running Loss: 2.439.. \n",
            "Epoch: 28/30..  Running Loss: 2.827.. \n",
            "Epoch: 28/30..  Running Loss: 2.236.. \n",
            "Epoch: 28/30..  Running Loss: 2.502.. \n",
            "Epoch: 28/30..  Running Loss: 2.689.. \n",
            "Epoch: 28/30..  Running Loss: 2.892.. \n",
            "Epoch: 28/30..  Running Loss: 2.014.. \n",
            "Epoch: 28/30..  Running Loss: 2.023.. \n",
            "Epoch: 28/30..  Running Loss: 2.251.. \n",
            "Epoch: 28/30..  Running Loss: 2.986.. \n",
            "Epoch: 28/30..  Running Loss: 2.751.. \n",
            "Epoch: 28/30..  Running Loss: 2.609.. \n",
            "Epoch: 28/30..  Running Loss: 2.818.. \n",
            "Epoch: 28/30..  Running Loss: 2.932.. \n",
            "Epoch: 28/30..  Running Loss: 3.017.. \n",
            "Epoch: 28/30..  Running Loss: 2.425.. \n",
            "Epoch: 28/30..  Running Loss: 2.549.. \n",
            "Epoch: 28/30..  Running Loss: 2.287.. \n",
            "Epoch: 28/30..  Running Loss: 2.142.. \n",
            "Epoch: 28/30..  Running Loss: 2.341.. \n",
            "Epoch: 28/30..  Running Loss: 2.796.. \n",
            "Epoch: 28/30..  Running Loss: 2.247.. \n",
            "Epoch: 28/30..  Running Loss: 1.968.. \n",
            "Epoch: 28/30..  Running Loss: 2.444.. \n",
            "Epoch: 28/30..  Running Loss: 2.333.. \n",
            "Epoch: 28/30..  Running Loss: 2.503.. \n",
            "Epoch: 28/30..  Running Loss: 2.481.. \n",
            "Epoch: 28/30..  Running Loss: 2.617.. \n",
            "Epoch: 28/30..  Running Loss: 2.544.. \n",
            "Epoch: 28/30..  Running Loss: 2.713.. \n",
            "Epoch: 28/30..  Running Loss: 2.633.. \n",
            "Epoch: 28/30..  Running Loss: 2.484.. \n",
            "Epoch: 28/30..  Running Loss: 2.390.. \n",
            "Epoch: 28/30..  Running Loss: 2.323.. \n",
            "Epoch: 28/30..  Running Loss: 2.512.. \n",
            "Epoch: 28/30..  Running Loss: 2.779.. \n",
            "Epoch: 28/30..  Running Loss: 2.779.. \n",
            "Epoch: 28/30..  Running Loss: 2.366.. \n",
            "Epoch: 28/30..  Running Loss: 2.269.. \n",
            "Epoch: 28/30..  Running Loss: 2.140.. \n",
            "Epoch: 28/30..  Running Loss: 2.316.. \n",
            "Epoch: 28/30..  Running Loss: 2.949.. \n",
            "Epoch: 28/30..  Running Loss: 2.758.. \n",
            "Epoch: 28/30..  Running Loss: 2.330.. \n",
            "Epoch: 28/30..  Running Loss: 2.601.. \n",
            "Epoch: 28/30..  Running Loss: 2.500.. \n",
            "Epoch: 28/30..  Running Loss: 2.836.. \n",
            "Epoch: 28/30..  Running Loss: 2.413.. \n",
            "Epoch: 28/30..  Running Loss: 2.432.. \n",
            "Epoch: 28/30..  Running Loss: 2.735.. \n",
            "Epoch: 28/30..  Running Loss: 2.746.. \n",
            "Epoch: 28/30..  Running Loss: 2.705.. \n",
            "Epoch: 28/30..  Running Loss: 2.126.. \n",
            "Epoch: 28/30..  Running Loss: 2.458.. \n",
            "Epoch: 28/30..  Running Loss: 2.760.. \n",
            "Epoch: 28/30..  Running Loss: 2.482.. \n",
            "Epoch: 28/30..  Running Loss: 1.934.. \n",
            "Epoch: 28/30..  Running Loss: 2.465.. \n",
            "Epoch: 28/30..  Running Loss: 2.738.. \n",
            "Epoch: 28/30..  Running Loss: 2.588.. \n",
            "Epoch: 28/30..  Running Loss: 2.473.. \n",
            "Epoch: 28/30..  Running Loss: 2.890.. \n",
            "Epoch: 28/30..  Running Loss: 2.440.. \n",
            "Epoch: 28/30..  Running Loss: 2.400.. \n",
            "Epoch: 28/30..  Running Loss: 2.311.. \n",
            "Epoch: 28/30..  Running Loss: 2.665.. \n",
            "Epoch: 28/30..  Running Loss: 2.647.. \n",
            "Epoch: 28/30..  Running Loss: 2.413.. \n",
            "Epoch: 28/30..  Running Loss: 2.556.. \n",
            "Epoch: 28/30..  Running Loss: 2.284.. \n",
            "Epoch: 28/30..  Running Loss: 2.419.. \n",
            "Epoch: 28/30..  Running Loss: 2.682.. \n",
            "Epoch: 28/30..  Running Loss: 2.747.. \n",
            "Epoch: 28/30..  Running Loss: 2.874.. \n",
            "Epoch: 28/30..  Running Loss: 2.208.. \n",
            "Epoch: 28/30..  Running Loss: 3.006.. \n",
            "Epoch: 28/30..  Running Loss: 2.706.. \n",
            "Epoch: 28/30..  Running Loss: 2.483.. \n",
            "Epoch: 28/30..  Running Loss: 2.756.. \n",
            "Epoch: 28/30..  Running Loss: 2.786.. \n",
            "Epoch: 28/30..  Running Loss: 2.453.. \n",
            "Epoch: 28/30..  Running Loss: 2.162.. \n",
            "Epoch: 28/30..  Running Loss: 2.319.. \n",
            "Epoch: 28/30..  Running Loss: 2.399.. \n",
            "Epoch: 28/30..  Running Loss: 2.833.. \n",
            "Epoch: 28/30..  Running Loss: 2.315.. \n",
            "Epoch: 28/30..  Running Loss: 2.383.. \n",
            "Epoch: 28/30..  Running Loss: 2.512.. \n",
            "Epoch: 28/30..  Running Loss: 2.430.. \n",
            "Epoch: 28/30..  Running Loss: 2.978.. \n",
            "Epoch: 28/30..  Running Loss: 2.255.. \n",
            "Epoch: 28/30..  Running Loss: 2.705.. \n",
            "Epoch: 28/30..  Running Loss: 2.431.. \n",
            "Epoch: 28/30..  Running Loss: 2.625.. \n",
            "Epoch: 28/30..  Running Loss: 3.080.. \n",
            "Epoch: 28/30..  Running Loss: 2.417.. \n",
            "Epoch: 28/30..  Running Loss: 2.441.. \n",
            "Epoch: 28/30..  Running Loss: 2.656.. \n",
            "Epoch: 28/30..  Running Loss: 2.401.. \n",
            "Epoch: 28/30..  Running Loss: 2.663.. \n",
            "Epoch: 28/30..  Running Loss: 2.404.. \n",
            "Epoch: 28/30..  Running Loss: 2.543.. \n",
            "Epoch: 28/30..  Running Loss: 2.649.. \n",
            "Epoch: 28/30..  Running Loss: 2.348.. \n",
            "Epoch: 28/30..  Running Loss: 2.931.. \n",
            "Epoch: 28/30..  Running Loss: 2.354.. \n",
            "Epoch: 28/30..  Running Loss: 2.255.. \n",
            "Epoch: 28/30..  Running Loss: 2.853.. \n",
            "Epoch: 28/30..  Running Loss: 2.438.. \n",
            "Epoch: 28/30..  Running Loss: 2.328.. \n",
            "Epoch: 28/30..  Running Loss: 2.406.. \n",
            "Epoch: 28/30..  Running Loss: 2.054.. \n",
            "Epoch: 28/30..  Running Loss: 2.712.. \n",
            "Epoch: 28/30..  Running Loss: 2.311.. \n",
            "Epoch: 28/30..  Running Loss: 2.752.. \n",
            "Epoch: 28/30..  Running Loss: 2.229.. \n",
            "Epoch: 28/30..  Running Loss: 2.242.. \n",
            "Epoch: 28/30..  Running Loss: 2.287.. \n",
            "Epoch: 28/30..  Running Loss: 2.539.. \n",
            "Epoch: 28/30..  Running Loss: 2.325.. \n",
            "Epoch: 28/30..  Running Loss: 2.527.. \n",
            "Epoch: 28/30..  Running Loss: 2.558.. \n",
            "Epoch: 28/30..  Running Loss: 2.667.. \n",
            "Epoch: 28/30..  Running Loss: 2.029.. \n",
            "Epoch: 28/30..  Running Loss: 1.683.. \n",
            "Epoch: 28/30..  Running Loss: 1.980.. \n",
            "Epoch: 28/30..  Running Loss: 2.126.. \n",
            "Epoch: 28/30..  Running Loss: 2.459.. \n",
            "Epoch: 28/30..  Running Loss: 2.153.. \n",
            "Epoch: 28/30..  Running Loss: 2.356.. \n",
            "Epoch: 28/30..  Running Loss: 2.464.. \n",
            "Epoch: 28/30..  Running Loss: 2.767.. \n",
            "Epoch: 28/30..  Running Loss: 2.550.. \n",
            "Epoch: 28/30..  Running Loss: 2.432.. \n",
            "Epoch: 28/30..  Running Loss: 2.263.. \n",
            "Epoch: 28/30..  Running Loss: 2.698.. \n",
            "Epoch: 28/30..  Running Loss: 2.101.. \n",
            "Epoch: 28/30..  Running Loss: 2.403.. \n",
            "Epoch: 28/30..  Running Loss: 2.362.. \n",
            "Epoch: 28/30..  Running Loss: 2.501.. \n",
            "Epoch: 28/30..  Running Loss: 2.519.. \n",
            "Epoch: 28/30..  Running Loss: 2.240.. \n",
            "Epoch: 28/30..  Running Loss: 2.264.. \n",
            "Epoch: 28/30..  Running Loss: 2.571.. \n",
            "Epoch: 28/30..  Running Loss: 2.472.. \n",
            "Epoch: 28/30..  Running Loss: 2.717.. \n",
            "Epoch: 28/30..  Running Loss: 2.639.. \n",
            "Epoch: 28/30..  Running Loss: 2.236.. \n",
            "Epoch: 28/30..  Running Loss: 2.392.. \n",
            "Epoch: 28/30..  Running Loss: 2.330.. \n",
            "Epoch: 28/30..  Running Loss: 2.131.. \n",
            "Epoch: 28/30..  Running Loss: 2.515.. \n",
            "Epoch: 28/30..  Running Loss: 2.405.. \n",
            "Epoch: 28/30..  Running Loss: 2.136.. \n",
            "Epoch: 28/30..  Running Loss: 1.885.. \n",
            "Epoch: 28/30..  Running Loss: 2.047.. \n",
            "Epoch: 28/30..  Running Loss: 2.337.. \n",
            "Epoch: 28/30..  Running Loss: 2.334.. \n",
            "Epoch: 28/30..  Running Loss: 1.269.. \n",
            "Epoch: 28/30..  Running Loss: 2.087.. \n",
            "Epoch: 28/30..  Running Loss: 2.179.. \n",
            "Epoch: 28/30..  Running Loss: 2.606.. \n",
            "Epoch: 28/30..  Running Loss: 1.163.. \n",
            "Epoch: 28/30..  Running Loss: 2.068.. \n",
            "Epoch: 28/30..  Running Loss: 1.711.. \n",
            "Epoch: 28/30..  Running Loss: 2.117.. \n",
            "Epoch: 28/30..  Running Loss: 1.071.. \n",
            "Epoch: 28/30..  Running Loss: 2.108.. \n",
            "Epoch: 28/30..  Running Loss: 2.275.. \n",
            "Epoch: 28/30..  Running Loss: 2.128.. \n",
            "Epoch: 28/30..  Running Loss: 1.421.. \n",
            "Epoch: 28/30..  Running Loss: 2.375.. \n",
            "Epoch: 28/30..  Running Loss: 2.361.. \n",
            "Epoch: 28/30..  Running Loss: 2.370.. \n",
            "Epoch: 28/30..  Running Loss: 2.624.. \n",
            "Epoch: 28/30..  Running Loss: 2.797.. \n",
            "Epoch: 28/30..  Running Loss: 2.461.. \n",
            "Epoch: 28/30..  Running Loss: 2.641.. \n",
            "Epoch: 28/30..  Running Loss: 2.178.. \n",
            "Epoch: 28/30..  Running Loss: 2.361.. \n",
            "Epoch: 28/30..  Running Loss: 2.196.. \n",
            "Epoch: 28/30..  Running Loss: 2.748.. \n",
            "Epoch: 28/30..  Running Loss: 2.100.. \n",
            "Epoch: 28/30..  Running Loss: 2.356.. \n",
            "Epoch: 28/30..  Running Loss: 2.506.. \n",
            "Epoch: 28/30..  Running Loss: 2.455.. \n",
            "Epoch: 28/30..  Running Loss: 2.005.. \n",
            "Epoch: 28/30..  Running Loss: 1.721.. \n",
            "Epoch: 28/30..  Running Loss: 2.722.. \n",
            "Epoch: 28/30..  Running Loss: 2.533.. \n",
            "Epoch: 28/30..  Running Loss: 1.863.. \n",
            "Epoch: 28/30..  Running Loss: 2.413.. \n",
            "Epoch: 28/30..  Running Loss: 2.766.. \n",
            "Epoch: 28/30..  Running Loss: 2.849.. \n",
            "Epoch: 28/30..  Running Loss: 2.671.. \n",
            "Epoch: 28/30..  Running Loss: 2.540.. \n",
            "Epoch: 28/30..  Running Loss: 2.668.. \n",
            "Epoch: 28/30..  Running Loss: 2.533.. \n",
            "Epoch: 28/30..  Running Loss: 2.630.. \n",
            "Epoch: 28/30..  Running Loss: 2.835.. \n",
            "Epoch: 28/30..  Running Loss: 2.272.. \n",
            "Epoch: 28/30..  Running Loss: 2.149.. \n",
            "Epoch: 28/30..  Running Loss: 2.485.. \n",
            "Epoch: 28/30..  Running Loss: 2.229.. \n",
            "Epoch: 28/30..  Running Loss: 2.930.. \n",
            "Epoch: 28/30..  Running Loss: 2.360.. \n",
            "Epoch: 28/30..  Running Loss: 2.422.. \n",
            "Epoch: 28/30..  Running Loss: 2.133.. \n",
            "Epoch: 28/30..  Running Loss: 2.103.. \n",
            "Epoch: 28/30..  Running Loss: 1.885.. \n",
            "Epoch: 28/30..  Running Loss: 2.601.. \n",
            "Epoch: 28/30..  Running Loss: 2.217.. \n",
            "Epoch: 28/30..  Running Loss: 2.734.. \n",
            "Epoch: 28/30..  Running Loss: 3.023.. \n",
            "Epoch: 28/30..  Running Loss: 2.313.. \n",
            "Epoch: 28/30..  Running Loss: 2.403.. \n",
            "Epoch: 28/30..  Running Loss: 2.239.. \n",
            "Epoch: 28/30..  Running Loss: 1.895.. \n",
            "Epoch: 28/30..  Running Loss: 1.696.. \n",
            "Epoch: 28/30..  Running Loss: 1.451.. \n",
            "Epoch: 28/30..  Running Loss: 2.371.. \n",
            "Epoch: 28/30..  Running Loss: 1.627.. \n",
            "Epoch: 28/30..  Running Loss: 2.016.. \n",
            "Epoch: 28/30..  Running Loss: 2.157.. \n",
            "Epoch: 28/30..  Running Loss: 2.200.. \n",
            "Epoch: 28/30..  Running Loss: 2.489.. \n",
            "Epoch: 28/30..  Running Loss: 2.931.. \n",
            "Epoch: 28/30..  Running Loss: 2.499.. \n",
            "Epoch: 28/30..  Running Loss: 2.600.. \n",
            "Epoch: 28/30..  Running Loss: 2.381.. \n",
            "Epoch: 28/30..  Running Loss: 2.584.. \n",
            "Epoch: 28/30..  Running Loss: 2.382.. \n",
            "Epoch: 28/30..  Running Loss: 2.829.. \n",
            "Epoch: 28/30..  Running Loss: 2.435.. \n",
            "Epoch: 28/30..  Running Loss: 2.335.. \n",
            "Epoch: 28/30..  Running Loss: 2.709.. \n",
            "Epoch: 28/30..  Running Loss: 2.709.. \n",
            "Epoch: 28/30..  Running Loss: 2.433.. \n",
            "Epoch: 28/30..  Running Loss: 2.172.. \n",
            "Epoch: 28/30..  Running Loss: 2.299.. \n",
            "Epoch: 28/30..  Running Loss: 2.901.. \n",
            "Epoch: 28/30..  Running Loss: 1.853.. \n",
            "Epoch: 28/30..  Running Loss: 2.101.. \n",
            "Epoch: 28/30..  Running Loss: 2.251.. \n",
            "Epoch: 28/30..  Running Loss: 2.419.. \n",
            "Epoch: 28/30..  Running Loss: 2.274.. \n",
            "Epoch: 28/30..  Running Loss: 2.140.. \n",
            "Epoch: 28/30..  Running Loss: 3.019.. \n",
            "Epoch: 28/30..  Running Loss: 2.451.. \n",
            "Epoch: 28/30..  Running Loss: 2.526.. \n",
            "Epoch: 28/30..  Running Loss: 2.454.. \n",
            "Epoch: 28/30..  Running Loss: 2.672.. \n",
            "Epoch: 28/30..  Running Loss: 2.259.. \n",
            "Epoch: 28/30..  Running Loss: 2.398.. \n",
            "Epoch: 28/30..  Running Loss: 2.286.. \n",
            "Epoch: 28/30..  Running Loss: 2.436.. \n",
            "Epoch: 28/30..  Running Loss: 2.739.. \n",
            "Epoch: 28/30..  Running Loss: 2.565.. \n",
            "Epoch: 28/30..  Running Loss: 2.414.. \n",
            "Epoch: 28/30..  Running Loss: 2.347.. \n",
            "Epoch: 28/30..  Running Loss: 2.217.. \n",
            "Epoch: 28/30..  Running Loss: 2.502.. \n",
            "Epoch: 28/30..  Running Loss: 2.849.. \n",
            "Epoch: 28/30..  Running Loss: 2.654.. \n",
            "Epoch: 28/30..  Running Loss: 2.237.. \n",
            "Epoch: 28/30..  Running Loss: 2.831.. \n",
            "Epoch: 28/30..  Running Loss: 2.193.. \n",
            "Epoch: 28/30..  Running Loss: 2.271.. \n",
            "Epoch: 28/30..  Running Loss: 2.074.. \n",
            "Epoch: 28/30..  Running Loss: 2.340.. \n",
            "Epoch: 28/30..  Running Loss: 1.708.. \n",
            "Epoch: 28/30..  Running Loss: 2.749.. \n",
            "Epoch: 28/30..  Running Loss: 2.678.. \n",
            "Epoch: 28/30..  Running Loss: 2.211.. \n",
            "Epoch: 28/30..  Running Loss: 2.619.. \n",
            "Epoch: 28/30..  Running Loss: 2.578.. \n",
            "Epoch: 28/30..  Running Loss: 2.604.. \n",
            "Epoch: 28/30..  Running Loss: 2.662.. \n",
            "Epoch: 28/30..  Running Loss: 2.260.. \n",
            "Epoch: 28/30..  Running Loss: 2.529.. \n",
            "Epoch: 28/30..  Running Loss: 2.418.. \n",
            "Epoch: 28/30..  Running Loss: 1.818.. \n",
            "Epoch: 28/30..  Running Loss: 2.524.. \n",
            "Epoch: 28/30..  Running Loss: 2.296.. \n",
            "Epoch: 28/30..  Running Loss: 2.663.. \n",
            "Epoch: 28/30..  Running Loss: 2.296.. \n",
            "Epoch: 28/30..  Running Loss: 2.535.. \n",
            "Epoch: 28/30..  Running Loss: 2.387.. \n",
            "Epoch: 28/30..  Running Loss: 2.698.. \n",
            "Epoch: 28/30..  Running Loss: 2.583.. \n",
            "Epoch: 28/30..  Running Loss: 2.474.. \n",
            "Epoch: 28/30..  Running Loss: 2.663.. \n",
            "Epoch: 28/30..  Running Loss: 2.337.. \n",
            "Epoch: 28/30..  Running Loss: 2.402.. \n",
            "Epoch: 28/30..  Running Loss: 2.107.. \n",
            "Epoch: 28/30..  Running Loss: 2.730.. \n",
            "Epoch: 28/30..  Running Loss: 2.572.. \n",
            "Epoch: 28/30..  Running Loss: 2.359.. \n",
            "Epoch: 28/30..  Running Loss: 2.460.. \n",
            "Epoch: 28/30..  Running Loss: 2.377.. \n",
            "Epoch: 28/30..  Running Loss: 2.612.. \n",
            "Epoch: 28/30..  Running Loss: 2.450.. \n",
            "Epoch: 28/30..  Running Loss: 2.536.. \n",
            "Epoch: 28/30..  Running Loss: 2.517.. \n",
            "Epoch: 28/30..  Running Loss: 2.807.. \n",
            "Epoch: 28/30..  Running Loss: 2.581.. \n",
            "Epoch: 28/30..  Running Loss: 2.174.. \n",
            "Epoch: 28/30..  Running Loss: 2.388.. \n",
            "Epoch: 28/30..  Running Loss: 2.570.. \n",
            "Epoch: 28/30..  Running Loss: 2.770.. \n",
            "Epoch: 28/30..  Running Loss: 2.152.. \n",
            "Epoch: 28/30..  Running Loss: 2.525.. \n",
            "Epoch: 28/30..  Running Loss: 2.717.. \n",
            "Epoch: 28/30..  Running Loss: 2.152.. \n",
            "Epoch: 28/30..  Running Loss: 1.957.. \n",
            "Epoch: 28/30..  Running Loss: 2.793.. \n",
            "Epoch: 28/30..  Running Loss: 2.536.. \n",
            "Epoch: 28/30..  Running Loss: 2.714.. \n",
            "Epoch: 28/30..  Running Loss: 2.318.. \n",
            "Epoch: 28/30..  Running Loss: 1.854.. \n",
            "Epoch: 28/30..  Running Loss: 2.439.. \n",
            "Epoch: 28/30..  Running Loss: 2.721.. \n",
            "Epoch: 28/30..  Running Loss: 2.133.. \n",
            "Epoch: 28/30..  Running Loss: 2.293.. \n",
            "Epoch: 28/30..  Running Loss: 2.397.. \n",
            "Epoch: 28/30..  Running Loss: 2.620.. \n",
            "Epoch: 28/30..  Running Loss: 2.507.. \n",
            "Epoch: 28/30..  Running Loss: 2.387.. \n",
            "Epoch: 28/30..  Running Loss: 2.513.. \n",
            "Epoch: 28/30..  Running Loss: 2.264.. \n",
            "Epoch: 28/30..  Running Loss: 2.153.. \n",
            "Epoch: 28/30..  Running Loss: 2.301.. \n",
            "Epoch: 28/30..  Running Loss: 2.310.. \n",
            "Epoch: 28/30..  Running Loss: 2.095.. \n",
            "Epoch: 28/30..  Running Loss: 2.261.. \n",
            "Epoch: 28/30..  Running Loss: 2.346.. \n",
            "Epoch: 28/30..  Running Loss: 2.316.. \n",
            "Epoch: 28/30..  Running Loss: 2.445.. \n",
            "Epoch: 28/30..  Running Loss: 2.710.. \n",
            "Epoch: 28/30..  Running Loss: 2.510.. \n",
            "Epoch: 28/30..  Running Loss: 2.497.. \n",
            "Epoch: 28/30..  Running Loss: 2.329.. \n",
            "Epoch: 28/30..  Running Loss: 2.613.. \n",
            "Epoch: 28/30..  Running Loss: 2.728.. \n",
            "Epoch: 28/30..  Running Loss: 2.571.. \n",
            "Epoch: 28/30..  Running Loss: 2.562.. \n",
            "Epoch: 28/30..  Running Loss: 2.388.. \n",
            "Epoch: 28/30..  Running Loss: 2.077.. \n",
            "Epoch: 28/30..  Running Loss: 2.404.. \n",
            "Epoch: 28/30..  Running Loss: 2.614.. \n",
            "Epoch: 28/30..  Running Loss: 2.497.. \n",
            "Epoch: 28/30..  Running Loss: 2.225.. \n",
            "Epoch: 28/30..  Running Loss: 2.677.. \n",
            "Epoch: 28/30..  Running Loss: 2.400.. \n",
            "Epoch: 28/30..  Running Loss: 1.902.. \n",
            "Epoch: 28/30..  Running Loss: 2.503.. \n",
            "Epoch: 28/30..  Running Loss: 2.663.. \n",
            "Epoch: 28/30..  Running Loss: 2.137.. \n",
            "Epoch: 28/30..  Running Loss: 2.625.. \n",
            "Epoch: 28/30..  Running Loss: 2.475.. \n",
            "Epoch: 28/30..  Running Loss: 2.634.. \n",
            "Epoch: 28/30..  Running Loss: 2.446.. \n",
            "Epoch: 28/30..  Running Loss: 2.836.. \n",
            "Epoch: 28/30..  Running Loss: 2.606.. \n",
            "Epoch: 28/30..  Running Loss: 2.427.. \n",
            "Epoch: 28/30..  Running Loss: 2.516.. \n",
            "Epoch: 28/30..  Running Loss: 2.280.. \n",
            "Epoch: 28/30..  Running Loss: 2.408.. \n",
            "Epoch: 28/30..  Running Loss: 2.632.. \n",
            "Epoch: 28/30..  Running Loss: 2.381.. \n",
            "Epoch: 28/30..  Running Loss: 2.486.. \n",
            "Epoch: 28/30..  Running Loss: 2.218.. \n",
            "Epoch: 28/30..  Running Loss: 2.463.. \n",
            "Epoch: 28/30..  Running Loss: 2.888.. \n",
            "Epoch: 28/30..  Running Loss: 2.780.. \n",
            "Epoch: 28/30..  Running Loss: 2.261.. \n",
            "Epoch: 28/30..  Running Loss: 2.236.. \n",
            "Epoch: 28/30..  Running Loss: 1.911.. \n",
            "Epoch: 28/30..  Running Loss: 2.975.. \n",
            "Epoch: 28/30..  Running Loss: 2.519.. \n",
            "Epoch: 28/30..  Running Loss: 2.681.. \n",
            "Epoch: 28/30..  Running Loss: 2.052.. \n",
            "Epoch: 28/30..  Running Loss: 2.010.. \n",
            "Epoch: 28/30..  Running Loss: 2.363.. \n",
            "Epoch: 28/30..  Running Loss: 2.407.. \n",
            "Epoch: 28/30..  Running Loss: 1.855.. \n",
            "Epoch: 28/30..  Running Loss: 1.915.. \n",
            "Epoch: 28/30..  Running Loss: 1.717.. \n",
            "Epoch: 28/30..  Running Loss: 2.682.. \n",
            "Epoch: 28/30..  Running Loss: 2.878.. \n",
            "Epoch: 28/30..  Running Loss: 2.698.. \n",
            "Epoch: 28/30..  Running Loss: 2.914.. \n",
            "Epoch: 28/30..  Running Loss: 2.468.. \n",
            "Epoch: 28/30..  Running Loss: 2.402.. \n",
            "Epoch: 28/30..  Running Loss: 2.774.. \n",
            "Epoch: 28/30..  Running Loss: 2.209.. \n",
            "Epoch: 28/30..  Running Loss: 2.557.. \n",
            "Epoch: 28/30..  Running Loss: 2.217.. \n",
            "Epoch: 28/30..  Running Loss: 2.620.. \n",
            "Epoch: 28/30..  Running Loss: 2.298.. \n",
            "Epoch: 28/30..  Running Loss: 2.301.. \n",
            "Epoch: 28/30..  Running Loss: 2.095.. \n",
            "Epoch: 28/30..  Running Loss: 2.668.. \n",
            "Epoch: 28/30..  Running Loss: 2.497.. \n",
            "Epoch: 28/30..  Running Loss: 2.611.. \n",
            "Epoch: 28/30..  Running Loss: 2.583.. \n",
            "Epoch: 28/30..  Running Loss: 2.318.. \n",
            "Epoch: 28/30..  Running Loss: 2.597.. \n",
            "Epoch: 28/30..  Running Loss: 2.411.. \n",
            "Epoch: 28/30..  Running Loss: 2.707.. \n",
            "Epoch: 28/30..  Running Loss: 2.089.. \n",
            "Epoch: 28/30..  Running Loss: 2.486.. \n",
            "Epoch: 28/30..  Running Loss: 2.608.. \n",
            "Epoch: 28/30..  Running Loss: 2.367.. \n",
            "Epoch: 28/30..  Running Loss: 2.482.. \n",
            "Epoch: 28/30..  Running Loss: 2.837.. \n",
            "Epoch: 28/30..  Running Loss: 2.859.. \n",
            "Epoch: 28/30..  Running Loss: 2.751.. \n",
            "Epoch: 28/30..  Running Loss: 2.358.. \n",
            "Epoch: 28/30..  Running Loss: 2.844.. \n",
            "Epoch: 28/30..  Running Loss: 2.319.. \n",
            "Epoch: 28/30..  Running Loss: 2.409.. \n",
            "Epoch: 28/30..  Running Loss: 2.552.. \n",
            "Epoch: 28/30..  Running Loss: 2.561.. \n",
            "Epoch: 28/30..  Running Loss: 2.271.. \n",
            "Epoch: 28/30..  Running Loss: 2.549.. \n",
            "Epoch: 28/30..  Running Loss: 2.307.. \n",
            "Epoch: 28/30..  Running Loss: 2.492.. \n",
            "Epoch: 28/30..  Running Loss: 2.684.. \n",
            "Epoch: 28/30..  Running Loss: 2.666.. \n",
            "Epoch: 28/30..  Running Loss: 2.690.. \n",
            "Epoch: 28/30..  Running Loss: 2.590.. \n",
            "Epoch: 28/30..  Running Loss: 2.820.. \n",
            "Epoch: 28/30..  Running Loss: 2.356.. \n",
            "Epoch: 28/30..  Running Loss: 2.696.. \n",
            "Epoch: 28/30..  Running Loss: 2.573.. \n",
            "Epoch: 28/30..  Running Loss: 2.377.. \n",
            "Epoch: 28/30..  Running Loss: 2.518.. \n",
            "Epoch: 28/30..  Running Loss: 2.862.. \n",
            "Epoch: 28/30..  Running Loss: 2.639.. \n",
            "Epoch: 28/30..  Running Loss: 2.543.. \n",
            "Epoch: 28/30..  Running Loss: 2.414.. \n",
            "Epoch: 28/30..  Running Loss: 2.822.. \n",
            "Epoch: 28/30..  Running Loss: 2.295.. \n",
            "Epoch: 28/30..  Running Loss: 2.346.. \n",
            "Epoch: 28/30..  Running Loss: 2.418.. \n",
            "Epoch: 28/30..  Running Loss: 2.481.. \n",
            "Epoch: 28/30..  Running Loss: 2.100.. \n",
            "Epoch: 28/30..  Running Loss: 2.071.. \n",
            "Epoch: 28/30..  Running Loss: 2.112.. \n",
            "Epoch: 28/30..  Running Loss: 2.248.. \n",
            "Epoch: 28/30..  Running Loss: 1.755.. \n",
            "Epoch: 28/30..  Running Loss: 1.782.. \n",
            "Epoch: 28/30..  Running Loss: 2.079.. \n",
            "Epoch: 28/30..  Running Loss: 2.339.. \n",
            "Epoch: 28/30..  Running Loss: 2.147.. \n",
            "Epoch: 28/30..  Running Loss: 2.543.. \n",
            "Epoch: 28/30..  Running Loss: 2.807.. \n",
            "Epoch: 28/30..  Running Loss: 2.400.. \n",
            "Epoch: 28/30..  Running Loss: 2.693.. \n",
            "Epoch: 28/30..  Running Loss: 2.283.. \n",
            "Epoch: 28/30..  Running Loss: 2.132.. \n",
            "Epoch: 28/30..  Running Loss: 2.281.. \n",
            "Epoch: 28/30..  Running Loss: 2.416.. \n",
            "Epoch: 28/30..  Running Loss: 2.703.. \n",
            "Epoch: 28/30..  Running Loss: 2.545.. \n",
            "Epoch: 28/30..  Running Loss: 2.426.. \n",
            "Epoch: 28/30..  Running Loss: 2.274.. \n",
            "Epoch: 28/30..  Running Loss: 2.423.. \n",
            "Epoch: 28/30..  Running Loss: 2.243.. \n",
            "Epoch: 28/30..  Running Loss: 2.400.. \n",
            "Epoch: 28/30..  Running Loss: 2.041.. \n",
            "Epoch: 28/30..  Running Loss: 2.291.. \n",
            "Epoch: 28/30..  Running Loss: 2.553.. \n",
            "Epoch: 28/30..  Running Loss: 2.757.. \n",
            "Epoch: 28/30..  Running Loss: 2.404.. \n",
            "Epoch: 28/30..  Running Loss: 2.299.. \n",
            "Epoch: 28/30..  Running Loss: 2.617.. \n",
            "Epoch: 28/30..  Running Loss: 2.368.. \n",
            "Epoch: 28/30..  Running Loss: 2.547.. \n",
            "Epoch: 28/30..  Running Loss: 2.626.. \n",
            "Epoch: 28/30..  Running Loss: 2.199.. \n",
            "Epoch: 28/30..  Running Loss: 2.090.. \n",
            "Epoch: 28/30..  Running Loss: 2.588.. \n",
            "Epoch: 28/30..  Running Loss: 2.733.. \n",
            "Epoch: 28/30..  Running Loss: 3.257.. \n",
            "Epoch: 28/30..  Running Loss: 2.165.. \n",
            "Epoch: 28/30..  Running Loss: 2.458.. \n",
            "Epoch: 28/30..  Running Loss: 2.037.. \n",
            "Epoch: 28/30..  Running Loss: 2.268.. \n",
            "Epoch: 28/30..  Running Loss: 2.201.. \n",
            "Epoch: 28/30..  Running Loss: 2.570.. \n",
            "Epoch: 28/30..  Running Loss: 2.527.. \n",
            "Epoch: 28/30..  Running Loss: 2.499.. \n",
            "Epoch: 28/30..  Running Loss: 2.451.. \n",
            "Epoch: 28/30..  Running Loss: 2.720.. \n",
            "Epoch: 28/30..  Running Loss: 2.682.. \n",
            "Epoch: 28/30..  Running Loss: 2.360.. \n",
            "Epoch: 28/30..  Running Loss: 2.588.. \n",
            "Epoch: 28/30..  Running Loss: 2.430.. \n",
            "Epoch: 28/30..  Running Loss: 2.401.. \n",
            "Epoch: 28/30..  Running Loss: 2.306.. \n",
            "Epoch: 28/30..  Running Loss: 2.501.. \n",
            "Epoch: 28/30..  Running Loss: 2.209.. \n",
            "Epoch: 28/30..  Running Loss: 2.534.. \n",
            "Epoch: 28/30..  Running Loss: 1.685.. \n",
            "Epoch: 28/30..  Running Loss: 2.541.. \n",
            "Epoch: 28/30..  Running Loss: 2.788.. \n",
            "Epoch: 28/30..  Running Loss: 1.658.. \n",
            "Epoch: 28/30..  Running Loss: 2.141.. \n",
            "Epoch: 28/30..  Running Loss: 2.103.. \n",
            "Epoch: 28/30..  Running Loss: 2.743.. \n",
            "Epoch: 28/30..  Running Loss: 1.601.. \n",
            "Epoch: 28/30..  Running Loss: 2.250.. \n",
            "Epoch: 28/30..  Running Loss: 2.384.. \n",
            "Epoch: 28/30..  Running Loss: 1.935.. \n",
            "Epoch: 28/30..  Running Loss: 2.443.. \n",
            "Epoch: 28/30..  Running Loss: 2.303.. \n",
            "Epoch: 28/30..  Running Loss: 2.364.. \n",
            "Epoch: 28/30..  Running Loss: 2.622.. \n",
            "Epoch: 28/30..  Running Loss: 2.604.. \n",
            "Epoch: 28/30..  Running Loss: 2.168.. \n",
            "Epoch: 28/30..  Running Loss: 1.788.. \n",
            "Epoch: 28/30..  Running Loss: 2.342.. \n",
            "Epoch: 28/30..  Running Loss: 2.763.. \n",
            "Epoch: 28/30..  Running Loss: 2.605.. \n",
            "Epoch: 28/30..  Running Loss: 2.575.. \n",
            "Epoch: 28/30..  Running Loss: 2.587.. \n",
            "Epoch: 28/30..  Running Loss: 2.635.. \n",
            "Epoch: 28/30..  Running Loss: 2.596.. \n",
            "Epoch: 28/30..  Running Loss: 2.144.. \n",
            "Epoch: 28/30..  Running Loss: 2.214.. \n",
            "Epoch: 28/30..  Running Loss: 2.428.. \n",
            "Epoch: 28/30..  Running Loss: 2.406.. \n",
            "Epoch: 28/30..  Running Loss: 2.355.. \n",
            "Epoch: 28/30..  Running Loss: 2.517.. \n",
            "Epoch: 28/30..  Running Loss: 2.489.. \n",
            "Epoch: 28/30..  Running Loss: 2.926.. \n",
            "Epoch: 28/30..  Running Loss: 2.233.. \n",
            "Epoch: 28/30..  Running Loss: 2.755.. \n",
            "Epoch: 28/30..  Running Loss: 2.059.. \n",
            "Epoch: 28/30..  Running Loss: 2.329.. \n",
            "Epoch: 28/30..  Running Loss: 1.929.. \n",
            "Epoch: 28/30..  Running Loss: 2.448.. \n",
            "Epoch: 28/30..  Running Loss: 2.502.. \n",
            "Epoch: 28/30..  Running Loss: 2.702.. \n",
            "Epoch: 28/30..  Running Loss: 1.829.. \n",
            "Epoch: 28/30..  Running Loss: 2.061.. \n",
            "Epoch: 28/30..  Running Loss: 1.472.. \n",
            "Epoch: 28/30..  Running Loss: 2.152.. \n",
            "Epoch: 28/30..  Running Loss: 2.588.. \n",
            "Epoch: 28/30..  Running Loss: 2.321.. \n",
            "Epoch: 28/30..  Running Loss: 2.473.. \n",
            "Epoch: 28/30..  Running Loss: 1.847.. \n",
            "Epoch: 28/30..  Running Loss: 2.544.. \n",
            "Epoch: 28/30..  Running Loss: 2.904.. \n",
            "Epoch: 28/30..  Running Loss: 2.611.. \n",
            "Epoch: 28/30..  Running Loss: 2.559.. \n",
            "Epoch: 28/30..  Running Loss: 2.301.. \n",
            "Epoch: 28/30..  Running Loss: 2.326.. \n",
            "Epoch: 28/30..  Running Loss: 2.537.. \n",
            "Epoch: 28/30..  Running Loss: 2.195.. \n",
            "Epoch: 28/30..  Running Loss: 2.520.. \n",
            "Epoch: 28/30..  Running Loss: 2.044.. \n",
            "Epoch: 28/30..  Running Loss: 2.349.. \n",
            "Epoch: 28/30..  Running Loss: 2.768.. \n",
            "Epoch: 28/30..  Running Loss: 2.287.. \n",
            "Epoch: 28/30..  Running Loss: 2.333.. \n",
            "Epoch: 28/30..  Running Loss: 2.617.. \n",
            "Epoch: 28/30..  Running Loss: 2.315.. \n",
            "Epoch: 28/30..  Running Loss: 2.747.. \n",
            "Epoch: 28/30..  Running Loss: 2.327.. \n",
            "Epoch: 28/30..  Running Loss: 2.896.. \n",
            "Epoch: 28/30..  Running Loss: 2.459.. \n",
            "Epoch: 28/30..  Running Loss: 2.814.. \n",
            "Epoch: 28/30..  Running Loss: 2.737.. \n",
            "Epoch: 28/30..  Running Loss: 2.070.. \n",
            "Epoch: 28/30..  Running Loss: 2.216.. \n",
            "Epoch: 28/30..  Running Loss: 2.284.. \n",
            "Epoch: 28/30..  Running Loss: 1.061.. \n",
            "Epoch: 28/30..  Running Loss: 2.339.. \n",
            "Epoch: 28/30..  Running Loss: 2.515.. \n",
            "Epoch: 28/30..  Running Loss: 2.318.. \n",
            "Epoch: 28/30..  Running Loss: 2.736.. \n",
            "Epoch: 28/30..  Running Loss: 2.447.. \n",
            "Epoch: 28/30..  Running Loss: 2.228.. \n",
            "Epoch: 28/30..  Running Loss: 2.386.. \n",
            "Epoch: 28/30..  Running Loss: 1.939.. \n",
            "Epoch: 28/30..  Running Loss: 1.760.. \n",
            "Epoch: 28/30..  Running Loss: 2.760.. \n",
            "Epoch: 28/30..  Running Loss: 2.705.. \n",
            "Epoch: 28/30..  Running Loss: 2.395.. \n",
            "Epoch: 28/30..  Running Loss: 2.637.. \n",
            "Epoch: 28/30..  Running Loss: 1.511.. \n",
            "Epoch: 28/30..  Running Loss: 2.465.. \n",
            "Epoch: 28/30..  Running Loss: 2.123.. \n",
            "Epoch: 28/30..  Running Loss: 2.357.. \n",
            "Epoch: 28/30..  Running Loss: 2.573.. \n",
            "Epoch: 28/30..  Running Loss: 2.665.. \n",
            "Epoch: 28/30..  Running Loss: 2.628.. \n",
            "Epoch: 28/30..  Running Loss: 2.766.. \n",
            "Epoch: 28/30..  Running Loss: 2.472.. \n",
            "Epoch: 28/30..  Running Loss: 2.791.. \n",
            "Epoch: 28/30..  Running Loss: 2.551.. \n",
            "Epoch: 28/30..  Running Loss: 2.094.. \n",
            "Epoch: 28/30..  Running Loss: 2.206.. \n",
            "Epoch: 28/30..  Running Loss: 2.609.. \n",
            "Epoch: 28/30..  Running Loss: 2.562.. \n",
            "Epoch: 28/30..  Running Loss: 2.292.. \n",
            "Epoch: 28/30..  Running Loss: 2.372.. \n",
            "Epoch: 28/30..  Running Loss: 2.323.. \n",
            "Epoch: 28/30..  Running Loss: 2.793.. \n",
            "Epoch: 28/30..  Running Loss: 2.440.. \n",
            "Epoch: 28/30..  Running Loss: 2.880.. \n",
            "Epoch: 28/30..  Running Loss: 2.246.. \n",
            "Epoch: 28/30..  Running Loss: 1.844.. \n",
            "Epoch: 28/30..  Running Loss: 2.231.. \n",
            "Epoch: 28/30..  Running Loss: 2.594.. \n",
            "Epoch: 28/30..  Running Loss: 2.168.. \n",
            "Epoch: 28/30..  Running Loss: 2.647.. \n",
            "Epoch: 28/30..  Running Loss: 2.545.. \n",
            "Epoch: 28/30..  Running Loss: 2.583.. \n",
            "Epoch: 28/30..  Running Loss: 2.999.. \n",
            "Epoch: 28/30..  Running Loss: 2.578.. \n",
            "Epoch: 28/30..  Running Loss: 2.327.. \n",
            "Epoch: 28/30..  Running Loss: 2.602.. \n",
            "Epoch: 28/30..  Running Loss: 1.931.. \n",
            "Epoch: 28/30..  Running Loss: 2.789.. \n",
            "Epoch: 28/30..  Running Loss: 2.427.. \n",
            "Epoch: 28/30..  Running Loss: 2.613.. \n",
            "Epoch: 28/30..  Running Loss: 2.319.. \n",
            "Epoch: 28/30..  Running Loss: 2.313.. \n",
            "Epoch: 28/30..  Running Loss: 2.433.. \n",
            "Epoch: 28/30..  Running Loss: 2.435.. \n",
            "Epoch: 28/30..  Running Loss: 2.395.. \n",
            "Epoch: 28/30..  Running Loss: 2.360.. \n",
            "Epoch: 28/30..  Running Loss: 2.700.. \n",
            "Epoch: 28/30..  Running Loss: 2.396.. \n",
            "Epoch: 28/30..  Running Loss: 2.425.. \n",
            "Epoch: 28/30..  Running Loss: 2.450.. \n",
            "Epoch: 28/30..  Running Loss: 2.653.. \n",
            "Epoch: 28/30..  Running Loss: 2.573.. \n",
            "Epoch: 28/30..  Running Loss: 2.427.. \n",
            "Epoch: 28/30..  Running Loss: 2.460.. \n",
            "Epoch: 28/30..  Running Loss: 2.383.. \n",
            "Epoch: 28/30..  Running Loss: 2.611.. \n",
            "Epoch: 28/30..  Running Loss: 2.753.. \n",
            "Epoch: 28/30..  Running Loss: 2.375.. \n",
            "Epoch: 28/30..  Running Loss: 2.835.. \n",
            "Epoch: 28/30..  Running Loss: 2.471.. \n",
            "Epoch: 28/30..  Running Loss: 2.243.. \n",
            "Epoch: 28/30..  Running Loss: 2.508.. \n",
            "Epoch: 28/30..  Running Loss: 2.961.. \n",
            "Epoch: 28/30..  Running Loss: 2.406.. \n",
            "Epoch: 28/30..  Running Loss: 2.726.. \n",
            "Epoch: 28/30..  Running Loss: 2.348.. \n",
            "Epoch: 28/30..  Running Loss: 2.161.. \n",
            "Epoch: 28/30..  Running Loss: 2.080.. \n",
            "Epoch: 28/30..  Running Loss: 0.691.. \n",
            "Epoch: 28/30..  Running Loss: 1.778.. \n",
            "Epoch: 28/30..  Running Loss: 2.057.. \n",
            "Epoch: 28/30..  Running Loss: 1.052.. \n",
            "Epoch: 28/30..  Running Loss: 1.721.. \n",
            "Epoch: 28/30..  Running Loss: 2.050.. \n",
            "Epoch: 28/30..  Running Loss: 2.168.. \n",
            "Epoch: 28/30..  Running Loss: 1.066.. \n",
            "Epoch: 28/30..  Running Loss: 2.263.. \n",
            "Epoch: 28/30..  Running Loss: 2.098.. \n",
            "Epoch: 28/30..  Running Loss: 2.112.. \n",
            "Epoch: 28/30..  Running Loss: 1.861.. \n",
            "Epoch: 28/30..  Running Loss: 2.235.. \n",
            "Epoch: 28/30..  Running Loss: 2.190.. \n",
            "Epoch: 28/30..  Running Loss: 2.213.. \n",
            "Epoch: 28/30..  Running Loss: 2.623.. \n",
            "Epoch: 28/30..  Running Loss: 2.878.. \n",
            "Epoch: 28/30..  Running Loss: 2.774.. \n",
            "Epoch: 28/30..  Running Loss: 2.621.. \n",
            "Epoch: 28/30..  Running Loss: 2.784.. \n",
            "Epoch: 28/30..  Running Loss: 2.581.. \n",
            "Epoch: 28/30..  Running Loss: 2.626.. \n",
            "Epoch: 28/30..  Running Loss: 2.700.. \n",
            "Epoch: 28/30..  Running Loss: 2.759.. \n",
            "Epoch: 28/30..  Running Loss: 2.615.. \n",
            "Epoch: 28/30..  Running Loss: 2.519.. \n",
            "Epoch: 28/30..  Running Loss: 2.309.. \n",
            "Epoch: 28/30..  Running Loss: 1.843.. \n",
            "Epoch: 28/30..  Running Loss: 1.673.. \n",
            "Epoch: 28/30..  Running Loss: 0.807.. \n",
            "Epoch: 28/30..  Running Loss: 1.387.. \n",
            "Epoch: 28/30..  Running Loss: 0.951.. \n",
            "Epoch: 28/30..  Running Loss: 0.712.. \n",
            "Epoch: 28/30..  Running Loss: 1.330.. \n",
            "Epoch: 28/30..  Running Loss: 0.931.. \n",
            "Epoch: 28/30..  Running Loss: 0.683.. \n",
            "Epoch: 28/30..  Running Loss: 0.831.. \n",
            "Epoch: 28/30..  Running Loss: 0.853.. \n",
            "Epoch: 28/30..  Running Loss: 1.969.. \n",
            "Epoch: 28/30..  Running Loss: 2.700.. \n",
            "Epoch: 28/30..  Running Loss: 2.313.. \n",
            "Epoch: 28/30..  Running Loss: 2.142.. \n",
            "Epoch: 28/30..  Running Loss: 2.586.. \n",
            "Epoch: 28/30..  Running Loss: 2.961.. \n",
            "Epoch: 28/30..  Running Loss: 2.613.. \n",
            "Epoch: 28/30..  Running Loss: 2.494.. \n",
            "Epoch: 28/30..  Running Loss: 2.506.. \n",
            "Epoch: 28/30..  Running Loss: 2.234.. \n",
            "Epoch: 28/30..  Running Loss: 2.848.. \n",
            "Epoch: 28/30..  Running Loss: 2.562.. \n",
            "Epoch: 28/30..  Running Loss: 2.260.. \n",
            "Epoch: 28/30..  Running Loss: 2.439.. \n",
            "Epoch: 28/30..  Running Loss: 2.366.. \n",
            "Epoch: 28/30..  Running Loss: 2.427.. \n",
            "Epoch: 28/30..  Running Loss: 2.569.. \n",
            "Epoch: 28/30..  Running Loss: 2.719.. \n",
            "Epoch: 28/30..  Running Loss: 2.153.. \n",
            "Epoch: 28/30..  Running Loss: 2.263.. \n",
            "Epoch: 28/30..  Running Loss: 2.047.. \n",
            "Epoch: 28/30..  Running Loss: 2.714.. \n",
            "Epoch: 28/30..  Running Loss: 2.449.. \n",
            "Epoch: 28/30..  Running Loss: 2.514.. \n",
            "Epoch: 28/30..  Running Loss: 2.701.. \n",
            "Epoch: 28/30..  Running Loss: 2.899.. \n",
            "Epoch: 28/30..  Running Loss: 2.300.. \n",
            "Epoch: 28/30..  Running Loss: 2.274.. \n",
            "Epoch: 28/30..  Running Loss: 2.327.. \n",
            "Epoch: 28/30..  Running Loss: 2.567.. \n",
            "Epoch: 28/30..  Running Loss: 2.466.. \n",
            "Epoch: 28/30..  Running Loss: 2.433.. \n",
            "Epoch: 28/30..  Running Loss: 2.780.. \n",
            "Epoch: 28/30..  Running Loss: 2.393.. \n",
            "Epoch: 28/30..  Running Loss: 2.761.. \n",
            "Epoch: 28/30..  Running Loss: 2.475.. \n",
            "Epoch: 28/30..  Running Loss: 2.573.. \n",
            "Epoch: 28/30..  Running Loss: 2.838.. \n",
            "Epoch: 28/30..  Running Loss: 2.586.. \n",
            "Epoch: 28/30..  Running Loss: 2.682.. \n",
            "Epoch: 28/30..  Running Loss: 2.518.. \n",
            "Epoch: 28/30..  Running Loss: 2.475.. \n",
            "Epoch: 28/30..  Running Loss: 2.721.. \n",
            "Epoch: 28/30..  Running Loss: 2.642.. \n",
            "Epoch: 28/30..  Running Loss: 2.291.. \n",
            "Epoch: 28/30..  Running Loss: 1.893.. \n",
            "Epoch: 28/30..  Running Loss: 2.349.. \n",
            "Epoch: 28/30..  Running Loss: 2.536.. \n",
            "Epoch: 28/30..  Running Loss: 2.255.. \n",
            "Epoch: 28/30..  Running Loss: 2.532.. \n",
            "Epoch: 28/30..  Running Loss: 2.567.. \n",
            "Epoch: 28/30..  Running Loss: 2.253.. \n",
            "Epoch: 28/30..  Running Loss: 2.522.. \n",
            "Epoch: 28/30..  Running Loss: 2.641.. \n",
            "Epoch: 28/30..  Running Loss: 2.753.. \n",
            "Epoch: 28/30..  Running Loss: 2.206.. \n",
            "Epoch: 28/30..  Running Loss: 2.892.. \n",
            "Epoch: 28/30..  Running Loss: 2.614.. \n",
            "Epoch: 28/30..  Running Loss: 2.657.. \n",
            "Epoch: 28/30..  Running Loss: 2.381.. \n",
            "Epoch: 28/30..  Running Loss: 2.496.. \n",
            "Epoch: 28/30..  Running Loss: 2.200.. \n",
            "Epoch: 28/30..  Running Loss: 2.753.. \n",
            "Epoch: 28/30..  Running Loss: 2.378.. \n",
            "Epoch: 28/30..  Running Loss: 2.439.. \n",
            "Epoch: 28/30..  Running Loss: 2.497.. \n",
            "Epoch: 28/30..  Running Loss: 2.893.. \n",
            "Epoch: 28/30..  Running Loss: 2.222.. \n",
            "Epoch: 28/30..  Running Loss: 2.314.. \n",
            "Epoch: 28/30..  Running Loss: 2.217.. \n",
            "Epoch: 28/30..  Running Loss: 2.217.. \n",
            "Epoch: 28/30..  Running Loss: 2.533.. \n",
            "Epoch: 28/30..  Running Loss: 2.440.. \n",
            "Epoch: 28/30..  Running Loss: 2.644.. \n",
            "Epoch: 28/30..  Running Loss: 2.662.. \n",
            "Epoch: 28/30..  Running Loss: 2.497.. \n",
            "Epoch: 28/30..  Running Loss: 2.388.. \n",
            "Epoch: 28/30..  Running Loss: 2.544.. \n",
            "Epoch: 28/30..  Running Loss: 1.939.. \n",
            "Epoch: 28/30..  Running Loss: 2.548.. \n",
            "Epoch: 28/30..  Running Loss: 2.847.. \n",
            "Epoch: 28/30..  Running Loss: 2.551.. \n",
            "Epoch: 28/30..  Running Loss: 2.439.. \n",
            "Epoch: 28/30..  Running Loss: 2.454.. \n",
            "Epoch: 28/30..  Running Loss: 2.413.. \n",
            "Epoch: 28/30..  Running Loss: 2.271.. \n",
            "Epoch: 28/30..  Running Loss: 2.299.. \n",
            "Epoch: 28/30..  Running Loss: 2.177.. \n",
            "Epoch: 28/30..  Running Loss: 2.331.. \n",
            "Epoch: 28/30..  Running Loss: 2.626.. \n",
            "Epoch: 28/30..  Running Loss: 3.035.. \n",
            "Epoch: 28/30..  Running Loss: 2.641.. \n",
            "Epoch: 28/30..  Running Loss: 2.594.. \n",
            "Epoch: 28/30..  Running Loss: 2.625.. \n",
            "Epoch: 28/30..  Running Loss: 2.630.. \n",
            "Epoch: 28/30..  Running Loss: 2.331.. \n",
            "Epoch: 28/30..  Running Loss: 2.462.. \n",
            "Epoch: 28/30..  Running Loss: 2.254.. \n",
            "Epoch: 28/30..  Running Loss: 2.261.. \n",
            "Epoch: 28/30..  Running Loss: 2.394.. \n",
            "Epoch: 28/30..  Running Loss: 2.419.. \n",
            "Epoch: 28/30..  Running Loss: 2.497.. \n",
            "Epoch: 28/30..  Running Loss: 2.743.. \n",
            "Epoch: 28/30..  Running Loss: 2.388.. \n",
            "Epoch: 28/30..  Running Loss: 2.476.. \n",
            "Epoch: 28/30..  Running Loss: 2.390.. \n",
            "Epoch: 28/30..  Running Loss: 2.233.. \n",
            "Epoch: 28/30..  Running Loss: 2.357.. \n",
            "Epoch: 28/30..  Running Loss: 2.477.. \n",
            "Epoch: 28/30..  Running Loss: 2.032.. \n",
            "Epoch: 28/30..  Running Loss: 2.379.. \n",
            "Epoch: 28/30..  Running Loss: 2.683.. \n",
            "Epoch: 28/30..  Running Loss: 2.644.. \n",
            "Epoch: 28/30..  Running Loss: 2.781.. \n",
            "Epoch: 28/30..  Running Loss: 2.293.. \n",
            "Epoch: 28/30..  Running Loss: 2.509.. \n",
            "Epoch: 28/30..  Running Loss: 2.203.. \n",
            "Epoch: 28/30..  Running Loss: 2.497.. \n",
            "Epoch: 28/30..  Running Loss: 2.333.. \n",
            "Epoch: 28/30..  Running Loss: 2.427.. \n",
            "Epoch: 28/30..  Running Loss: 2.537.. \n",
            "Epoch: 28/30..  Running Loss: 2.581.. \n",
            "Epoch: 28/30..  Running Loss: 2.374.. \n",
            "Epoch: 28/30..  Running Loss: 2.458.. \n",
            "Epoch: 28/30..  Running Loss: 2.172.. \n",
            "Epoch: 28/30..  Running Loss: 2.466.. \n",
            "Epoch: 28/30..  Running Loss: 2.344.. \n",
            "Epoch: 28/30..  Running Loss: 2.148.. \n",
            "Epoch: 28/30..  Running Loss: 2.065.. \n",
            "Epoch: 28/30..  Running Loss: 2.529.. \n",
            "Epoch: 28/30..  Running Loss: 2.384.. \n",
            "Epoch: 28/30..  Running Loss: 2.496.. \n",
            "Epoch: 28/30..  Running Loss: 2.302.. \n",
            "Epoch: 28/30..  Running Loss: 2.534.. \n",
            "Epoch: 28/30..  Running Loss: 1.956.. \n",
            "Epoch: 28/30..  Running Loss: 2.672.. \n",
            "Epoch: 28/30..  Running Loss: 2.263.. \n",
            "Epoch: 28/30..  Running Loss: 2.690.. \n",
            "Epoch: 28/30..  Running Loss: 2.364.. \n",
            "Epoch: 28/30..  Running Loss: 2.831.. \n",
            "Epoch: 28/30..  Running Loss: 2.810.. \n",
            "Epoch: 28/30..  Running Loss: 2.734.. \n",
            "Epoch: 28/30..  Running Loss: 2.083.. \n",
            "Epoch: 28/30..  Running Loss: 2.264.. \n",
            "Epoch: 28/30..  Running Loss: 2.503.. \n",
            "Epoch: 28/30..  Running Loss: 2.675.. \n",
            "Epoch: 28/30..  Running Loss: 2.367.. \n",
            "Epoch: 28/30..  Running Loss: 2.308.. \n",
            "Epoch: 28/30..  Running Loss: 2.536.. \n",
            "Epoch: 28/30..  Running Loss: 2.271.. \n",
            "Epoch: 28/30..  Running Loss: 2.306.. \n",
            "Epoch: 28/30..  Running Loss: 2.405.. \n",
            "Epoch: 28/30..  Running Loss: 2.423.. \n",
            "Epoch: 28/30..  Running Loss: 2.499.. \n",
            "Epoch: 28/30..  Running Loss: 2.289.. \n",
            "Epoch: 28/30..  Running Loss: 2.505.. \n",
            "Epoch: 28/30..  Running Loss: 2.521.. \n",
            "Epoch: 28/30..  Running Loss: 2.364.. \n",
            "Epoch: 28/30..  Running Loss: 2.619.. \n",
            "Epoch: 28/30..  Running Loss: 1.953.. \n",
            "Epoch: 28/30..  Running Loss: 2.380.. \n",
            "Epoch: 28/30..  Running Loss: 2.933.. \n",
            "Epoch: 28/30..  Running Loss: 2.260.. \n",
            "Epoch: 28/30..  Running Loss: 2.747.. \n",
            "Epoch: 28/30..  Running Loss: 2.354.. \n",
            "Epoch: 28/30..  Running Loss: 2.462.. \n",
            "Epoch: 28/30..  Running Loss: 2.513.. \n",
            "Epoch: 28/30..  Running Loss: 2.167.. \n",
            "Epoch: 28/30..  Running Loss: 2.319.. \n",
            "Epoch: 28/30..  Running Loss: 2.955.. \n",
            "Epoch: 28/30..  Running Loss: 2.651.. \n",
            "Epoch: 28/30..  Running Loss: 2.683.. \n",
            "Epoch: 28/30..  Running Loss: 2.306.. \n",
            "Epoch: 28/30..  Running Loss: 2.642.. \n",
            "Epoch: 28/30..  Running Loss: 2.466.. \n",
            "Epoch: 28/30..  Running Loss: 2.740.. \n",
            "Epoch: 28/30..  Running Loss: 2.537.. \n",
            "Epoch: 28/30..  Running Loss: 2.508.. \n",
            "Epoch: 28/30..  Running Loss: 2.424.. \n",
            "Epoch: 28/30..  Running Loss: 3.005.. \n",
            "Epoch: 28/30..  Running Loss: 2.655.. \n",
            "Epoch: 28/30..  Running Loss: 2.627.. \n",
            "Epoch: 28/30..  Running Loss: 2.295.. \n",
            "Epoch: 28/30..  Running Loss: 2.585.. \n",
            "Epoch: 28/30..  Running Loss: 2.692.. \n",
            "Epoch: 28/30..  Running Loss: 2.792.. \n",
            "Epoch: 28/30..  Running Loss: 2.948.. \n",
            "Epoch: 28/30..  Running Loss: 2.305.. \n",
            "Epoch: 28/30..  Running Loss: 2.446.. \n",
            "Epoch: 28/30..  Running Loss: 2.601.. \n",
            "Epoch: 28/30..  Running Loss: 2.492.. \n",
            "Epoch: 28/30..  Running Loss: 2.395.. \n",
            "Epoch: 28/30..  Running Loss: 2.277.. \n",
            "Epoch: 28/30..  Running Loss: 2.644.. \n",
            "Epoch: 28/30..  Running Loss: 2.159.. \n",
            "Epoch: 28/30..  Running Loss: 2.216.. \n",
            "Epoch: 28/30..  Running Loss: 3.111.. \n",
            "Epoch: 28/30..  Running Loss: 2.537.. \n",
            "Epoch: 28/30..  Running Loss: 2.301.. \n",
            "Epoch: 28/30..  Running Loss: 2.772.. \n",
            "Epoch: 28/30..  Running Loss: 2.347.. \n",
            "Epoch: 28/30..  Running Loss: 2.459.. \n",
            "Epoch: 28/30..  Running Loss: 2.587.. \n",
            "Epoch: 28/30..  Running Loss: 2.403.. \n",
            "Epoch: 28/30..  Running Loss: 2.571.. \n",
            "Epoch: 28/30..  Running Loss: 2.348.. \n",
            "Epoch: 28/30..  Running Loss: 2.488.. \n",
            "Epoch: 28/30..  Running Loss: 2.506.. \n",
            "Epoch: 28/30..  Running Loss: 2.212.. \n",
            "Epoch: 28/30..  Running Loss: 2.465.. \n",
            "Epoch: 28/30..  Running Loss: 2.364.. \n",
            "Epoch: 28/30..  Running Loss: 2.401.. \n",
            "Epoch: 28/30..  Running Loss: 2.365.. \n",
            "Epoch: 28/30..  Running Loss: 2.242.. \n",
            "Epoch: 28/30..  Running Loss: 2.305.. \n",
            "Epoch: 28/30..  Running Loss: 2.259.. \n",
            "Epoch: 28/30..  Running Loss: 2.421.. \n",
            "Epoch: 28/30..  Running Loss: 2.221.. \n",
            "Epoch: 28/30..  Running Loss: 2.228.. \n",
            "Epoch: 28/30..  Running Loss: 2.262.. \n",
            "Epoch: 28/30..  Running Loss: 2.441.. \n",
            "Epoch: 28/30..  Running Loss: 2.601.. \n",
            "Epoch: 28/30..  Running Loss: 2.033.. \n",
            "Epoch: 28/30..  Running Loss: 2.607.. \n",
            "Epoch: 28/30..  Running Loss: 2.398.. \n",
            "Epoch: 28/30..  Running Loss: 2.503.. \n",
            "Epoch: 28/30..  Running Loss: 2.410.. \n",
            "Epoch: 28/30..  Running Loss: 2.272.. \n",
            "Epoch: 28/30..  Running Loss: 2.284.. \n",
            "Epoch: 28/30..  Running Loss: 2.157.. \n",
            "Epoch: 28/30..  Running Loss: 2.575.. \n",
            "Epoch: 28/30..  Running Loss: 2.283.. \n",
            "Epoch: 28/30..  Running Loss: 2.731.. \n",
            "Epoch: 28/30..  Running Loss: 2.448.. \n",
            "Epoch: 28/30..  Running Loss: 2.338.. \n",
            "Epoch: 28/30..  Running Loss: 2.533.. \n",
            "Epoch: 28/30..  Running Loss: 2.328.. \n",
            "Epoch: 28/30..  Running Loss: 2.605.. \n",
            "Epoch: 28/30..  Running Loss: 2.547.. \n",
            "Epoch: 28/30..  Running Loss: 2.685.. \n",
            "Epoch: 28/30..  Running Loss: 2.667.. \n",
            "Epoch: 28/30..  Running Loss: 2.738.. \n",
            "Epoch: 28/30..  Running Loss: 2.352.. \n",
            "Epoch: 28/30..  Running Loss: 2.472.. \n",
            "Epoch: 28/30..  Running Loss: 2.402.. \n",
            "Epoch: 28/30..  Running Loss: 2.364.. \n",
            "Epoch: 28/30..  Running Loss: 2.599.. \n",
            "Epoch: 28/30..  Running Loss: 2.410.. \n",
            "Epoch: 28/30..  Running Loss: 2.019.. \n",
            "Epoch: 28/30..  Running Loss: 2.508.. \n",
            "Epoch: 28/30..  Running Loss: 2.542.. \n",
            "Epoch: 28/30..  Running Loss: 2.071.. \n",
            "Epoch: 28/30..  Running Loss: 2.583.. \n",
            "Epoch: 28/30..  Running Loss: 2.485.. \n",
            "Epoch: 28/30..  Running Loss: 2.430.. \n",
            "Epoch: 28/30..  Running Loss: 2.119.. \n",
            "Epoch: 28/30..  Running Loss: 2.166.. \n",
            "Epoch: 28/30..  Running Loss: 2.434.. \n",
            "Epoch: 28/30..  Running Loss: 2.518.. \n",
            "Epoch: 28/30..  Running Loss: 2.640.. \n",
            "Epoch: 28/30..  Running Loss: 2.412.. \n",
            "Epoch: 28/30..  Running Loss: 2.320.. \n",
            "Epoch: 28/30..  Running Loss: 2.906.. \n",
            "Epoch: 28/30..  Running Loss: 2.484.. \n",
            "Epoch: 28/30..  Running Loss: 2.653.. \n",
            "Epoch: 28/30..  Running Loss: 2.470.. \n",
            "Epoch: 28/30..  Running Loss: 2.408.. \n",
            "Epoch: 28/30..  Running Loss: 2.442.. \n",
            "Epoch: 28/30..  Running Loss: 2.529.. \n",
            "Epoch: 28/30..  Running Loss: 2.318.. \n",
            "Epoch: 28/30..  Running Loss: 2.343.. \n",
            "Epoch: 28/30..  Running Loss: 2.203.. \n",
            "Epoch: 28/30..  Running Loss: 2.338.. \n",
            "Epoch: 28/30..  Running Loss: 2.411.. \n",
            "Epoch: 28/30..  Running Loss: 2.154.. \n",
            "Epoch: 28/30..  Running Loss: 2.182.. \n",
            "Epoch: 28/30..  Running Loss: 2.419.. \n",
            "Epoch: 28/30..  Running Loss: 2.413.. \n",
            "Epoch: 28/30..  Running Loss: 2.785.. \n",
            "Epoch: 28/30..  Running Loss: 2.126.. \n",
            "Epoch: 28/30..  Running Loss: 3.039.. \n",
            "Epoch: 28/30..  Running Loss: 2.183.. \n",
            "Epoch: 28/30..  Running Loss: 2.544.. \n",
            "Epoch: 28/30..  Running Loss: 2.426.. \n",
            "Epoch: 28/30..  Running Loss: 2.421.. \n",
            "Epoch: 28/30..  Running Loss: 1.411.. \n",
            "Epoch: 28/30..  Running Loss: 2.615.. \n",
            "Epoch: 28/30..  Running Loss: 2.524.. \n",
            "Epoch: 28/30..  Running Loss: 2.467.. \n",
            "Epoch: 28/30..  Running Loss: 2.917.. \n",
            "Epoch: 28/30..  Running Loss: 2.253.. \n",
            "Epoch: 28/30..  Running Loss: 2.520.. \n",
            "Epoch: 28/30..  Running Loss: 2.710.. \n",
            "Epoch: 28/30..  Running Loss: 2.390.. \n",
            "Epoch: 28/30..  Running Loss: 2.499.. \n",
            "Epoch: 28/30..  Running Loss: 2.226.. \n",
            "Epoch: 28/30..  Running Loss: 2.835.. \n",
            "Epoch: 28/30..  Running Loss: 2.456.. \n",
            "Epoch: 28/30..  Running Loss: 2.665.. \n",
            "Epoch: 28/30..  Running Loss: 2.693.. \n",
            "Epoch: 28/30..  Running Loss: 2.310.. \n",
            "Epoch: 28/30..  Running Loss: 2.149.. \n",
            "Epoch: 28/30..  Running Loss: 2.356.. \n",
            "Epoch: 28/30..  Running Loss: 2.761.. \n",
            "Epoch: 28/30..  Running Loss: 2.552.. \n",
            "Epoch: 28/30..  Running Loss: 2.531.. \n",
            "Epoch: 28/30..  Running Loss: 2.170.. \n",
            "Epoch: 28/30..  Running Loss: 2.783.. \n",
            "Epoch: 28/30..  Running Loss: 2.457.. \n",
            "Epoch: 28/30..  Running Loss: 2.357.. \n",
            "Epoch: 28/30..  Running Loss: 2.825.. \n",
            "Epoch: 28/30..  Running Loss: 2.100.. \n",
            "Epoch: 28/30..  Running Loss: 2.497.. \n",
            "Epoch: 28/30..  Running Loss: 2.196.. \n",
            "Epoch: 28/30..  Running Loss: 2.560.. \n",
            "Epoch: 28/30..  Running Loss: 2.426.. \n",
            "Epoch: 28/30..  Running Loss: 2.274.. \n",
            "Epoch: 28/30..  Running Loss: 2.067.. \n",
            "Epoch: 28/30..  Running Loss: 2.454.. \n",
            "Epoch: 28/30..  Running Loss: 2.456.. \n",
            "Epoch: 28/30..  Running Loss: 2.626.. \n",
            "Epoch: 28/30..  Running Loss: 2.458.. \n",
            "Epoch: 28/30..  Running Loss: 2.192.. \n",
            "Epoch: 28/30..  Running Loss: 2.709.. \n",
            "Epoch: 28/30..  Running Loss: 2.255.. \n",
            "Epoch: 28/30..  Running Loss: 2.413.. \n",
            "Epoch: 28/30..  Running Loss: 2.396.. \n",
            "Epoch: 28/30..  Running Loss: 2.347.. \n",
            "Epoch: 28/30..  Running Loss: 2.508.. \n",
            "Epoch: 28/30..  Running Loss: 2.301.. \n",
            "Epoch: 28/30..  Running Loss: 2.375.. \n",
            "Epoch: 28/30..  Running Loss: 2.643.. \n",
            "Epoch: 28/30..  Running Loss: 2.337.. \n",
            "Epoch: 28/30..  Running Loss: 2.702.. \n",
            "Epoch: 28/30..  Running Loss: 2.301.. \n",
            "Epoch: 28/30..  Running Loss: 2.645.. \n",
            "Epoch: 28/30..  Running Loss: 2.479.. \n",
            "Epoch: 28/30..  Running Loss: 2.517.. \n",
            "Epoch: 28/30..  Running Loss: 2.513.. \n",
            "Epoch: 28/30..  Running Loss: 2.309.. \n",
            "Epoch: 28/30..  Running Loss: 2.546.. \n",
            "Epoch: 28/30..  Running Loss: 2.172.. \n",
            "Epoch: 28/30..  Running Loss: 2.838.. \n",
            "Epoch: 28/30..  Running Loss: 2.371.. \n",
            "Epoch: 28/30..  Running Loss: 2.124.. \n",
            "Epoch: 28/30..  Running Loss: 1.955.. \n",
            "Epoch: 28/30..  Running Loss: 2.445.. \n",
            "Epoch: 28/30..  Running Loss: 2.514.. \n",
            "Epoch: 28/30..  Running Loss: 2.393.. \n",
            "Epoch: 28/30..  Running Loss: 2.406.. \n",
            "Epoch: 28/30..  Running Loss: 2.186.. \n",
            "Epoch: 28/30..  Running Loss: 2.753.. \n",
            "Epoch: 28/30..  Running Loss: 2.663.. \n",
            "Epoch: 28/30..  Running Loss: 2.561.. \n",
            "Epoch: 28/30..  Running Loss: 2.340.. \n",
            "Epoch: 28/30..  Running Loss: 2.474.. \n",
            "Epoch: 28/30..  Running Loss: 2.500.. \n",
            "Epoch: 28/30..  Running Loss: 2.231.. \n",
            "Epoch: 28/30..  Running Loss: 2.500.. \n",
            "Epoch: 28/30..  Running Loss: 2.418.. \n",
            "Epoch: 28/30..  Running Loss: 2.314.. \n",
            "Epoch: 28/30..  Running Loss: 2.502.. \n",
            "Epoch: 28/30..  Running Loss: 2.429.. \n",
            "Epoch: 28/30..  Running Loss: 2.393.. \n",
            "Epoch: 28/30..  Running Loss: 2.553.. \n",
            "Epoch: 28/30..  Running Loss: 2.415.. \n",
            "Epoch: 28/30..  Running Loss: 2.186.. \n",
            "Epoch: 28/30..  Running Loss: 2.268.. \n",
            "Epoch: 28/30..  Running Loss: 2.515.. \n",
            "Epoch: 28/30..  Running Loss: 2.484.. \n",
            "Epoch: 28/30..  Running Loss: 2.485.. \n",
            "Epoch: 28/30..  Running Loss: 2.361.. \n",
            "Epoch: 28/30..  Running Loss: 2.515.. \n",
            "Epoch: 28/30..  Running Loss: 2.396.. \n",
            "Epoch: 28/30..  Running Loss: 2.531.. \n",
            "Epoch: 28/30..  Running Loss: 2.793.. \n",
            "Epoch: 29/30..  Running Loss: 2.626.. \n",
            "Epoch: 29/30..  Running Loss: 2.470.. \n",
            "Epoch: 29/30..  Running Loss: 2.795.. \n",
            "Epoch: 29/30..  Running Loss: 2.377.. \n",
            "Epoch: 29/30..  Running Loss: 2.337.. \n",
            "Epoch: 29/30..  Running Loss: 2.139.. \n",
            "Epoch: 29/30..  Running Loss: 2.702.. \n",
            "Epoch: 29/30..  Running Loss: 2.592.. \n",
            "Epoch: 29/30..  Running Loss: 2.505.. \n",
            "Epoch: 29/30..  Running Loss: 2.713.. \n",
            "Epoch: 29/30..  Running Loss: 2.289.. \n",
            "Epoch: 29/30..  Running Loss: 2.162.. \n",
            "Epoch: 29/30..  Running Loss: 2.272.. \n",
            "Epoch: 29/30..  Running Loss: 2.685.. \n",
            "Epoch: 29/30..  Running Loss: 2.282.. \n",
            "Epoch: 29/30..  Running Loss: 2.507.. \n",
            "Epoch: 29/30..  Running Loss: 2.281.. \n",
            "Epoch: 29/30..  Running Loss: 2.223.. \n",
            "Epoch: 29/30..  Running Loss: 2.179.. \n",
            "Epoch: 29/30..  Running Loss: 2.214.. \n",
            "Epoch: 29/30..  Running Loss: 2.439.. \n",
            "Epoch: 29/30..  Running Loss: 2.455.. \n",
            "Epoch: 29/30..  Running Loss: 2.652.. \n",
            "Epoch: 29/30..  Running Loss: 2.323.. \n",
            "Epoch: 29/30..  Running Loss: 2.177.. \n",
            "Epoch: 29/30..  Running Loss: 2.315.. \n",
            "Epoch: 29/30..  Running Loss: 2.413.. \n",
            "Epoch: 29/30..  Running Loss: 2.403.. \n",
            "Epoch: 29/30..  Running Loss: 1.974.. \n",
            "Epoch: 29/30..  Running Loss: 2.069.. \n",
            "Epoch: 29/30..  Running Loss: 2.324.. \n",
            "Epoch: 29/30..  Running Loss: 2.082.. \n",
            "Epoch: 29/30..  Running Loss: 2.376.. \n",
            "Epoch: 29/30..  Running Loss: 2.125.. \n",
            "Epoch: 29/30..  Running Loss: 2.154.. \n",
            "Epoch: 29/30..  Running Loss: 2.771.. \n",
            "Epoch: 29/30..  Running Loss: 2.819.. \n",
            "Epoch: 29/30..  Running Loss: 2.003.. \n",
            "Epoch: 29/30..  Running Loss: 2.273.. \n",
            "Epoch: 29/30..  Running Loss: 2.280.. \n",
            "Epoch: 29/30..  Running Loss: 2.285.. \n",
            "Epoch: 29/30..  Running Loss: 2.500.. \n",
            "Epoch: 29/30..  Running Loss: 2.261.. \n",
            "Epoch: 29/30..  Running Loss: 2.724.. \n",
            "Epoch: 29/30..  Running Loss: 2.807.. \n",
            "Epoch: 29/30..  Running Loss: 2.255.. \n",
            "Epoch: 29/30..  Running Loss: 2.524.. \n",
            "Epoch: 29/30..  Running Loss: 2.427.. \n",
            "Epoch: 29/30..  Running Loss: 2.300.. \n",
            "Epoch: 29/30..  Running Loss: 2.562.. \n",
            "Epoch: 29/30..  Running Loss: 2.098.. \n",
            "Epoch: 29/30..  Running Loss: 2.324.. \n",
            "Epoch: 29/30..  Running Loss: 2.445.. \n",
            "Epoch: 29/30..  Running Loss: 2.418.. \n",
            "Epoch: 29/30..  Running Loss: 2.286.. \n",
            "Epoch: 29/30..  Running Loss: 2.437.. \n",
            "Epoch: 29/30..  Running Loss: 2.605.. \n",
            "Epoch: 29/30..  Running Loss: 2.434.. \n",
            "Epoch: 29/30..  Running Loss: 1.890.. \n",
            "Epoch: 29/30..  Running Loss: 2.371.. \n",
            "Epoch: 29/30..  Running Loss: 2.630.. \n",
            "Epoch: 29/30..  Running Loss: 2.469.. \n",
            "Epoch: 29/30..  Running Loss: 2.216.. \n",
            "Epoch: 29/30..  Running Loss: 2.226.. \n",
            "Epoch: 29/30..  Running Loss: 2.247.. \n",
            "Epoch: 29/30..  Running Loss: 1.997.. \n",
            "Epoch: 29/30..  Running Loss: 2.158.. \n",
            "Epoch: 29/30..  Running Loss: 2.667.. \n",
            "Epoch: 29/30..  Running Loss: 2.299.. \n",
            "Epoch: 29/30..  Running Loss: 2.265.. \n",
            "Epoch: 29/30..  Running Loss: 2.208.. \n",
            "Epoch: 29/30..  Running Loss: 2.316.. \n",
            "Epoch: 29/30..  Running Loss: 2.500.. \n",
            "Epoch: 29/30..  Running Loss: 2.595.. \n",
            "Epoch: 29/30..  Running Loss: 2.312.. \n",
            "Epoch: 29/30..  Running Loss: 2.549.. \n",
            "Epoch: 29/30..  Running Loss: 2.105.. \n",
            "Epoch: 29/30..  Running Loss: 2.069.. \n",
            "Epoch: 29/30..  Running Loss: 1.950.. \n",
            "Epoch: 29/30..  Running Loss: 2.305.. \n",
            "Epoch: 29/30..  Running Loss: 2.384.. \n",
            "Epoch: 29/30..  Running Loss: 2.240.. \n",
            "Epoch: 29/30..  Running Loss: 2.395.. \n",
            "Epoch: 29/30..  Running Loss: 2.294.. \n",
            "Epoch: 29/30..  Running Loss: 2.393.. \n",
            "Epoch: 29/30..  Running Loss: 2.278.. \n",
            "Epoch: 29/30..  Running Loss: 2.652.. \n",
            "Epoch: 29/30..  Running Loss: 2.813.. \n",
            "Epoch: 29/30..  Running Loss: 2.047.. \n",
            "Epoch: 29/30..  Running Loss: 2.750.. \n",
            "Epoch: 29/30..  Running Loss: 2.404.. \n",
            "Epoch: 29/30..  Running Loss: 2.648.. \n",
            "Epoch: 29/30..  Running Loss: 2.920.. \n",
            "Epoch: 29/30..  Running Loss: 2.302.. \n",
            "Epoch: 29/30..  Running Loss: 2.029.. \n",
            "Epoch: 29/30..  Running Loss: 2.595.. \n",
            "Epoch: 29/30..  Running Loss: 2.808.. \n",
            "Epoch: 29/30..  Running Loss: 2.377.. \n",
            "Epoch: 29/30..  Running Loss: 2.125.. \n",
            "Epoch: 29/30..  Running Loss: 2.879.. \n",
            "Epoch: 29/30..  Running Loss: 2.348.. \n",
            "Epoch: 29/30..  Running Loss: 2.338.. \n",
            "Epoch: 29/30..  Running Loss: 2.756.. \n",
            "Epoch: 29/30..  Running Loss: 2.539.. \n",
            "Epoch: 29/30..  Running Loss: 2.712.. \n",
            "Epoch: 29/30..  Running Loss: 2.419.. \n",
            "Epoch: 29/30..  Running Loss: 2.269.. \n",
            "Epoch: 29/30..  Running Loss: 2.679.. \n",
            "Epoch: 29/30..  Running Loss: 2.358.. \n",
            "Epoch: 29/30..  Running Loss: 3.140.. \n",
            "Epoch: 29/30..  Running Loss: 2.444.. \n",
            "Epoch: 29/30..  Running Loss: 2.489.. \n",
            "Epoch: 29/30..  Running Loss: 2.296.. \n",
            "Epoch: 29/30..  Running Loss: 2.085.. \n",
            "Epoch: 29/30..  Running Loss: 2.447.. \n",
            "Epoch: 29/30..  Running Loss: 2.624.. \n",
            "Epoch: 29/30..  Running Loss: 2.719.. \n",
            "Epoch: 29/30..  Running Loss: 2.431.. \n",
            "Epoch: 29/30..  Running Loss: 2.289.. \n",
            "Epoch: 29/30..  Running Loss: 2.205.. \n",
            "Epoch: 29/30..  Running Loss: 2.677.. \n",
            "Epoch: 29/30..  Running Loss: 2.407.. \n",
            "Epoch: 29/30..  Running Loss: 1.970.. \n",
            "Epoch: 29/30..  Running Loss: 2.502.. \n",
            "Epoch: 29/30..  Running Loss: 2.467.. \n",
            "Epoch: 29/30..  Running Loss: 2.769.. \n",
            "Epoch: 29/30..  Running Loss: 2.380.. \n",
            "Epoch: 29/30..  Running Loss: 2.856.. \n",
            "Epoch: 29/30..  Running Loss: 2.516.. \n",
            "Epoch: 29/30..  Running Loss: 2.403.. \n",
            "Epoch: 29/30..  Running Loss: 2.307.. \n",
            "Epoch: 29/30..  Running Loss: 2.684.. \n",
            "Epoch: 29/30..  Running Loss: 2.435.. \n",
            "Epoch: 29/30..  Running Loss: 2.491.. \n",
            "Epoch: 29/30..  Running Loss: 2.557.. \n",
            "Epoch: 29/30..  Running Loss: 2.893.. \n",
            "Epoch: 29/30..  Running Loss: 2.070.. \n",
            "Epoch: 29/30..  Running Loss: 2.664.. \n",
            "Epoch: 29/30..  Running Loss: 2.297.. \n",
            "Epoch: 29/30..  Running Loss: 2.330.. \n",
            "Epoch: 29/30..  Running Loss: 2.465.. \n",
            "Epoch: 29/30..  Running Loss: 2.145.. \n",
            "Epoch: 29/30..  Running Loss: 2.604.. \n",
            "Epoch: 29/30..  Running Loss: 2.313.. \n",
            "Epoch: 29/30..  Running Loss: 2.229.. \n",
            "Epoch: 29/30..  Running Loss: 2.490.. \n",
            "Epoch: 29/30..  Running Loss: 2.446.. \n",
            "Epoch: 29/30..  Running Loss: 2.536.. \n",
            "Epoch: 29/30..  Running Loss: 2.532.. \n",
            "Epoch: 29/30..  Running Loss: 2.615.. \n",
            "Epoch: 29/30..  Running Loss: 2.943.. \n",
            "Epoch: 29/30..  Running Loss: 2.383.. \n",
            "Epoch: 29/30..  Running Loss: 2.434.. \n",
            "Epoch: 29/30..  Running Loss: 2.529.. \n",
            "Epoch: 29/30..  Running Loss: 2.788.. \n",
            "Epoch: 29/30..  Running Loss: 2.458.. \n",
            "Epoch: 29/30..  Running Loss: 2.374.. \n",
            "Epoch: 29/30..  Running Loss: 2.390.. \n",
            "Epoch: 29/30..  Running Loss: 2.353.. \n",
            "Epoch: 29/30..  Running Loss: 2.343.. \n",
            "Epoch: 29/30..  Running Loss: 2.655.. \n",
            "Epoch: 29/30..  Running Loss: 2.322.. \n",
            "Epoch: 29/30..  Running Loss: 1.861.. \n",
            "Epoch: 29/30..  Running Loss: 2.280.. \n",
            "Epoch: 29/30..  Running Loss: 2.346.. \n",
            "Epoch: 29/30..  Running Loss: 2.179.. \n",
            "Epoch: 29/30..  Running Loss: 2.597.. \n",
            "Epoch: 29/30..  Running Loss: 2.372.. \n",
            "Epoch: 29/30..  Running Loss: 2.599.. \n",
            "Epoch: 29/30..  Running Loss: 2.158.. \n",
            "Epoch: 29/30..  Running Loss: 2.160.. \n",
            "Epoch: 29/30..  Running Loss: 2.301.. \n",
            "Epoch: 29/30..  Running Loss: 2.113.. \n",
            "Epoch: 29/30..  Running Loss: 2.292.. \n",
            "Epoch: 29/30..  Running Loss: 2.042.. \n",
            "Epoch: 29/30..  Running Loss: 2.239.. \n",
            "Epoch: 29/30..  Running Loss: 2.079.. \n",
            "Epoch: 29/30..  Running Loss: 1.903.. \n",
            "Epoch: 29/30..  Running Loss: 2.659.. \n",
            "Epoch: 29/30..  Running Loss: 2.221.. \n",
            "Epoch: 29/30..  Running Loss: 2.292.. \n",
            "Epoch: 29/30..  Running Loss: 2.506.. \n",
            "Epoch: 29/30..  Running Loss: 1.953.. \n",
            "Epoch: 29/30..  Running Loss: 2.144.. \n",
            "Epoch: 29/30..  Running Loss: 1.885.. \n",
            "Epoch: 29/30..  Running Loss: 2.221.. \n",
            "Epoch: 29/30..  Running Loss: 2.326.. \n",
            "Epoch: 29/30..  Running Loss: 2.270.. \n",
            "Epoch: 29/30..  Running Loss: 1.862.. \n",
            "Epoch: 29/30..  Running Loss: 2.255.. \n",
            "Epoch: 29/30..  Running Loss: 2.519.. \n",
            "Epoch: 29/30..  Running Loss: 2.488.. \n",
            "Epoch: 29/30..  Running Loss: 2.696.. \n",
            "Epoch: 29/30..  Running Loss: 2.429.. \n",
            "Epoch: 29/30..  Running Loss: 2.371.. \n",
            "Epoch: 29/30..  Running Loss: 2.533.. \n",
            "Epoch: 29/30..  Running Loss: 2.481.. \n",
            "Epoch: 29/30..  Running Loss: 2.140.. \n",
            "Epoch: 29/30..  Running Loss: 2.160.. \n",
            "Epoch: 29/30..  Running Loss: 2.321.. \n",
            "Epoch: 29/30..  Running Loss: 2.239.. \n",
            "Epoch: 29/30..  Running Loss: 2.096.. \n",
            "Epoch: 29/30..  Running Loss: 2.332.. \n",
            "Epoch: 29/30..  Running Loss: 1.915.. \n",
            "Epoch: 29/30..  Running Loss: 2.455.. \n",
            "Epoch: 29/30..  Running Loss: 2.266.. \n",
            "Epoch: 29/30..  Running Loss: 2.749.. \n",
            "Epoch: 29/30..  Running Loss: 2.407.. \n",
            "Epoch: 29/30..  Running Loss: 2.830.. \n",
            "Epoch: 29/30..  Running Loss: 2.433.. \n",
            "Epoch: 29/30..  Running Loss: 2.310.. \n",
            "Epoch: 29/30..  Running Loss: 2.160.. \n",
            "Epoch: 29/30..  Running Loss: 2.308.. \n",
            "Epoch: 29/30..  Running Loss: 2.572.. \n",
            "Epoch: 29/30..  Running Loss: 2.388.. \n",
            "Epoch: 29/30..  Running Loss: 2.483.. \n",
            "Epoch: 29/30..  Running Loss: 2.400.. \n",
            "Epoch: 29/30..  Running Loss: 2.126.. \n",
            "Epoch: 29/30..  Running Loss: 2.107.. \n",
            "Epoch: 29/30..  Running Loss: 2.608.. \n",
            "Epoch: 29/30..  Running Loss: 2.664.. \n",
            "Epoch: 29/30..  Running Loss: 2.680.. \n",
            "Epoch: 29/30..  Running Loss: 2.124.. \n",
            "Epoch: 29/30..  Running Loss: 2.023.. \n",
            "Epoch: 29/30..  Running Loss: 2.295.. \n",
            "Epoch: 29/30..  Running Loss: 1.962.. \n",
            "Epoch: 29/30..  Running Loss: 2.296.. \n",
            "Epoch: 29/30..  Running Loss: 2.599.. \n",
            "Epoch: 29/30..  Running Loss: 2.382.. \n",
            "Epoch: 29/30..  Running Loss: 2.532.. \n",
            "Epoch: 29/30..  Running Loss: 2.461.. \n",
            "Epoch: 29/30..  Running Loss: 2.405.. \n",
            "Epoch: 29/30..  Running Loss: 2.449.. \n",
            "Epoch: 29/30..  Running Loss: 2.518.. \n",
            "Epoch: 29/30..  Running Loss: 2.444.. \n",
            "Epoch: 29/30..  Running Loss: 2.255.. \n",
            "Epoch: 29/30..  Running Loss: 2.518.. \n",
            "Epoch: 29/30..  Running Loss: 2.371.. \n",
            "Epoch: 29/30..  Running Loss: 2.478.. \n",
            "Epoch: 29/30..  Running Loss: 2.294.. \n",
            "Epoch: 29/30..  Running Loss: 2.015.. \n",
            "Epoch: 29/30..  Running Loss: 2.216.. \n",
            "Epoch: 29/30..  Running Loss: 2.311.. \n",
            "Epoch: 29/30..  Running Loss: 2.476.. \n",
            "Epoch: 29/30..  Running Loss: 2.361.. \n",
            "Epoch: 29/30..  Running Loss: 2.699.. \n",
            "Epoch: 29/30..  Running Loss: 2.436.. \n",
            "Epoch: 29/30..  Running Loss: 2.208.. \n",
            "Epoch: 29/30..  Running Loss: 2.090.. \n",
            "Epoch: 29/30..  Running Loss: 2.308.. \n",
            "Epoch: 29/30..  Running Loss: 2.558.. \n",
            "Epoch: 29/30..  Running Loss: 2.660.. \n",
            "Epoch: 29/30..  Running Loss: 2.385.. \n",
            "Epoch: 29/30..  Running Loss: 2.263.. \n",
            "Epoch: 29/30..  Running Loss: 2.184.. \n",
            "Epoch: 29/30..  Running Loss: 2.479.. \n",
            "Epoch: 29/30..  Running Loss: 2.255.. \n",
            "Epoch: 29/30..  Running Loss: 2.063.. \n",
            "Epoch: 29/30..  Running Loss: 2.335.. \n",
            "Epoch: 29/30..  Running Loss: 2.484.. \n",
            "Epoch: 29/30..  Running Loss: 2.461.. \n",
            "Epoch: 29/30..  Running Loss: 2.020.. \n",
            "Epoch: 29/30..  Running Loss: 2.038.. \n",
            "Epoch: 29/30..  Running Loss: 3.059.. \n",
            "Epoch: 29/30..  Running Loss: 2.390.. \n",
            "Epoch: 29/30..  Running Loss: 2.045.. \n",
            "Epoch: 29/30..  Running Loss: 2.768.. \n",
            "Epoch: 29/30..  Running Loss: 2.231.. \n",
            "Epoch: 29/30..  Running Loss: 2.216.. \n",
            "Epoch: 29/30..  Running Loss: 2.498.. \n",
            "Epoch: 29/30..  Running Loss: 2.621.. \n",
            "Epoch: 29/30..  Running Loss: 2.773.. \n",
            "Epoch: 29/30..  Running Loss: 2.560.. \n",
            "Epoch: 29/30..  Running Loss: 2.664.. \n",
            "Epoch: 29/30..  Running Loss: 2.689.. \n",
            "Epoch: 29/30..  Running Loss: 2.447.. \n",
            "Epoch: 29/30..  Running Loss: 2.365.. \n",
            "Epoch: 29/30..  Running Loss: 1.880.. \n",
            "Epoch: 29/30..  Running Loss: 2.312.. \n",
            "Epoch: 29/30..  Running Loss: 2.356.. \n",
            "Epoch: 29/30..  Running Loss: 2.580.. \n",
            "Epoch: 29/30..  Running Loss: 2.450.. \n",
            "Epoch: 29/30..  Running Loss: 2.034.. \n",
            "Epoch: 29/30..  Running Loss: 2.661.. \n",
            "Epoch: 29/30..  Running Loss: 2.386.. \n",
            "Epoch: 29/30..  Running Loss: 2.496.. \n",
            "Epoch: 29/30..  Running Loss: 2.410.. \n",
            "Epoch: 29/30..  Running Loss: 2.345.. \n",
            "Epoch: 29/30..  Running Loss: 2.573.. \n",
            "Epoch: 29/30..  Running Loss: 2.437.. \n",
            "Epoch: 29/30..  Running Loss: 2.210.. \n",
            "Epoch: 29/30..  Running Loss: 2.089.. \n",
            "Epoch: 29/30..  Running Loss: 2.172.. \n",
            "Epoch: 29/30..  Running Loss: 2.352.. \n",
            "Epoch: 29/30..  Running Loss: 2.781.. \n",
            "Epoch: 29/30..  Running Loss: 2.048.. \n",
            "Epoch: 29/30..  Running Loss: 2.451.. \n",
            "Epoch: 29/30..  Running Loss: 1.855.. \n",
            "Epoch: 29/30..  Running Loss: 2.256.. \n",
            "Epoch: 29/30..  Running Loss: 2.031.. \n",
            "Epoch: 29/30..  Running Loss: 1.817.. \n",
            "Epoch: 29/30..  Running Loss: 2.184.. \n",
            "Epoch: 29/30..  Running Loss: 2.067.. \n",
            "Epoch: 29/30..  Running Loss: 2.088.. \n",
            "Epoch: 29/30..  Running Loss: 2.940.. \n",
            "Epoch: 29/30..  Running Loss: 2.375.. \n",
            "Epoch: 29/30..  Running Loss: 2.375.. \n",
            "Epoch: 29/30..  Running Loss: 2.394.. \n",
            "Epoch: 29/30..  Running Loss: 2.977.. \n",
            "Epoch: 29/30..  Running Loss: 2.594.. \n",
            "Epoch: 29/30..  Running Loss: 2.691.. \n",
            "Epoch: 29/30..  Running Loss: 2.462.. \n",
            "Epoch: 29/30..  Running Loss: 2.356.. \n",
            "Epoch: 29/30..  Running Loss: 2.688.. \n",
            "Epoch: 29/30..  Running Loss: 2.504.. \n",
            "Epoch: 29/30..  Running Loss: 2.599.. \n",
            "Epoch: 29/30..  Running Loss: 2.752.. \n",
            "Epoch: 29/30..  Running Loss: 2.549.. \n",
            "Epoch: 29/30..  Running Loss: 2.562.. \n",
            "Epoch: 29/30..  Running Loss: 2.594.. \n",
            "Epoch: 29/30..  Running Loss: 2.710.. \n",
            "Epoch: 29/30..  Running Loss: 2.722.. \n",
            "Epoch: 29/30..  Running Loss: 2.414.. \n",
            "Epoch: 29/30..  Running Loss: 2.979.. \n",
            "Epoch: 29/30..  Running Loss: 2.282.. \n",
            "Epoch: 29/30..  Running Loss: 2.564.. \n",
            "Epoch: 29/30..  Running Loss: 2.266.. \n",
            "Epoch: 29/30..  Running Loss: 2.769.. \n",
            "Epoch: 29/30..  Running Loss: 2.506.. \n",
            "Epoch: 29/30..  Running Loss: 2.789.. \n",
            "Epoch: 29/30..  Running Loss: 2.642.. \n",
            "Epoch: 29/30..  Running Loss: 2.572.. \n",
            "Epoch: 29/30..  Running Loss: 2.666.. \n",
            "Epoch: 29/30..  Running Loss: 2.602.. \n",
            "Epoch: 29/30..  Running Loss: 2.257.. \n",
            "Epoch: 29/30..  Running Loss: 2.857.. \n",
            "Epoch: 29/30..  Running Loss: 2.598.. \n",
            "Epoch: 29/30..  Running Loss: 2.122.. \n",
            "Epoch: 29/30..  Running Loss: 2.836.. \n",
            "Epoch: 29/30..  Running Loss: 2.671.. \n",
            "Epoch: 29/30..  Running Loss: 2.650.. \n",
            "Epoch: 29/30..  Running Loss: 2.587.. \n",
            "Epoch: 29/30..  Running Loss: 2.546.. \n",
            "Epoch: 29/30..  Running Loss: 2.154.. \n",
            "Epoch: 29/30..  Running Loss: 2.444.. \n",
            "Epoch: 29/30..  Running Loss: 2.173.. \n",
            "Epoch: 29/30..  Running Loss: 2.289.. \n",
            "Epoch: 29/30..  Running Loss: 2.253.. \n",
            "Epoch: 29/30..  Running Loss: 2.505.. \n",
            "Epoch: 29/30..  Running Loss: 2.377.. \n",
            "Epoch: 29/30..  Running Loss: 2.423.. \n",
            "Epoch: 29/30..  Running Loss: 2.573.. \n",
            "Epoch: 29/30..  Running Loss: 2.956.. \n",
            "Epoch: 29/30..  Running Loss: 2.356.. \n",
            "Epoch: 29/30..  Running Loss: 2.301.. \n",
            "Epoch: 29/30..  Running Loss: 2.074.. \n",
            "Epoch: 29/30..  Running Loss: 2.573.. \n",
            "Epoch: 29/30..  Running Loss: 2.924.. \n",
            "Epoch: 29/30..  Running Loss: 2.848.. \n",
            "Epoch: 29/30..  Running Loss: 2.498.. \n",
            "Epoch: 29/30..  Running Loss: 2.280.. \n",
            "Epoch: 29/30..  Running Loss: 2.202.. \n",
            "Epoch: 29/30..  Running Loss: 2.517.. \n",
            "Epoch: 29/30..  Running Loss: 2.221.. \n",
            "Epoch: 29/30..  Running Loss: 2.273.. \n",
            "Epoch: 29/30..  Running Loss: 2.146.. \n",
            "Epoch: 29/30..  Running Loss: 2.543.. \n",
            "Epoch: 29/30..  Running Loss: 2.215.. \n",
            "Epoch: 29/30..  Running Loss: 2.237.. \n",
            "Epoch: 29/30..  Running Loss: 2.489.. \n",
            "Epoch: 29/30..  Running Loss: 2.880.. \n",
            "Epoch: 29/30..  Running Loss: 2.451.. \n",
            "Epoch: 29/30..  Running Loss: 2.521.. \n",
            "Epoch: 29/30..  Running Loss: 2.446.. \n",
            "Epoch: 29/30..  Running Loss: 2.509.. \n",
            "Epoch: 29/30..  Running Loss: 2.642.. \n",
            "Epoch: 29/30..  Running Loss: 2.532.. \n",
            "Epoch: 29/30..  Running Loss: 2.283.. \n",
            "Epoch: 29/30..  Running Loss: 2.635.. \n",
            "Epoch: 29/30..  Running Loss: 2.428.. \n",
            "Epoch: 29/30..  Running Loss: 2.554.. \n",
            "Epoch: 29/30..  Running Loss: 2.561.. \n",
            "Epoch: 29/30..  Running Loss: 2.651.. \n",
            "Epoch: 29/30..  Running Loss: 2.834.. \n",
            "Epoch: 29/30..  Running Loss: 2.867.. \n",
            "Epoch: 29/30..  Running Loss: 2.454.. \n",
            "Epoch: 29/30..  Running Loss: 2.849.. \n",
            "Epoch: 29/30..  Running Loss: 2.528.. \n",
            "Epoch: 29/30..  Running Loss: 2.612.. \n",
            "Epoch: 29/30..  Running Loss: 2.478.. \n",
            "Epoch: 29/30..  Running Loss: 2.458.. \n",
            "Epoch: 29/30..  Running Loss: 2.342.. \n",
            "Epoch: 29/30..  Running Loss: 2.269.. \n",
            "Epoch: 29/30..  Running Loss: 2.668.. \n",
            "Epoch: 29/30..  Running Loss: 2.151.. \n",
            "Epoch: 29/30..  Running Loss: 2.238.. \n",
            "Epoch: 29/30..  Running Loss: 2.891.. \n",
            "Epoch: 29/30..  Running Loss: 2.540.. \n",
            "Epoch: 29/30..  Running Loss: 2.402.. \n",
            "Epoch: 29/30..  Running Loss: 2.493.. \n",
            "Epoch: 29/30..  Running Loss: 2.753.. \n",
            "Epoch: 29/30..  Running Loss: 2.402.. \n",
            "Epoch: 29/30..  Running Loss: 2.628.. \n",
            "Epoch: 29/30..  Running Loss: 2.107.. \n",
            "Epoch: 29/30..  Running Loss: 2.266.. \n",
            "Epoch: 29/30..  Running Loss: 2.473.. \n",
            "Epoch: 29/30..  Running Loss: 2.252.. \n",
            "Epoch: 29/30..  Running Loss: 2.732.. \n",
            "Epoch: 29/30..  Running Loss: 2.357.. \n",
            "Epoch: 29/30..  Running Loss: 2.311.. \n",
            "Epoch: 29/30..  Running Loss: 2.312.. \n",
            "Epoch: 29/30..  Running Loss: 2.239.. \n",
            "Epoch: 29/30..  Running Loss: 2.503.. \n",
            "Epoch: 29/30..  Running Loss: 2.296.. \n",
            "Epoch: 29/30..  Running Loss: 2.273.. \n",
            "Epoch: 29/30..  Running Loss: 2.615.. \n",
            "Epoch: 29/30..  Running Loss: 2.373.. \n",
            "Epoch: 29/30..  Running Loss: 2.566.. \n",
            "Epoch: 29/30..  Running Loss: 2.668.. \n",
            "Epoch: 29/30..  Running Loss: 2.068.. \n",
            "Epoch: 29/30..  Running Loss: 2.573.. \n",
            "Epoch: 29/30..  Running Loss: 2.316.. \n",
            "Epoch: 29/30..  Running Loss: 2.615.. \n",
            "Epoch: 29/30..  Running Loss: 2.128.. \n",
            "Epoch: 29/30..  Running Loss: 2.608.. \n",
            "Epoch: 29/30..  Running Loss: 2.507.. \n",
            "Epoch: 29/30..  Running Loss: 2.330.. \n",
            "Epoch: 29/30..  Running Loss: 2.327.. \n",
            "Epoch: 29/30..  Running Loss: 2.712.. \n",
            "Epoch: 29/30..  Running Loss: 2.241.. \n",
            "Epoch: 29/30..  Running Loss: 2.381.. \n",
            "Epoch: 29/30..  Running Loss: 2.594.. \n",
            "Epoch: 29/30..  Running Loss: 2.466.. \n",
            "Epoch: 29/30..  Running Loss: 2.538.. \n",
            "Epoch: 29/30..  Running Loss: 2.541.. \n",
            "Epoch: 29/30..  Running Loss: 2.311.. \n",
            "Epoch: 29/30..  Running Loss: 2.752.. \n",
            "Epoch: 29/30..  Running Loss: 2.047.. \n",
            "Epoch: 29/30..  Running Loss: 2.419.. \n",
            "Epoch: 29/30..  Running Loss: 2.244.. \n",
            "Epoch: 29/30..  Running Loss: 2.511.. \n",
            "Epoch: 29/30..  Running Loss: 2.442.. \n",
            "Epoch: 29/30..  Running Loss: 2.374.. \n",
            "Epoch: 29/30..  Running Loss: 2.870.. \n",
            "Epoch: 29/30..  Running Loss: 2.353.. \n",
            "Epoch: 29/30..  Running Loss: 2.752.. \n",
            "Epoch: 29/30..  Running Loss: 2.086.. \n",
            "Epoch: 29/30..  Running Loss: 2.290.. \n",
            "Epoch: 29/30..  Running Loss: 2.658.. \n",
            "Epoch: 29/30..  Running Loss: 2.260.. \n",
            "Epoch: 29/30..  Running Loss: 2.141.. \n",
            "Epoch: 29/30..  Running Loss: 2.684.. \n",
            "Epoch: 29/30..  Running Loss: 2.783.. \n",
            "Epoch: 29/30..  Running Loss: 2.549.. \n",
            "Epoch: 29/30..  Running Loss: 2.341.. \n",
            "Epoch: 29/30..  Running Loss: 2.624.. \n",
            "Epoch: 29/30..  Running Loss: 2.665.. \n",
            "Epoch: 29/30..  Running Loss: 2.275.. \n",
            "Epoch: 29/30..  Running Loss: 2.503.. \n",
            "Epoch: 29/30..  Running Loss: 2.124.. \n",
            "Epoch: 29/30..  Running Loss: 2.322.. \n",
            "Epoch: 29/30..  Running Loss: 2.471.. \n",
            "Epoch: 29/30..  Running Loss: 2.479.. \n",
            "Epoch: 29/30..  Running Loss: 2.724.. \n",
            "Epoch: 29/30..  Running Loss: 2.878.. \n",
            "Epoch: 29/30..  Running Loss: 2.560.. \n",
            "Epoch: 29/30..  Running Loss: 2.953.. \n",
            "Epoch: 29/30..  Running Loss: 2.726.. \n",
            "Epoch: 29/30..  Running Loss: 2.612.. \n",
            "Epoch: 29/30..  Running Loss: 2.314.. \n",
            "Epoch: 29/30..  Running Loss: 2.520.. \n",
            "Epoch: 29/30..  Running Loss: 2.375.. \n",
            "Epoch: 29/30..  Running Loss: 2.206.. \n",
            "Epoch: 29/30..  Running Loss: 2.734.. \n",
            "Epoch: 29/30..  Running Loss: 2.053.. \n",
            "Epoch: 29/30..  Running Loss: 2.292.. \n",
            "Epoch: 29/30..  Running Loss: 2.277.. \n",
            "Epoch: 29/30..  Running Loss: 2.076.. \n",
            "Epoch: 29/30..  Running Loss: 2.385.. \n",
            "Epoch: 29/30..  Running Loss: 2.435.. \n",
            "Epoch: 29/30..  Running Loss: 2.422.. \n",
            "Epoch: 29/30..  Running Loss: 2.773.. \n",
            "Epoch: 29/30..  Running Loss: 2.543.. \n",
            "Epoch: 29/30..  Running Loss: 2.461.. \n",
            "Epoch: 29/30..  Running Loss: 2.916.. \n",
            "Epoch: 29/30..  Running Loss: 2.337.. \n",
            "Epoch: 29/30..  Running Loss: 2.392.. \n",
            "Epoch: 29/30..  Running Loss: 2.454.. \n",
            "Epoch: 29/30..  Running Loss: 2.678.. \n",
            "Epoch: 29/30..  Running Loss: 2.853.. \n",
            "Epoch: 29/30..  Running Loss: 2.643.. \n",
            "Epoch: 29/30..  Running Loss: 2.328.. \n",
            "Epoch: 29/30..  Running Loss: 2.680.. \n",
            "Epoch: 29/30..  Running Loss: 2.154.. \n",
            "Epoch: 29/30..  Running Loss: 2.099.. \n",
            "Epoch: 29/30..  Running Loss: 2.156.. \n",
            "Epoch: 29/30..  Running Loss: 2.474.. \n",
            "Epoch: 29/30..  Running Loss: 2.655.. \n",
            "Epoch: 29/30..  Running Loss: 2.535.. \n",
            "Epoch: 29/30..  Running Loss: 2.461.. \n",
            "Epoch: 29/30..  Running Loss: 2.393.. \n",
            "Epoch: 29/30..  Running Loss: 2.868.. \n",
            "Epoch: 29/30..  Running Loss: 2.495.. \n",
            "Epoch: 29/30..  Running Loss: 2.574.. \n",
            "Epoch: 29/30..  Running Loss: 2.304.. \n",
            "Epoch: 29/30..  Running Loss: 2.642.. \n",
            "Epoch: 29/30..  Running Loss: 2.443.. \n",
            "Epoch: 29/30..  Running Loss: 2.145.. \n",
            "Epoch: 29/30..  Running Loss: 2.353.. \n",
            "Epoch: 29/30..  Running Loss: 2.100.. \n",
            "Epoch: 29/30..  Running Loss: 2.009.. \n",
            "Epoch: 29/30..  Running Loss: 2.318.. \n",
            "Epoch: 29/30..  Running Loss: 2.642.. \n",
            "Epoch: 29/30..  Running Loss: 1.991.. \n",
            "Epoch: 29/30..  Running Loss: 2.177.. \n",
            "Epoch: 29/30..  Running Loss: 2.187.. \n",
            "Epoch: 29/30..  Running Loss: 2.511.. \n",
            "Epoch: 29/30..  Running Loss: 2.233.. \n",
            "Epoch: 29/30..  Running Loss: 2.008.. \n",
            "Epoch: 29/30..  Running Loss: 2.125.. \n",
            "Epoch: 29/30..  Running Loss: 2.164.. \n",
            "Epoch: 29/30..  Running Loss: 2.322.. \n",
            "Epoch: 29/30..  Running Loss: 2.203.. \n",
            "Epoch: 29/30..  Running Loss: 2.355.. \n",
            "Epoch: 29/30..  Running Loss: 2.718.. \n",
            "Epoch: 29/30..  Running Loss: 2.491.. \n",
            "Epoch: 29/30..  Running Loss: 2.498.. \n",
            "Epoch: 29/30..  Running Loss: 2.319.. \n",
            "Epoch: 29/30..  Running Loss: 2.498.. \n",
            "Epoch: 29/30..  Running Loss: 2.226.. \n",
            "Epoch: 29/30..  Running Loss: 1.821.. \n",
            "Epoch: 29/30..  Running Loss: 2.237.. \n",
            "Epoch: 29/30..  Running Loss: 1.781.. \n",
            "Epoch: 29/30..  Running Loss: 2.233.. \n",
            "Epoch: 29/30..  Running Loss: 2.301.. \n",
            "Epoch: 29/30..  Running Loss: 2.835.. \n",
            "Epoch: 29/30..  Running Loss: 2.925.. \n",
            "Epoch: 29/30..  Running Loss: 2.170.. \n",
            "Epoch: 29/30..  Running Loss: 2.269.. \n",
            "Epoch: 29/30..  Running Loss: 2.640.. \n",
            "Epoch: 29/30..  Running Loss: 2.294.. \n",
            "Epoch: 29/30..  Running Loss: 2.421.. \n",
            "Epoch: 29/30..  Running Loss: 2.204.. \n",
            "Epoch: 29/30..  Running Loss: 2.429.. \n",
            "Epoch: 29/30..  Running Loss: 2.509.. \n",
            "Epoch: 29/30..  Running Loss: 2.233.. \n",
            "Epoch: 29/30..  Running Loss: 2.313.. \n",
            "Epoch: 29/30..  Running Loss: 2.351.. \n",
            "Epoch: 29/30..  Running Loss: 2.220.. \n",
            "Epoch: 29/30..  Running Loss: 2.340.. \n",
            "Epoch: 29/30..  Running Loss: 2.478.. \n",
            "Epoch: 29/30..  Running Loss: 2.427.. \n",
            "Epoch: 29/30..  Running Loss: 2.156.. \n",
            "Epoch: 29/30..  Running Loss: 2.204.. \n",
            "Epoch: 29/30..  Running Loss: 2.509.. \n",
            "Epoch: 29/30..  Running Loss: 3.029.. \n",
            "Epoch: 29/30..  Running Loss: 2.284.. \n",
            "Epoch: 29/30..  Running Loss: 2.291.. \n",
            "Epoch: 29/30..  Running Loss: 2.303.. \n",
            "Epoch: 29/30..  Running Loss: 2.160.. \n",
            "Epoch: 29/30..  Running Loss: 2.247.. \n",
            "Epoch: 29/30..  Running Loss: 2.538.. \n",
            "Epoch: 29/30..  Running Loss: 2.944.. \n",
            "Epoch: 29/30..  Running Loss: 2.888.. \n",
            "Epoch: 29/30..  Running Loss: 2.135.. \n",
            "Epoch: 29/30..  Running Loss: 2.378.. \n",
            "Epoch: 29/30..  Running Loss: 2.800.. \n",
            "Epoch: 29/30..  Running Loss: 2.154.. \n",
            "Epoch: 29/30..  Running Loss: 2.440.. \n",
            "Epoch: 29/30..  Running Loss: 2.621.. \n",
            "Epoch: 29/30..  Running Loss: 2.813.. \n",
            "Epoch: 29/30..  Running Loss: 1.934.. \n",
            "Epoch: 29/30..  Running Loss: 1.960.. \n",
            "Epoch: 29/30..  Running Loss: 2.175.. \n",
            "Epoch: 29/30..  Running Loss: 2.900.. \n",
            "Epoch: 29/30..  Running Loss: 2.672.. \n",
            "Epoch: 29/30..  Running Loss: 2.562.. \n",
            "Epoch: 29/30..  Running Loss: 2.752.. \n",
            "Epoch: 29/30..  Running Loss: 2.900.. \n",
            "Epoch: 29/30..  Running Loss: 2.960.. \n",
            "Epoch: 29/30..  Running Loss: 2.348.. \n",
            "Epoch: 29/30..  Running Loss: 2.498.. \n",
            "Epoch: 29/30..  Running Loss: 2.262.. \n",
            "Epoch: 29/30..  Running Loss: 2.095.. \n",
            "Epoch: 29/30..  Running Loss: 2.314.. \n",
            "Epoch: 29/30..  Running Loss: 2.766.. \n",
            "Epoch: 29/30..  Running Loss: 2.217.. \n",
            "Epoch: 29/30..  Running Loss: 1.956.. \n",
            "Epoch: 29/30..  Running Loss: 2.397.. \n",
            "Epoch: 29/30..  Running Loss: 2.300.. \n",
            "Epoch: 29/30..  Running Loss: 2.463.. \n",
            "Epoch: 29/30..  Running Loss: 2.431.. \n",
            "Epoch: 29/30..  Running Loss: 2.588.. \n",
            "Epoch: 29/30..  Running Loss: 2.501.. \n",
            "Epoch: 29/30..  Running Loss: 2.644.. \n",
            "Epoch: 29/30..  Running Loss: 2.568.. \n",
            "Epoch: 29/30..  Running Loss: 2.455.. \n",
            "Epoch: 29/30..  Running Loss: 2.359.. \n",
            "Epoch: 29/30..  Running Loss: 2.272.. \n",
            "Epoch: 29/30..  Running Loss: 2.458.. \n",
            "Epoch: 29/30..  Running Loss: 2.714.. \n",
            "Epoch: 29/30..  Running Loss: 2.698.. \n",
            "Epoch: 29/30..  Running Loss: 2.320.. \n",
            "Epoch: 29/30..  Running Loss: 2.252.. \n",
            "Epoch: 29/30..  Running Loss: 2.097.. \n",
            "Epoch: 29/30..  Running Loss: 2.236.. \n",
            "Epoch: 29/30..  Running Loss: 2.899.. \n",
            "Epoch: 29/30..  Running Loss: 2.728.. \n",
            "Epoch: 29/30..  Running Loss: 2.233.. \n",
            "Epoch: 29/30..  Running Loss: 2.525.. \n",
            "Epoch: 29/30..  Running Loss: 2.461.. \n",
            "Epoch: 29/30..  Running Loss: 2.764.. \n",
            "Epoch: 29/30..  Running Loss: 2.341.. \n",
            "Epoch: 29/30..  Running Loss: 2.390.. \n",
            "Epoch: 29/30..  Running Loss: 2.689.. \n",
            "Epoch: 29/30..  Running Loss: 2.709.. \n",
            "Epoch: 29/30..  Running Loss: 2.677.. \n",
            "Epoch: 29/30..  Running Loss: 2.087.. \n",
            "Epoch: 29/30..  Running Loss: 2.401.. \n",
            "Epoch: 29/30..  Running Loss: 2.688.. \n",
            "Epoch: 29/30..  Running Loss: 2.429.. \n",
            "Epoch: 29/30..  Running Loss: 1.921.. \n",
            "Epoch: 29/30..  Running Loss: 2.439.. \n",
            "Epoch: 29/30..  Running Loss: 2.662.. \n",
            "Epoch: 29/30..  Running Loss: 2.539.. \n",
            "Epoch: 29/30..  Running Loss: 2.415.. \n",
            "Epoch: 29/30..  Running Loss: 2.818.. \n",
            "Epoch: 29/30..  Running Loss: 2.362.. \n",
            "Epoch: 29/30..  Running Loss: 2.336.. \n",
            "Epoch: 29/30..  Running Loss: 2.243.. \n",
            "Epoch: 29/30..  Running Loss: 2.571.. \n",
            "Epoch: 29/30..  Running Loss: 2.564.. \n",
            "Epoch: 29/30..  Running Loss: 2.364.. \n",
            "Epoch: 29/30..  Running Loss: 2.500.. \n",
            "Epoch: 29/30..  Running Loss: 2.242.. \n",
            "Epoch: 29/30..  Running Loss: 2.379.. \n",
            "Epoch: 29/30..  Running Loss: 2.644.. \n",
            "Epoch: 29/30..  Running Loss: 2.684.. \n",
            "Epoch: 29/30..  Running Loss: 2.813.. \n",
            "Epoch: 29/30..  Running Loss: 2.163.. \n",
            "Epoch: 29/30..  Running Loss: 2.910.. \n",
            "Epoch: 29/30..  Running Loss: 2.637.. \n",
            "Epoch: 29/30..  Running Loss: 2.443.. \n",
            "Epoch: 29/30..  Running Loss: 2.694.. \n",
            "Epoch: 29/30..  Running Loss: 2.693.. \n",
            "Epoch: 29/30..  Running Loss: 2.404.. \n",
            "Epoch: 29/30..  Running Loss: 2.107.. \n",
            "Epoch: 29/30..  Running Loss: 2.258.. \n",
            "Epoch: 29/30..  Running Loss: 2.329.. \n",
            "Epoch: 29/30..  Running Loss: 2.793.. \n",
            "Epoch: 29/30..  Running Loss: 2.263.. \n",
            "Epoch: 29/30..  Running Loss: 2.329.. \n",
            "Epoch: 29/30..  Running Loss: 2.457.. \n",
            "Epoch: 29/30..  Running Loss: 2.381.. \n",
            "Epoch: 29/30..  Running Loss: 2.903.. \n",
            "Epoch: 29/30..  Running Loss: 2.230.. \n",
            "Epoch: 29/30..  Running Loss: 2.627.. \n",
            "Epoch: 29/30..  Running Loss: 2.402.. \n",
            "Epoch: 29/30..  Running Loss: 2.553.. \n",
            "Epoch: 29/30..  Running Loss: 3.026.. \n",
            "Epoch: 29/30..  Running Loss: 2.348.. \n",
            "Epoch: 29/30..  Running Loss: 2.400.. \n",
            "Epoch: 29/30..  Running Loss: 2.626.. \n",
            "Epoch: 29/30..  Running Loss: 2.375.. \n",
            "Epoch: 29/30..  Running Loss: 2.604.. \n",
            "Epoch: 29/30..  Running Loss: 2.337.. \n",
            "Epoch: 29/30..  Running Loss: 2.481.. \n",
            "Epoch: 29/30..  Running Loss: 2.582.. \n",
            "Epoch: 29/30..  Running Loss: 2.290.. \n",
            "Epoch: 29/30..  Running Loss: 2.856.. \n",
            "Epoch: 29/30..  Running Loss: 2.304.. \n",
            "Epoch: 29/30..  Running Loss: 2.198.. \n",
            "Epoch: 29/30..  Running Loss: 2.805.. \n",
            "Epoch: 29/30..  Running Loss: 2.377.. \n",
            "Epoch: 29/30..  Running Loss: 2.277.. \n",
            "Epoch: 29/30..  Running Loss: 2.341.. \n",
            "Epoch: 29/30..  Running Loss: 1.992.. \n",
            "Epoch: 29/30..  Running Loss: 2.690.. \n",
            "Epoch: 29/30..  Running Loss: 2.276.. \n",
            "Epoch: 29/30..  Running Loss: 2.717.. \n",
            "Epoch: 29/30..  Running Loss: 2.202.. \n",
            "Epoch: 29/30..  Running Loss: 2.170.. \n",
            "Epoch: 29/30..  Running Loss: 2.243.. \n",
            "Epoch: 29/30..  Running Loss: 2.504.. \n",
            "Epoch: 29/30..  Running Loss: 2.311.. \n",
            "Epoch: 29/30..  Running Loss: 2.472.. \n",
            "Epoch: 29/30..  Running Loss: 2.491.. \n",
            "Epoch: 29/30..  Running Loss: 2.619.. \n",
            "Epoch: 29/30..  Running Loss: 2.007.. \n",
            "Epoch: 29/30..  Running Loss: 1.648.. \n",
            "Epoch: 29/30..  Running Loss: 1.947.. \n",
            "Epoch: 29/30..  Running Loss: 2.099.. \n",
            "Epoch: 29/30..  Running Loss: 2.391.. \n",
            "Epoch: 29/30..  Running Loss: 2.112.. \n",
            "Epoch: 29/30..  Running Loss: 2.308.. \n",
            "Epoch: 29/30..  Running Loss: 2.432.. \n",
            "Epoch: 29/30..  Running Loss: 2.720.. \n",
            "Epoch: 29/30..  Running Loss: 2.526.. \n",
            "Epoch: 29/30..  Running Loss: 2.371.. \n",
            "Epoch: 29/30..  Running Loss: 2.211.. \n",
            "Epoch: 29/30..  Running Loss: 2.652.. \n",
            "Epoch: 29/30..  Running Loss: 2.072.. \n",
            "Epoch: 29/30..  Running Loss: 2.353.. \n",
            "Epoch: 29/30..  Running Loss: 2.291.. \n",
            "Epoch: 29/30..  Running Loss: 2.457.. \n",
            "Epoch: 29/30..  Running Loss: 2.449.. \n",
            "Epoch: 29/30..  Running Loss: 2.182.. \n",
            "Epoch: 29/30..  Running Loss: 2.235.. \n",
            "Epoch: 29/30..  Running Loss: 2.537.. \n",
            "Epoch: 29/30..  Running Loss: 2.448.. \n",
            "Epoch: 29/30..  Running Loss: 2.660.. \n",
            "Epoch: 29/30..  Running Loss: 2.599.. \n",
            "Epoch: 29/30..  Running Loss: 2.218.. \n",
            "Epoch: 29/30..  Running Loss: 2.343.. \n",
            "Epoch: 29/30..  Running Loss: 2.268.. \n",
            "Epoch: 29/30..  Running Loss: 2.119.. \n",
            "Epoch: 29/30..  Running Loss: 2.475.. \n",
            "Epoch: 29/30..  Running Loss: 2.371.. \n",
            "Epoch: 29/30..  Running Loss: 2.085.. \n",
            "Epoch: 29/30..  Running Loss: 1.848.. \n",
            "Epoch: 29/30..  Running Loss: 2.007.. \n",
            "Epoch: 29/30..  Running Loss: 2.305.. \n",
            "Epoch: 29/30..  Running Loss: 2.299.. \n",
            "Epoch: 29/30..  Running Loss: 1.246.. \n",
            "Epoch: 29/30..  Running Loss: 2.056.. \n",
            "Epoch: 29/30..  Running Loss: 2.161.. \n",
            "Epoch: 29/30..  Running Loss: 2.531.. \n",
            "Epoch: 29/30..  Running Loss: 1.154.. \n",
            "Epoch: 29/30..  Running Loss: 2.020.. \n",
            "Epoch: 29/30..  Running Loss: 1.690.. \n",
            "Epoch: 29/30..  Running Loss: 2.045.. \n",
            "Epoch: 29/30..  Running Loss: 1.079.. \n",
            "Epoch: 29/30..  Running Loss: 2.060.. \n",
            "Epoch: 29/30..  Running Loss: 2.215.. \n",
            "Epoch: 29/30..  Running Loss: 2.103.. \n",
            "Epoch: 29/30..  Running Loss: 1.393.. \n",
            "Epoch: 29/30..  Running Loss: 2.346.. \n",
            "Epoch: 29/30..  Running Loss: 2.303.. \n",
            "Epoch: 29/30..  Running Loss: 2.318.. \n",
            "Epoch: 29/30..  Running Loss: 2.555.. \n",
            "Epoch: 29/30..  Running Loss: 2.749.. \n",
            "Epoch: 29/30..  Running Loss: 2.431.. \n",
            "Epoch: 29/30..  Running Loss: 2.600.. \n",
            "Epoch: 29/30..  Running Loss: 2.115.. \n",
            "Epoch: 29/30..  Running Loss: 2.299.. \n",
            "Epoch: 29/30..  Running Loss: 2.143.. \n",
            "Epoch: 29/30..  Running Loss: 2.730.. \n",
            "Epoch: 29/30..  Running Loss: 2.067.. \n",
            "Epoch: 29/30..  Running Loss: 2.295.. \n",
            "Epoch: 29/30..  Running Loss: 2.473.. \n",
            "Epoch: 29/30..  Running Loss: 2.398.. \n",
            "Epoch: 29/30..  Running Loss: 1.970.. \n",
            "Epoch: 29/30..  Running Loss: 1.687.. \n",
            "Epoch: 29/30..  Running Loss: 2.672.. \n",
            "Epoch: 29/30..  Running Loss: 2.505.. \n",
            "Epoch: 29/30..  Running Loss: 1.816.. \n",
            "Epoch: 29/30..  Running Loss: 2.354.. \n",
            "Epoch: 29/30..  Running Loss: 2.699.. \n",
            "Epoch: 29/30..  Running Loss: 2.784.. \n",
            "Epoch: 29/30..  Running Loss: 2.606.. \n",
            "Epoch: 29/30..  Running Loss: 2.495.. \n",
            "Epoch: 29/30..  Running Loss: 2.600.. \n",
            "Epoch: 29/30..  Running Loss: 2.460.. \n",
            "Epoch: 29/30..  Running Loss: 2.562.. \n",
            "Epoch: 29/30..  Running Loss: 2.779.. \n",
            "Epoch: 29/30..  Running Loss: 2.199.. \n",
            "Epoch: 29/30..  Running Loss: 2.114.. \n",
            "Epoch: 29/30..  Running Loss: 2.446.. \n",
            "Epoch: 29/30..  Running Loss: 2.171.. \n",
            "Epoch: 29/30..  Running Loss: 2.874.. \n",
            "Epoch: 29/30..  Running Loss: 2.301.. \n",
            "Epoch: 29/30..  Running Loss: 2.360.. \n",
            "Epoch: 29/30..  Running Loss: 2.099.. \n",
            "Epoch: 29/30..  Running Loss: 2.058.. \n",
            "Epoch: 29/30..  Running Loss: 1.836.. \n",
            "Epoch: 29/30..  Running Loss: 2.532.. \n",
            "Epoch: 29/30..  Running Loss: 2.155.. \n",
            "Epoch: 29/30..  Running Loss: 2.673.. \n",
            "Epoch: 29/30..  Running Loss: 2.967.. \n",
            "Epoch: 29/30..  Running Loss: 2.254.. \n",
            "Epoch: 29/30..  Running Loss: 2.324.. \n",
            "Epoch: 29/30..  Running Loss: 2.205.. \n",
            "Epoch: 29/30..  Running Loss: 1.866.. \n",
            "Epoch: 29/30..  Running Loss: 1.663.. \n",
            "Epoch: 29/30..  Running Loss: 1.412.. \n",
            "Epoch: 29/30..  Running Loss: 2.342.. \n",
            "Epoch: 29/30..  Running Loss: 1.591.. \n",
            "Epoch: 29/30..  Running Loss: 1.952.. \n",
            "Epoch: 29/30..  Running Loss: 2.118.. \n",
            "Epoch: 29/30..  Running Loss: 2.143.. \n",
            "Epoch: 29/30..  Running Loss: 2.452.. \n",
            "Epoch: 29/30..  Running Loss: 2.872.. \n",
            "Epoch: 29/30..  Running Loss: 2.461.. \n",
            "Epoch: 29/30..  Running Loss: 2.542.. \n",
            "Epoch: 29/30..  Running Loss: 2.311.. \n",
            "Epoch: 29/30..  Running Loss: 2.519.. \n",
            "Epoch: 29/30..  Running Loss: 2.315.. \n",
            "Epoch: 29/30..  Running Loss: 2.761.. \n",
            "Epoch: 29/30..  Running Loss: 2.386.. \n",
            "Epoch: 29/30..  Running Loss: 2.286.. \n",
            "Epoch: 29/30..  Running Loss: 2.644.. \n",
            "Epoch: 29/30..  Running Loss: 2.673.. \n",
            "Epoch: 29/30..  Running Loss: 2.381.. \n",
            "Epoch: 29/30..  Running Loss: 2.127.. \n",
            "Epoch: 29/30..  Running Loss: 2.258.. \n",
            "Epoch: 29/30..  Running Loss: 2.867.. \n",
            "Epoch: 29/30..  Running Loss: 1.786.. \n",
            "Epoch: 29/30..  Running Loss: 2.058.. \n",
            "Epoch: 29/30..  Running Loss: 2.216.. \n",
            "Epoch: 29/30..  Running Loss: 2.391.. \n",
            "Epoch: 29/30..  Running Loss: 2.238.. \n",
            "Epoch: 29/30..  Running Loss: 2.083.. \n",
            "Epoch: 29/30..  Running Loss: 2.932.. \n",
            "Epoch: 29/30..  Running Loss: 2.417.. \n",
            "Epoch: 29/30..  Running Loss: 2.486.. \n",
            "Epoch: 29/30..  Running Loss: 2.402.. \n",
            "Epoch: 29/30..  Running Loss: 2.614.. \n",
            "Epoch: 29/30..  Running Loss: 2.206.. \n",
            "Epoch: 29/30..  Running Loss: 2.356.. \n",
            "Epoch: 29/30..  Running Loss: 2.213.. \n",
            "Epoch: 29/30..  Running Loss: 2.406.. \n",
            "Epoch: 29/30..  Running Loss: 2.680.. \n",
            "Epoch: 29/30..  Running Loss: 2.530.. \n",
            "Epoch: 29/30..  Running Loss: 2.362.. \n",
            "Epoch: 29/30..  Running Loss: 2.310.. \n",
            "Epoch: 29/30..  Running Loss: 2.146.. \n",
            "Epoch: 29/30..  Running Loss: 2.499.. \n",
            "Epoch: 29/30..  Running Loss: 2.829.. \n",
            "Epoch: 29/30..  Running Loss: 2.589.. \n",
            "Epoch: 29/30..  Running Loss: 2.180.. \n",
            "Epoch: 29/30..  Running Loss: 2.757.. \n",
            "Epoch: 29/30..  Running Loss: 2.133.. \n",
            "Epoch: 29/30..  Running Loss: 2.237.. \n",
            "Epoch: 29/30..  Running Loss: 2.057.. \n",
            "Epoch: 29/30..  Running Loss: 2.319.. \n",
            "Epoch: 29/30..  Running Loss: 1.683.. \n",
            "Epoch: 29/30..  Running Loss: 2.665.. \n",
            "Epoch: 29/30..  Running Loss: 2.658.. \n",
            "Epoch: 29/30..  Running Loss: 2.148.. \n",
            "Epoch: 29/30..  Running Loss: 2.574.. \n",
            "Epoch: 29/30..  Running Loss: 2.536.. \n",
            "Epoch: 29/30..  Running Loss: 2.563.. \n",
            "Epoch: 29/30..  Running Loss: 2.634.. \n",
            "Epoch: 29/30..  Running Loss: 2.210.. \n",
            "Epoch: 29/30..  Running Loss: 2.462.. \n",
            "Epoch: 29/30..  Running Loss: 2.387.. \n",
            "Epoch: 29/30..  Running Loss: 1.774.. \n",
            "Epoch: 29/30..  Running Loss: 2.473.. \n",
            "Epoch: 29/30..  Running Loss: 2.253.. \n",
            "Epoch: 29/30..  Running Loss: 2.599.. \n",
            "Epoch: 29/30..  Running Loss: 2.230.. \n",
            "Epoch: 29/30..  Running Loss: 2.509.. \n",
            "Epoch: 29/30..  Running Loss: 2.313.. \n",
            "Epoch: 29/30..  Running Loss: 2.672.. \n",
            "Epoch: 29/30..  Running Loss: 2.524.. \n",
            "Epoch: 29/30..  Running Loss: 2.417.. \n",
            "Epoch: 29/30..  Running Loss: 2.578.. \n",
            "Epoch: 29/30..  Running Loss: 2.297.. \n",
            "Epoch: 29/30..  Running Loss: 2.354.. \n",
            "Epoch: 29/30..  Running Loss: 2.074.. \n",
            "Epoch: 29/30..  Running Loss: 2.694.. \n",
            "Epoch: 29/30..  Running Loss: 2.530.. \n",
            "Epoch: 29/30..  Running Loss: 2.319.. \n",
            "Epoch: 29/30..  Running Loss: 2.411.. \n",
            "Epoch: 29/30..  Running Loss: 2.301.. \n",
            "Epoch: 29/30..  Running Loss: 2.594.. \n",
            "Epoch: 29/30..  Running Loss: 2.370.. \n",
            "Epoch: 29/30..  Running Loss: 2.536.. \n",
            "Epoch: 29/30..  Running Loss: 2.486.. \n",
            "Epoch: 29/30..  Running Loss: 2.753.. \n",
            "Epoch: 29/30..  Running Loss: 2.549.. \n",
            "Epoch: 29/30..  Running Loss: 2.105.. \n",
            "Epoch: 29/30..  Running Loss: 2.349.. \n",
            "Epoch: 29/30..  Running Loss: 2.493.. \n",
            "Epoch: 29/30..  Running Loss: 2.713.. \n",
            "Epoch: 29/30..  Running Loss: 2.070.. \n",
            "Epoch: 29/30..  Running Loss: 2.500.. \n",
            "Epoch: 29/30..  Running Loss: 2.674.. \n",
            "Epoch: 29/30..  Running Loss: 2.109.. \n",
            "Epoch: 29/30..  Running Loss: 1.921.. \n",
            "Epoch: 29/30..  Running Loss: 2.740.. \n",
            "Epoch: 29/30..  Running Loss: 2.479.. \n",
            "Epoch: 29/30..  Running Loss: 2.678.. \n",
            "Epoch: 29/30..  Running Loss: 2.271.. \n",
            "Epoch: 29/30..  Running Loss: 1.818.. \n",
            "Epoch: 29/30..  Running Loss: 2.388.. \n",
            "Epoch: 29/30..  Running Loss: 2.653.. \n",
            "Epoch: 29/30..  Running Loss: 2.079.. \n",
            "Epoch: 29/30..  Running Loss: 2.197.. \n",
            "Epoch: 29/30..  Running Loss: 2.345.. \n",
            "Epoch: 29/30..  Running Loss: 2.591.. \n",
            "Epoch: 29/30..  Running Loss: 2.437.. \n",
            "Epoch: 29/30..  Running Loss: 2.331.. \n",
            "Epoch: 29/30..  Running Loss: 2.456.. \n",
            "Epoch: 29/30..  Running Loss: 2.223.. \n",
            "Epoch: 29/30..  Running Loss: 2.088.. \n",
            "Epoch: 29/30..  Running Loss: 2.269.. \n",
            "Epoch: 29/30..  Running Loss: 2.279.. \n",
            "Epoch: 29/30..  Running Loss: 2.022.. \n",
            "Epoch: 29/30..  Running Loss: 2.195.. \n",
            "Epoch: 29/30..  Running Loss: 2.307.. \n",
            "Epoch: 29/30..  Running Loss: 2.241.. \n",
            "Epoch: 29/30..  Running Loss: 2.376.. \n",
            "Epoch: 29/30..  Running Loss: 2.663.. \n",
            "Epoch: 29/30..  Running Loss: 2.453.. \n",
            "Epoch: 29/30..  Running Loss: 2.437.. \n",
            "Epoch: 29/30..  Running Loss: 2.285.. \n",
            "Epoch: 29/30..  Running Loss: 2.562.. \n",
            "Epoch: 29/30..  Running Loss: 2.657.. \n",
            "Epoch: 29/30..  Running Loss: 2.497.. \n",
            "Epoch: 29/30..  Running Loss: 2.514.. \n",
            "Epoch: 29/30..  Running Loss: 2.352.. \n",
            "Epoch: 29/30..  Running Loss: 2.014.. \n",
            "Epoch: 29/30..  Running Loss: 2.353.. \n",
            "Epoch: 29/30..  Running Loss: 2.559.. \n",
            "Epoch: 29/30..  Running Loss: 2.444.. \n",
            "Epoch: 29/30..  Running Loss: 2.187.. \n",
            "Epoch: 29/30..  Running Loss: 2.612.. \n",
            "Epoch: 29/30..  Running Loss: 2.355.. \n",
            "Epoch: 29/30..  Running Loss: 1.842.. \n",
            "Epoch: 29/30..  Running Loss: 2.454.. \n",
            "Epoch: 29/30..  Running Loss: 2.613.. \n",
            "Epoch: 29/30..  Running Loss: 2.084.. \n",
            "Epoch: 29/30..  Running Loss: 2.557.. \n",
            "Epoch: 29/30..  Running Loss: 2.409.. \n",
            "Epoch: 29/30..  Running Loss: 2.601.. \n",
            "Epoch: 29/30..  Running Loss: 2.386.. \n",
            "Epoch: 29/30..  Running Loss: 2.765.. \n",
            "Epoch: 29/30..  Running Loss: 2.564.. \n",
            "Epoch: 29/30..  Running Loss: 2.383.. \n",
            "Epoch: 29/30..  Running Loss: 2.446.. \n",
            "Epoch: 29/30..  Running Loss: 2.249.. \n",
            "Epoch: 29/30..  Running Loss: 2.380.. \n",
            "Epoch: 29/30..  Running Loss: 2.563.. \n",
            "Epoch: 29/30..  Running Loss: 2.315.. \n",
            "Epoch: 29/30..  Running Loss: 2.460.. \n",
            "Epoch: 29/30..  Running Loss: 2.174.. \n",
            "Epoch: 29/30..  Running Loss: 2.415.. \n",
            "Epoch: 29/30..  Running Loss: 2.822.. \n",
            "Epoch: 29/30..  Running Loss: 2.718.. \n",
            "Epoch: 29/30..  Running Loss: 2.201.. \n",
            "Epoch: 29/30..  Running Loss: 2.186.. \n",
            "Epoch: 29/30..  Running Loss: 1.891.. \n",
            "Epoch: 29/30..  Running Loss: 2.906.. \n",
            "Epoch: 29/30..  Running Loss: 2.460.. \n",
            "Epoch: 29/30..  Running Loss: 2.623.. \n",
            "Epoch: 29/30..  Running Loss: 2.006.. \n",
            "Epoch: 29/30..  Running Loss: 1.968.. \n",
            "Epoch: 29/30..  Running Loss: 2.305.. \n",
            "Epoch: 29/30..  Running Loss: 2.353.. \n",
            "Epoch: 29/30..  Running Loss: 1.831.. \n",
            "Epoch: 29/30..  Running Loss: 1.869.. \n",
            "Epoch: 29/30..  Running Loss: 1.672.. \n",
            "Epoch: 29/30..  Running Loss: 2.614.. \n",
            "Epoch: 29/30..  Running Loss: 2.806.. \n",
            "Epoch: 29/30..  Running Loss: 2.650.. \n",
            "Epoch: 29/30..  Running Loss: 2.852.. \n",
            "Epoch: 29/30..  Running Loss: 2.426.. \n",
            "Epoch: 29/30..  Running Loss: 2.347.. \n",
            "Epoch: 29/30..  Running Loss: 2.735.. \n",
            "Epoch: 29/30..  Running Loss: 2.154.. \n",
            "Epoch: 29/30..  Running Loss: 2.532.. \n",
            "Epoch: 29/30..  Running Loss: 2.192.. \n",
            "Epoch: 29/30..  Running Loss: 2.561.. \n",
            "Epoch: 29/30..  Running Loss: 2.222.. \n",
            "Epoch: 29/30..  Running Loss: 2.259.. \n",
            "Epoch: 29/30..  Running Loss: 2.060.. \n",
            "Epoch: 29/30..  Running Loss: 2.621.. \n",
            "Epoch: 29/30..  Running Loss: 2.439.. \n",
            "Epoch: 29/30..  Running Loss: 2.555.. \n",
            "Epoch: 29/30..  Running Loss: 2.536.. \n",
            "Epoch: 29/30..  Running Loss: 2.274.. \n",
            "Epoch: 29/30..  Running Loss: 2.542.. \n",
            "Epoch: 29/30..  Running Loss: 2.357.. \n",
            "Epoch: 29/30..  Running Loss: 2.643.. \n",
            "Epoch: 29/30..  Running Loss: 2.036.. \n",
            "Epoch: 29/30..  Running Loss: 2.467.. \n",
            "Epoch: 29/30..  Running Loss: 2.562.. \n",
            "Epoch: 29/30..  Running Loss: 2.280.. \n",
            "Epoch: 29/30..  Running Loss: 2.435.. \n",
            "Epoch: 29/30..  Running Loss: 2.775.. \n",
            "Epoch: 29/30..  Running Loss: 2.816.. \n",
            "Epoch: 29/30..  Running Loss: 2.716.. \n",
            "Epoch: 29/30..  Running Loss: 2.302.. \n",
            "Epoch: 29/30..  Running Loss: 2.787.. \n",
            "Epoch: 29/30..  Running Loss: 2.286.. \n",
            "Epoch: 29/30..  Running Loss: 2.383.. \n",
            "Epoch: 29/30..  Running Loss: 2.531.. \n",
            "Epoch: 29/30..  Running Loss: 2.494.. \n",
            "Epoch: 29/30..  Running Loss: 2.205.. \n",
            "Epoch: 29/30..  Running Loss: 2.485.. \n",
            "Epoch: 29/30..  Running Loss: 2.308.. \n",
            "Epoch: 29/30..  Running Loss: 2.430.. \n",
            "Epoch: 29/30..  Running Loss: 2.638.. \n",
            "Epoch: 29/30..  Running Loss: 2.619.. \n",
            "Epoch: 29/30..  Running Loss: 2.650.. \n",
            "Epoch: 29/30..  Running Loss: 2.499.. \n",
            "Epoch: 29/30..  Running Loss: 2.752.. \n",
            "Epoch: 29/30..  Running Loss: 2.310.. \n",
            "Epoch: 29/30..  Running Loss: 2.624.. \n",
            "Epoch: 29/30..  Running Loss: 2.517.. \n",
            "Epoch: 29/30..  Running Loss: 2.318.. \n",
            "Epoch: 29/30..  Running Loss: 2.478.. \n",
            "Epoch: 29/30..  Running Loss: 2.808.. \n",
            "Epoch: 29/30..  Running Loss: 2.589.. \n",
            "Epoch: 29/30..  Running Loss: 2.476.. \n",
            "Epoch: 29/30..  Running Loss: 2.362.. \n",
            "Epoch: 29/30..  Running Loss: 2.766.. \n",
            "Epoch: 29/30..  Running Loss: 2.228.. \n",
            "Epoch: 29/30..  Running Loss: 2.285.. \n",
            "Epoch: 29/30..  Running Loss: 2.355.. \n",
            "Epoch: 29/30..  Running Loss: 2.421.. \n",
            "Epoch: 29/30..  Running Loss: 2.052.. \n",
            "Epoch: 29/30..  Running Loss: 2.001.. \n",
            "Epoch: 29/30..  Running Loss: 2.033.. \n",
            "Epoch: 29/30..  Running Loss: 2.200.. \n",
            "Epoch: 29/30..  Running Loss: 1.738.. \n",
            "Epoch: 29/30..  Running Loss: 1.747.. \n",
            "Epoch: 29/30..  Running Loss: 2.043.. \n",
            "Epoch: 29/30..  Running Loss: 2.249.. \n",
            "Epoch: 29/30..  Running Loss: 2.088.. \n",
            "Epoch: 29/30..  Running Loss: 2.502.. \n",
            "Epoch: 29/30..  Running Loss: 2.776.. \n",
            "Epoch: 29/30..  Running Loss: 2.356.. \n",
            "Epoch: 29/30..  Running Loss: 2.655.. \n",
            "Epoch: 29/30..  Running Loss: 2.240.. \n",
            "Epoch: 29/30..  Running Loss: 2.092.. \n",
            "Epoch: 29/30..  Running Loss: 2.200.. \n",
            "Epoch: 29/30..  Running Loss: 2.357.. \n",
            "Epoch: 29/30..  Running Loss: 2.645.. \n",
            "Epoch: 29/30..  Running Loss: 2.475.. \n",
            "Epoch: 29/30..  Running Loss: 2.355.. \n",
            "Epoch: 29/30..  Running Loss: 2.233.. \n",
            "Epoch: 29/30..  Running Loss: 2.375.. \n",
            "Epoch: 29/30..  Running Loss: 2.202.. \n",
            "Epoch: 29/30..  Running Loss: 2.345.. \n",
            "Epoch: 29/30..  Running Loss: 2.017.. \n",
            "Epoch: 29/30..  Running Loss: 2.232.. \n",
            "Epoch: 29/30..  Running Loss: 2.512.. \n",
            "Epoch: 29/30..  Running Loss: 2.709.. \n",
            "Epoch: 29/30..  Running Loss: 2.365.. \n",
            "Epoch: 29/30..  Running Loss: 2.257.. \n",
            "Epoch: 29/30..  Running Loss: 2.583.. \n",
            "Epoch: 29/30..  Running Loss: 2.313.. \n",
            "Epoch: 29/30..  Running Loss: 2.490.. \n",
            "Epoch: 29/30..  Running Loss: 2.572.. \n",
            "Epoch: 29/30..  Running Loss: 2.163.. \n",
            "Epoch: 29/30..  Running Loss: 2.066.. \n",
            "Epoch: 29/30..  Running Loss: 2.546.. \n",
            "Epoch: 29/30..  Running Loss: 2.669.. \n",
            "Epoch: 29/30..  Running Loss: 3.183.. \n",
            "Epoch: 29/30..  Running Loss: 2.112.. \n",
            "Epoch: 29/30..  Running Loss: 2.408.. \n",
            "Epoch: 29/30..  Running Loss: 2.012.. \n",
            "Epoch: 29/30..  Running Loss: 2.240.. \n",
            "Epoch: 29/30..  Running Loss: 2.135.. \n",
            "Epoch: 29/30..  Running Loss: 2.499.. \n",
            "Epoch: 29/30..  Running Loss: 2.471.. \n",
            "Epoch: 29/30..  Running Loss: 2.453.. \n",
            "Epoch: 29/30..  Running Loss: 2.384.. \n",
            "Epoch: 29/30..  Running Loss: 2.671.. \n",
            "Epoch: 29/30..  Running Loss: 2.649.. \n",
            "Epoch: 29/30..  Running Loss: 2.288.. \n",
            "Epoch: 29/30..  Running Loss: 2.518.. \n",
            "Epoch: 29/30..  Running Loss: 2.370.. \n",
            "Epoch: 29/30..  Running Loss: 2.343.. \n",
            "Epoch: 29/30..  Running Loss: 2.238.. \n",
            "Epoch: 29/30..  Running Loss: 2.451.. \n",
            "Epoch: 29/30..  Running Loss: 2.164.. \n",
            "Epoch: 29/30..  Running Loss: 2.478.. \n",
            "Epoch: 29/30..  Running Loss: 1.666.. \n",
            "Epoch: 29/30..  Running Loss: 2.477.. \n",
            "Epoch: 29/30..  Running Loss: 2.725.. \n",
            "Epoch: 29/30..  Running Loss: 1.630.. \n",
            "Epoch: 29/30..  Running Loss: 2.126.. \n",
            "Epoch: 29/30..  Running Loss: 2.076.. \n",
            "Epoch: 29/30..  Running Loss: 2.682.. \n",
            "Epoch: 29/30..  Running Loss: 1.578.. \n",
            "Epoch: 29/30..  Running Loss: 2.196.. \n",
            "Epoch: 29/30..  Running Loss: 2.333.. \n",
            "Epoch: 29/30..  Running Loss: 1.916.. \n",
            "Epoch: 29/30..  Running Loss: 2.391.. \n",
            "Epoch: 29/30..  Running Loss: 2.268.. \n",
            "Epoch: 29/30..  Running Loss: 2.318.. \n",
            "Epoch: 29/30..  Running Loss: 2.582.. \n",
            "Epoch: 29/30..  Running Loss: 2.551.. \n",
            "Epoch: 29/30..  Running Loss: 2.130.. \n",
            "Epoch: 29/30..  Running Loss: 1.767.. \n",
            "Epoch: 29/30..  Running Loss: 2.323.. \n",
            "Epoch: 29/30..  Running Loss: 2.722.. \n",
            "Epoch: 29/30..  Running Loss: 2.542.. \n",
            "Epoch: 29/30..  Running Loss: 2.493.. \n",
            "Epoch: 29/30..  Running Loss: 2.531.. \n",
            "Epoch: 29/30..  Running Loss: 2.590.. \n",
            "Epoch: 29/30..  Running Loss: 2.547.. \n",
            "Epoch: 29/30..  Running Loss: 2.095.. \n",
            "Epoch: 29/30..  Running Loss: 2.147.. \n",
            "Epoch: 29/30..  Running Loss: 2.389.. \n",
            "Epoch: 29/30..  Running Loss: 2.384.. \n",
            "Epoch: 29/30..  Running Loss: 2.300.. \n",
            "Epoch: 29/30..  Running Loss: 2.458.. \n",
            "Epoch: 29/30..  Running Loss: 2.444.. \n",
            "Epoch: 29/30..  Running Loss: 2.866.. \n",
            "Epoch: 29/30..  Running Loss: 2.195.. \n",
            "Epoch: 29/30..  Running Loss: 2.704.. \n",
            "Epoch: 29/30..  Running Loss: 2.014.. \n",
            "Epoch: 29/30..  Running Loss: 2.269.. \n",
            "Epoch: 29/30..  Running Loss: 1.865.. \n",
            "Epoch: 29/30..  Running Loss: 2.382.. \n",
            "Epoch: 29/30..  Running Loss: 2.452.. \n",
            "Epoch: 29/30..  Running Loss: 2.669.. \n",
            "Epoch: 29/30..  Running Loss: 1.794.. \n",
            "Epoch: 29/30..  Running Loss: 2.006.. \n",
            "Epoch: 29/30..  Running Loss: 1.431.. \n",
            "Epoch: 29/30..  Running Loss: 2.106.. \n",
            "Epoch: 29/30..  Running Loss: 2.512.. \n",
            "Epoch: 29/30..  Running Loss: 2.285.. \n",
            "Epoch: 29/30..  Running Loss: 2.426.. \n",
            "Epoch: 29/30..  Running Loss: 1.814.. \n",
            "Epoch: 29/30..  Running Loss: 2.501.. \n",
            "Epoch: 29/30..  Running Loss: 2.854.. \n",
            "Epoch: 29/30..  Running Loss: 2.574.. \n",
            "Epoch: 29/30..  Running Loss: 2.488.. \n",
            "Epoch: 29/30..  Running Loss: 2.219.. \n",
            "Epoch: 29/30..  Running Loss: 2.290.. \n",
            "Epoch: 29/30..  Running Loss: 2.460.. \n",
            "Epoch: 29/30..  Running Loss: 2.144.. \n",
            "Epoch: 29/30..  Running Loss: 2.456.. \n",
            "Epoch: 29/30..  Running Loss: 1.996.. \n",
            "Epoch: 29/30..  Running Loss: 2.329.. \n",
            "Epoch: 29/30..  Running Loss: 2.714.. \n",
            "Epoch: 29/30..  Running Loss: 2.256.. \n",
            "Epoch: 29/30..  Running Loss: 2.263.. \n",
            "Epoch: 29/30..  Running Loss: 2.544.. \n",
            "Epoch: 29/30..  Running Loss: 2.283.. \n",
            "Epoch: 29/30..  Running Loss: 2.647.. \n",
            "Epoch: 29/30..  Running Loss: 2.284.. \n",
            "Epoch: 29/30..  Running Loss: 2.849.. \n",
            "Epoch: 29/30..  Running Loss: 2.421.. \n",
            "Epoch: 29/30..  Running Loss: 2.782.. \n",
            "Epoch: 29/30..  Running Loss: 2.704.. \n",
            "Epoch: 29/30..  Running Loss: 2.031.. \n",
            "Epoch: 29/30..  Running Loss: 2.157.. \n",
            "Epoch: 29/30..  Running Loss: 2.238.. \n",
            "Epoch: 29/30..  Running Loss: 1.032.. \n",
            "Epoch: 29/30..  Running Loss: 2.313.. \n",
            "Epoch: 29/30..  Running Loss: 2.452.. \n",
            "Epoch: 29/30..  Running Loss: 2.291.. \n",
            "Epoch: 29/30..  Running Loss: 2.673.. \n",
            "Epoch: 29/30..  Running Loss: 2.411.. \n",
            "Epoch: 29/30..  Running Loss: 2.183.. \n",
            "Epoch: 29/30..  Running Loss: 2.320.. \n",
            "Epoch: 29/30..  Running Loss: 1.934.. \n",
            "Epoch: 29/30..  Running Loss: 1.736.. \n",
            "Epoch: 29/30..  Running Loss: 2.729.. \n",
            "Epoch: 29/30..  Running Loss: 2.645.. \n",
            "Epoch: 29/30..  Running Loss: 2.348.. \n",
            "Epoch: 29/30..  Running Loss: 2.589.. \n",
            "Epoch: 29/30..  Running Loss: 1.478.. \n",
            "Epoch: 29/30..  Running Loss: 2.434.. \n",
            "Epoch: 29/30..  Running Loss: 2.091.. \n",
            "Epoch: 29/30..  Running Loss: 2.304.. \n",
            "Epoch: 29/30..  Running Loss: 2.500.. \n",
            "Epoch: 29/30..  Running Loss: 2.588.. \n",
            "Epoch: 29/30..  Running Loss: 2.567.. \n",
            "Epoch: 29/30..  Running Loss: 2.699.. \n",
            "Epoch: 29/30..  Running Loss: 2.424.. \n",
            "Epoch: 29/30..  Running Loss: 2.742.. \n",
            "Epoch: 29/30..  Running Loss: 2.477.. \n",
            "Epoch: 29/30..  Running Loss: 2.048.. \n",
            "Epoch: 29/30..  Running Loss: 2.151.. \n",
            "Epoch: 29/30..  Running Loss: 2.562.. \n",
            "Epoch: 29/30..  Running Loss: 2.498.. \n",
            "Epoch: 29/30..  Running Loss: 2.241.. \n",
            "Epoch: 29/30..  Running Loss: 2.326.. \n",
            "Epoch: 29/30..  Running Loss: 2.306.. \n",
            "Epoch: 29/30..  Running Loss: 2.726.. \n",
            "Epoch: 29/30..  Running Loss: 2.373.. \n",
            "Epoch: 29/30..  Running Loss: 2.838.. \n",
            "Epoch: 29/30..  Running Loss: 2.198.. \n",
            "Epoch: 29/30..  Running Loss: 1.821.. \n",
            "Epoch: 29/30..  Running Loss: 2.188.. \n",
            "Epoch: 29/30..  Running Loss: 2.528.. \n",
            "Epoch: 29/30..  Running Loss: 2.096.. \n",
            "Epoch: 29/30..  Running Loss: 2.562.. \n",
            "Epoch: 29/30..  Running Loss: 2.514.. \n",
            "Epoch: 29/30..  Running Loss: 2.489.. \n",
            "Epoch: 29/30..  Running Loss: 2.934.. \n",
            "Epoch: 29/30..  Running Loss: 2.525.. \n",
            "Epoch: 29/30..  Running Loss: 2.276.. \n",
            "Epoch: 29/30..  Running Loss: 2.542.. \n",
            "Epoch: 29/30..  Running Loss: 1.891.. \n",
            "Epoch: 29/30..  Running Loss: 2.729.. \n",
            "Epoch: 29/30..  Running Loss: 2.367.. \n",
            "Epoch: 29/30..  Running Loss: 2.560.. \n",
            "Epoch: 29/30..  Running Loss: 2.254.. \n",
            "Epoch: 29/30..  Running Loss: 2.264.. \n",
            "Epoch: 29/30..  Running Loss: 2.342.. \n",
            "Epoch: 29/30..  Running Loss: 2.384.. \n",
            "Epoch: 29/30..  Running Loss: 2.328.. \n",
            "Epoch: 29/30..  Running Loss: 2.290.. \n",
            "Epoch: 29/30..  Running Loss: 2.630.. \n",
            "Epoch: 29/30..  Running Loss: 2.352.. \n",
            "Epoch: 29/30..  Running Loss: 2.400.. \n",
            "Epoch: 29/30..  Running Loss: 2.397.. \n",
            "Epoch: 29/30..  Running Loss: 2.579.. \n",
            "Epoch: 29/30..  Running Loss: 2.523.. \n",
            "Epoch: 29/30..  Running Loss: 2.370.. \n",
            "Epoch: 29/30..  Running Loss: 2.412.. \n",
            "Epoch: 29/30..  Running Loss: 2.329.. \n",
            "Epoch: 29/30..  Running Loss: 2.566.. \n",
            "Epoch: 29/30..  Running Loss: 2.712.. \n",
            "Epoch: 29/30..  Running Loss: 2.333.. \n",
            "Epoch: 29/30..  Running Loss: 2.817.. \n",
            "Epoch: 29/30..  Running Loss: 2.434.. \n",
            "Epoch: 29/30..  Running Loss: 2.196.. \n",
            "Epoch: 29/30..  Running Loss: 2.474.. \n",
            "Epoch: 29/30..  Running Loss: 2.895.. \n",
            "Epoch: 29/30..  Running Loss: 2.372.. \n",
            "Epoch: 29/30..  Running Loss: 2.692.. \n",
            "Epoch: 29/30..  Running Loss: 2.326.. \n",
            "Epoch: 29/30..  Running Loss: 2.147.. \n",
            "Epoch: 29/30..  Running Loss: 2.060.. \n",
            "Epoch: 29/30..  Running Loss: 0.672.. \n",
            "Epoch: 29/30..  Running Loss: 1.745.. \n",
            "Epoch: 29/30..  Running Loss: 2.020.. \n",
            "Epoch: 29/30..  Running Loss: 1.040.. \n",
            "Epoch: 29/30..  Running Loss: 1.664.. \n",
            "Epoch: 29/30..  Running Loss: 2.023.. \n",
            "Epoch: 29/30..  Running Loss: 2.144.. \n",
            "Epoch: 29/30..  Running Loss: 1.048.. \n",
            "Epoch: 29/30..  Running Loss: 2.237.. \n",
            "Epoch: 29/30..  Running Loss: 2.036.. \n",
            "Epoch: 29/30..  Running Loss: 2.102.. \n",
            "Epoch: 29/30..  Running Loss: 1.824.. \n",
            "Epoch: 29/30..  Running Loss: 2.176.. \n",
            "Epoch: 29/30..  Running Loss: 2.125.. \n",
            "Epoch: 29/30..  Running Loss: 2.157.. \n",
            "Epoch: 29/30..  Running Loss: 2.543.. \n",
            "Epoch: 29/30..  Running Loss: 2.831.. \n",
            "Epoch: 29/30..  Running Loss: 2.720.. \n",
            "Epoch: 29/30..  Running Loss: 2.572.. \n",
            "Epoch: 29/30..  Running Loss: 2.757.. \n",
            "Epoch: 29/30..  Running Loss: 2.497.. \n",
            "Epoch: 29/30..  Running Loss: 2.574.. \n",
            "Epoch: 29/30..  Running Loss: 2.651.. \n",
            "Epoch: 29/30..  Running Loss: 2.670.. \n",
            "Epoch: 29/30..  Running Loss: 2.544.. \n",
            "Epoch: 29/30..  Running Loss: 2.453.. \n",
            "Epoch: 29/30..  Running Loss: 2.235.. \n",
            "Epoch: 29/30..  Running Loss: 1.789.. \n",
            "Epoch: 29/30..  Running Loss: 1.639.. \n",
            "Epoch: 29/30..  Running Loss: 0.797.. \n",
            "Epoch: 29/30..  Running Loss: 1.372.. \n",
            "Epoch: 29/30..  Running Loss: 0.935.. \n",
            "Epoch: 29/30..  Running Loss: 0.699.. \n",
            "Epoch: 29/30..  Running Loss: 1.294.. \n",
            "Epoch: 29/30..  Running Loss: 0.910.. \n",
            "Epoch: 29/30..  Running Loss: 0.675.. \n",
            "Epoch: 29/30..  Running Loss: 0.826.. \n",
            "Epoch: 29/30..  Running Loss: 0.834.. \n",
            "Epoch: 29/30..  Running Loss: 1.904.. \n",
            "Epoch: 29/30..  Running Loss: 2.632.. \n",
            "Epoch: 29/30..  Running Loss: 2.258.. \n",
            "Epoch: 29/30..  Running Loss: 2.109.. \n",
            "Epoch: 29/30..  Running Loss: 2.546.. \n",
            "Epoch: 29/30..  Running Loss: 2.885.. \n",
            "Epoch: 29/30..  Running Loss: 2.541.. \n",
            "Epoch: 29/30..  Running Loss: 2.452.. \n",
            "Epoch: 29/30..  Running Loss: 2.450.. \n",
            "Epoch: 29/30..  Running Loss: 2.161.. \n",
            "Epoch: 29/30..  Running Loss: 2.794.. \n",
            "Epoch: 29/30..  Running Loss: 2.515.. \n",
            "Epoch: 29/30..  Running Loss: 2.182.. \n",
            "Epoch: 29/30..  Running Loss: 2.396.. \n",
            "Epoch: 29/30..  Running Loss: 2.320.. \n",
            "Epoch: 29/30..  Running Loss: 2.373.. \n",
            "Epoch: 29/30..  Running Loss: 2.544.. \n",
            "Epoch: 29/30..  Running Loss: 2.662.. \n",
            "Epoch: 29/30..  Running Loss: 2.113.. \n",
            "Epoch: 29/30..  Running Loss: 2.221.. \n",
            "Epoch: 29/30..  Running Loss: 1.978.. \n",
            "Epoch: 29/30..  Running Loss: 2.659.. \n",
            "Epoch: 29/30..  Running Loss: 2.398.. \n",
            "Epoch: 29/30..  Running Loss: 2.447.. \n",
            "Epoch: 29/30..  Running Loss: 2.656.. \n",
            "Epoch: 29/30..  Running Loss: 2.844.. \n",
            "Epoch: 29/30..  Running Loss: 2.230.. \n",
            "Epoch: 29/30..  Running Loss: 2.230.. \n",
            "Epoch: 29/30..  Running Loss: 2.279.. \n",
            "Epoch: 29/30..  Running Loss: 2.533.. \n",
            "Epoch: 29/30..  Running Loss: 2.424.. \n",
            "Epoch: 29/30..  Running Loss: 2.370.. \n",
            "Epoch: 29/30..  Running Loss: 2.726.. \n",
            "Epoch: 29/30..  Running Loss: 2.325.. \n",
            "Epoch: 29/30..  Running Loss: 2.721.. \n",
            "Epoch: 29/30..  Running Loss: 2.409.. \n",
            "Epoch: 29/30..  Running Loss: 2.531.. \n",
            "Epoch: 29/30..  Running Loss: 2.779.. \n",
            "Epoch: 29/30..  Running Loss: 2.547.. \n",
            "Epoch: 29/30..  Running Loss: 2.629.. \n",
            "Epoch: 29/30..  Running Loss: 2.435.. \n",
            "Epoch: 29/30..  Running Loss: 2.422.. \n",
            "Epoch: 29/30..  Running Loss: 2.659.. \n",
            "Epoch: 29/30..  Running Loss: 2.573.. \n",
            "Epoch: 29/30..  Running Loss: 2.263.. \n",
            "Epoch: 29/30..  Running Loss: 1.852.. \n",
            "Epoch: 29/30..  Running Loss: 2.297.. \n",
            "Epoch: 29/30..  Running Loss: 2.487.. \n",
            "Epoch: 29/30..  Running Loss: 2.201.. \n",
            "Epoch: 29/30..  Running Loss: 2.475.. \n",
            "Epoch: 29/30..  Running Loss: 2.537.. \n",
            "Epoch: 29/30..  Running Loss: 2.216.. \n",
            "Epoch: 29/30..  Running Loss: 2.457.. \n",
            "Epoch: 29/30..  Running Loss: 2.597.. \n",
            "Epoch: 29/30..  Running Loss: 2.722.. \n",
            "Epoch: 29/30..  Running Loss: 2.170.. \n",
            "Epoch: 29/30..  Running Loss: 2.858.. \n",
            "Epoch: 29/30..  Running Loss: 2.533.. \n",
            "Epoch: 29/30..  Running Loss: 2.609.. \n",
            "Epoch: 29/30..  Running Loss: 2.333.. \n",
            "Epoch: 29/30..  Running Loss: 2.427.. \n",
            "Epoch: 29/30..  Running Loss: 2.137.. \n",
            "Epoch: 29/30..  Running Loss: 2.688.. \n",
            "Epoch: 29/30..  Running Loss: 2.328.. \n",
            "Epoch: 29/30..  Running Loss: 2.380.. \n",
            "Epoch: 29/30..  Running Loss: 2.447.. \n",
            "Epoch: 29/30..  Running Loss: 2.846.. \n",
            "Epoch: 29/30..  Running Loss: 2.183.. \n",
            "Epoch: 29/30..  Running Loss: 2.274.. \n",
            "Epoch: 29/30..  Running Loss: 2.152.. \n",
            "Epoch: 29/30..  Running Loss: 2.157.. \n",
            "Epoch: 29/30..  Running Loss: 2.482.. \n",
            "Epoch: 29/30..  Running Loss: 2.378.. \n",
            "Epoch: 29/30..  Running Loss: 2.614.. \n",
            "Epoch: 29/30..  Running Loss: 2.622.. \n",
            "Epoch: 29/30..  Running Loss: 2.436.. \n",
            "Epoch: 29/30..  Running Loss: 2.336.. \n",
            "Epoch: 29/30..  Running Loss: 2.531.. \n",
            "Epoch: 29/30..  Running Loss: 1.870.. \n",
            "Epoch: 29/30..  Running Loss: 2.496.. \n",
            "Epoch: 29/30..  Running Loss: 2.749.. \n",
            "Epoch: 29/30..  Running Loss: 2.485.. \n",
            "Epoch: 29/30..  Running Loss: 2.384.. \n",
            "Epoch: 29/30..  Running Loss: 2.405.. \n",
            "Epoch: 29/30..  Running Loss: 2.364.. \n",
            "Epoch: 29/30..  Running Loss: 2.222.. \n",
            "Epoch: 29/30..  Running Loss: 2.266.. \n",
            "Epoch: 29/30..  Running Loss: 2.112.. \n",
            "Epoch: 29/30..  Running Loss: 2.266.. \n",
            "Epoch: 29/30..  Running Loss: 2.573.. \n",
            "Epoch: 29/30..  Running Loss: 2.942.. \n",
            "Epoch: 29/30..  Running Loss: 2.559.. \n",
            "Epoch: 29/30..  Running Loss: 2.545.. \n",
            "Epoch: 29/30..  Running Loss: 2.555.. \n",
            "Epoch: 29/30..  Running Loss: 2.577.. \n",
            "Epoch: 29/30..  Running Loss: 2.275.. \n",
            "Epoch: 29/30..  Running Loss: 2.389.. \n",
            "Epoch: 29/30..  Running Loss: 2.212.. \n",
            "Epoch: 29/30..  Running Loss: 2.230.. \n",
            "Epoch: 29/30..  Running Loss: 2.346.. \n",
            "Epoch: 29/30..  Running Loss: 2.370.. \n",
            "Epoch: 29/30..  Running Loss: 2.428.. \n",
            "Epoch: 29/30..  Running Loss: 2.691.. \n",
            "Epoch: 29/30..  Running Loss: 2.332.. \n",
            "Epoch: 29/30..  Running Loss: 2.433.. \n",
            "Epoch: 29/30..  Running Loss: 2.346.. \n",
            "Epoch: 29/30..  Running Loss: 2.181.. \n",
            "Epoch: 29/30..  Running Loss: 2.312.. \n",
            "Epoch: 29/30..  Running Loss: 2.412.. \n",
            "Epoch: 29/30..  Running Loss: 1.982.. \n",
            "Epoch: 29/30..  Running Loss: 2.321.. \n",
            "Epoch: 29/30..  Running Loss: 2.613.. \n",
            "Epoch: 29/30..  Running Loss: 2.598.. \n",
            "Epoch: 29/30..  Running Loss: 2.728.. \n",
            "Epoch: 29/30..  Running Loss: 2.249.. \n",
            "Epoch: 29/30..  Running Loss: 2.477.. \n",
            "Epoch: 29/30..  Running Loss: 2.169.. \n",
            "Epoch: 29/30..  Running Loss: 2.440.. \n",
            "Epoch: 29/30..  Running Loss: 2.295.. \n",
            "Epoch: 29/30..  Running Loss: 2.379.. \n",
            "Epoch: 29/30..  Running Loss: 2.493.. \n",
            "Epoch: 29/30..  Running Loss: 2.534.. \n",
            "Epoch: 29/30..  Running Loss: 2.333.. \n",
            "Epoch: 29/30..  Running Loss: 2.417.. \n",
            "Epoch: 29/30..  Running Loss: 2.119.. \n",
            "Epoch: 29/30..  Running Loss: 2.369.. \n",
            "Epoch: 29/30..  Running Loss: 2.279.. \n",
            "Epoch: 29/30..  Running Loss: 2.114.. \n",
            "Epoch: 29/30..  Running Loss: 2.049.. \n",
            "Epoch: 29/30..  Running Loss: 2.478.. \n",
            "Epoch: 29/30..  Running Loss: 2.333.. \n",
            "Epoch: 29/30..  Running Loss: 2.416.. \n",
            "Epoch: 29/30..  Running Loss: 2.285.. \n",
            "Epoch: 29/30..  Running Loss: 2.465.. \n",
            "Epoch: 29/30..  Running Loss: 1.906.. \n",
            "Epoch: 29/30..  Running Loss: 2.614.. \n",
            "Epoch: 29/30..  Running Loss: 2.230.. \n",
            "Epoch: 29/30..  Running Loss: 2.658.. \n",
            "Epoch: 29/30..  Running Loss: 2.317.. \n",
            "Epoch: 29/30..  Running Loss: 2.745.. \n",
            "Epoch: 29/30..  Running Loss: 2.726.. \n",
            "Epoch: 29/30..  Running Loss: 2.693.. \n",
            "Epoch: 29/30..  Running Loss: 2.042.. \n",
            "Epoch: 29/30..  Running Loss: 2.208.. \n",
            "Epoch: 29/30..  Running Loss: 2.440.. \n",
            "Epoch: 29/30..  Running Loss: 2.653.. \n",
            "Epoch: 29/30..  Running Loss: 2.323.. \n",
            "Epoch: 29/30..  Running Loss: 2.271.. \n",
            "Epoch: 29/30..  Running Loss: 2.480.. \n",
            "Epoch: 29/30..  Running Loss: 2.198.. \n",
            "Epoch: 29/30..  Running Loss: 2.261.. \n",
            "Epoch: 29/30..  Running Loss: 2.348.. \n",
            "Epoch: 29/30..  Running Loss: 2.350.. \n",
            "Epoch: 29/30..  Running Loss: 2.437.. \n",
            "Epoch: 29/30..  Running Loss: 2.236.. \n",
            "Epoch: 29/30..  Running Loss: 2.458.. \n",
            "Epoch: 29/30..  Running Loss: 2.467.. \n",
            "Epoch: 29/30..  Running Loss: 2.323.. \n",
            "Epoch: 29/30..  Running Loss: 2.555.. \n",
            "Epoch: 29/30..  Running Loss: 1.917.. \n",
            "Epoch: 29/30..  Running Loss: 2.317.. \n",
            "Epoch: 29/30..  Running Loss: 2.897.. \n",
            "Epoch: 29/30..  Running Loss: 2.197.. \n",
            "Epoch: 29/30..  Running Loss: 2.678.. \n",
            "Epoch: 29/30..  Running Loss: 2.316.. \n",
            "Epoch: 29/30..  Running Loss: 2.423.. \n",
            "Epoch: 29/30..  Running Loss: 2.432.. \n",
            "Epoch: 29/30..  Running Loss: 2.086.. \n",
            "Epoch: 29/30..  Running Loss: 2.275.. \n",
            "Epoch: 29/30..  Running Loss: 2.924.. \n",
            "Epoch: 29/30..  Running Loss: 2.588.. \n",
            "Epoch: 29/30..  Running Loss: 2.623.. \n",
            "Epoch: 29/30..  Running Loss: 2.250.. \n",
            "Epoch: 29/30..  Running Loss: 2.600.. \n",
            "Epoch: 29/30..  Running Loss: 2.397.. \n",
            "Epoch: 29/30..  Running Loss: 2.692.. \n",
            "Epoch: 29/30..  Running Loss: 2.480.. \n",
            "Epoch: 29/30..  Running Loss: 2.475.. \n",
            "Epoch: 29/30..  Running Loss: 2.368.. \n",
            "Epoch: 29/30..  Running Loss: 2.962.. \n",
            "Epoch: 29/30..  Running Loss: 2.600.. \n",
            "Epoch: 29/30..  Running Loss: 2.581.. \n",
            "Epoch: 29/30..  Running Loss: 2.270.. \n",
            "Epoch: 29/30..  Running Loss: 2.493.. \n",
            "Epoch: 29/30..  Running Loss: 2.631.. \n",
            "Epoch: 29/30..  Running Loss: 2.728.. \n",
            "Epoch: 29/30..  Running Loss: 2.883.. \n",
            "Epoch: 29/30..  Running Loss: 2.254.. \n",
            "Epoch: 29/30..  Running Loss: 2.399.. \n",
            "Epoch: 29/30..  Running Loss: 2.554.. \n",
            "Epoch: 29/30..  Running Loss: 2.421.. \n",
            "Epoch: 29/30..  Running Loss: 2.337.. \n",
            "Epoch: 29/30..  Running Loss: 2.234.. \n",
            "Epoch: 29/30..  Running Loss: 2.605.. \n",
            "Epoch: 29/30..  Running Loss: 2.108.. \n",
            "Epoch: 29/30..  Running Loss: 2.167.. \n",
            "Epoch: 29/30..  Running Loss: 3.058.. \n",
            "Epoch: 29/30..  Running Loss: 2.451.. \n",
            "Epoch: 29/30..  Running Loss: 2.259.. \n",
            "Epoch: 29/30..  Running Loss: 2.713.. \n",
            "Epoch: 29/30..  Running Loss: 2.295.. \n",
            "Epoch: 29/30..  Running Loss: 2.398.. \n",
            "Epoch: 29/30..  Running Loss: 2.520.. \n",
            "Epoch: 29/30..  Running Loss: 2.354.. \n",
            "Epoch: 29/30..  Running Loss: 2.519.. \n",
            "Epoch: 29/30..  Running Loss: 2.292.. \n",
            "Epoch: 29/30..  Running Loss: 2.402.. \n",
            "Epoch: 29/30..  Running Loss: 2.443.. \n",
            "Epoch: 29/30..  Running Loss: 2.153.. \n",
            "Epoch: 29/30..  Running Loss: 2.412.. \n",
            "Epoch: 29/30..  Running Loss: 2.296.. \n",
            "Epoch: 29/30..  Running Loss: 2.327.. \n",
            "Epoch: 29/30..  Running Loss: 2.330.. \n",
            "Epoch: 29/30..  Running Loss: 2.198.. \n",
            "Epoch: 29/30..  Running Loss: 2.231.. \n",
            "Epoch: 29/30..  Running Loss: 2.190.. \n",
            "Epoch: 29/30..  Running Loss: 2.349.. \n",
            "Epoch: 29/30..  Running Loss: 2.157.. \n",
            "Epoch: 29/30..  Running Loss: 2.177.. \n",
            "Epoch: 29/30..  Running Loss: 2.227.. \n",
            "Epoch: 29/30..  Running Loss: 2.406.. \n",
            "Epoch: 29/30..  Running Loss: 2.560.. \n",
            "Epoch: 29/30..  Running Loss: 1.985.. \n",
            "Epoch: 29/30..  Running Loss: 2.551.. \n",
            "Epoch: 29/30..  Running Loss: 2.347.. \n",
            "Epoch: 29/30..  Running Loss: 2.439.. \n",
            "Epoch: 29/30..  Running Loss: 2.352.. \n",
            "Epoch: 29/30..  Running Loss: 2.222.. \n",
            "Epoch: 29/30..  Running Loss: 2.246.. \n",
            "Epoch: 29/30..  Running Loss: 2.111.. \n",
            "Epoch: 29/30..  Running Loss: 2.515.. \n",
            "Epoch: 29/30..  Running Loss: 2.238.. \n",
            "Epoch: 29/30..  Running Loss: 2.685.. \n",
            "Epoch: 29/30..  Running Loss: 2.376.. \n",
            "Epoch: 29/30..  Running Loss: 2.296.. \n",
            "Epoch: 29/30..  Running Loss: 2.505.. \n",
            "Epoch: 29/30..  Running Loss: 2.290.. \n",
            "Epoch: 29/30..  Running Loss: 2.540.. \n",
            "Epoch: 29/30..  Running Loss: 2.480.. \n",
            "Epoch: 29/30..  Running Loss: 2.623.. \n",
            "Epoch: 29/30..  Running Loss: 2.626.. \n",
            "Epoch: 29/30..  Running Loss: 2.671.. \n",
            "Epoch: 29/30..  Running Loss: 2.303.. \n",
            "Epoch: 29/30..  Running Loss: 2.427.. \n",
            "Epoch: 29/30..  Running Loss: 2.393.. \n",
            "Epoch: 29/30..  Running Loss: 2.319.. \n",
            "Epoch: 29/30..  Running Loss: 2.536.. \n",
            "Epoch: 29/30..  Running Loss: 2.374.. \n",
            "Epoch: 29/30..  Running Loss: 1.977.. \n",
            "Epoch: 29/30..  Running Loss: 2.431.. \n",
            "Epoch: 29/30..  Running Loss: 2.500.. \n",
            "Epoch: 29/30..  Running Loss: 2.009.. \n",
            "Epoch: 29/30..  Running Loss: 2.521.. \n",
            "Epoch: 29/30..  Running Loss: 2.446.. \n",
            "Epoch: 29/30..  Running Loss: 2.404.. \n",
            "Epoch: 29/30..  Running Loss: 2.084.. \n",
            "Epoch: 29/30..  Running Loss: 2.123.. \n",
            "Epoch: 29/30..  Running Loss: 2.366.. \n",
            "Epoch: 29/30..  Running Loss: 2.470.. \n",
            "Epoch: 29/30..  Running Loss: 2.609.. \n",
            "Epoch: 29/30..  Running Loss: 2.358.. \n",
            "Epoch: 29/30..  Running Loss: 2.262.. \n",
            "Epoch: 29/30..  Running Loss: 2.848.. \n",
            "Epoch: 29/30..  Running Loss: 2.443.. \n",
            "Epoch: 29/30..  Running Loss: 2.588.. \n",
            "Epoch: 29/30..  Running Loss: 2.416.. \n",
            "Epoch: 29/30..  Running Loss: 2.369.. \n",
            "Epoch: 29/30..  Running Loss: 2.386.. \n",
            "Epoch: 29/30..  Running Loss: 2.485.. \n",
            "Epoch: 29/30..  Running Loss: 2.253.. \n",
            "Epoch: 29/30..  Running Loss: 2.282.. \n",
            "Epoch: 29/30..  Running Loss: 2.156.. \n",
            "Epoch: 29/30..  Running Loss: 2.300.. \n",
            "Epoch: 29/30..  Running Loss: 2.367.. \n",
            "Epoch: 29/30..  Running Loss: 2.106.. \n",
            "Epoch: 29/30..  Running Loss: 2.118.. \n",
            "Epoch: 29/30..  Running Loss: 2.383.. \n",
            "Epoch: 29/30..  Running Loss: 2.383.. \n",
            "Epoch: 29/30..  Running Loss: 2.724.. \n",
            "Epoch: 29/30..  Running Loss: 2.074.. \n",
            "Epoch: 29/30..  Running Loss: 2.994.. \n",
            "Epoch: 29/30..  Running Loss: 2.181.. \n",
            "Epoch: 29/30..  Running Loss: 2.489.. \n",
            "Epoch: 29/30..  Running Loss: 2.368.. \n",
            "Epoch: 29/30..  Running Loss: 2.367.. \n",
            "Epoch: 29/30..  Running Loss: 1.388.. \n",
            "Epoch: 29/30..  Running Loss: 2.566.. \n",
            "Epoch: 29/30..  Running Loss: 2.470.. \n",
            "Epoch: 29/30..  Running Loss: 2.420.. \n",
            "Epoch: 29/30..  Running Loss: 2.862.. \n",
            "Epoch: 29/30..  Running Loss: 2.188.. \n",
            "Epoch: 29/30..  Running Loss: 2.466.. \n",
            "Epoch: 29/30..  Running Loss: 2.659.. \n",
            "Epoch: 29/30..  Running Loss: 2.361.. \n",
            "Epoch: 29/30..  Running Loss: 2.459.. \n",
            "Epoch: 29/30..  Running Loss: 2.161.. \n",
            "Epoch: 29/30..  Running Loss: 2.806.. \n",
            "Epoch: 29/30..  Running Loss: 2.414.. \n",
            "Epoch: 29/30..  Running Loss: 2.617.. \n",
            "Epoch: 29/30..  Running Loss: 2.648.. \n",
            "Epoch: 29/30..  Running Loss: 2.270.. \n",
            "Epoch: 29/30..  Running Loss: 2.089.. \n",
            "Epoch: 29/30..  Running Loss: 2.263.. \n",
            "Epoch: 29/30..  Running Loss: 2.728.. \n",
            "Epoch: 29/30..  Running Loss: 2.494.. \n",
            "Epoch: 29/30..  Running Loss: 2.498.. \n",
            "Epoch: 29/30..  Running Loss: 2.114.. \n",
            "Epoch: 29/30..  Running Loss: 2.698.. \n",
            "Epoch: 29/30..  Running Loss: 2.416.. \n",
            "Epoch: 29/30..  Running Loss: 2.301.. \n",
            "Epoch: 29/30..  Running Loss: 2.801.. \n",
            "Epoch: 29/30..  Running Loss: 2.073.. \n",
            "Epoch: 29/30..  Running Loss: 2.433.. \n",
            "Epoch: 29/30..  Running Loss: 2.156.. \n",
            "Epoch: 29/30..  Running Loss: 2.541.. \n",
            "Epoch: 29/30..  Running Loss: 2.383.. \n",
            "Epoch: 29/30..  Running Loss: 2.224.. \n",
            "Epoch: 29/30..  Running Loss: 2.048.. \n",
            "Epoch: 29/30..  Running Loss: 2.397.. \n",
            "Epoch: 29/30..  Running Loss: 2.404.. \n",
            "Epoch: 29/30..  Running Loss: 2.584.. \n",
            "Epoch: 29/30..  Running Loss: 2.372.. \n",
            "Epoch: 29/30..  Running Loss: 2.148.. \n",
            "Epoch: 29/30..  Running Loss: 2.670.. \n",
            "Epoch: 29/30..  Running Loss: 2.227.. \n",
            "Epoch: 29/30..  Running Loss: 2.364.. \n",
            "Epoch: 29/30..  Running Loss: 2.346.. \n",
            "Epoch: 29/30..  Running Loss: 2.281.. \n",
            "Epoch: 29/30..  Running Loss: 2.478.. \n",
            "Epoch: 29/30..  Running Loss: 2.245.. \n",
            "Epoch: 29/30..  Running Loss: 2.314.. \n",
            "Epoch: 29/30..  Running Loss: 2.600.. \n",
            "Epoch: 29/30..  Running Loss: 2.282.. \n",
            "Epoch: 29/30..  Running Loss: 2.659.. \n",
            "Epoch: 29/30..  Running Loss: 2.273.. \n",
            "Epoch: 29/30..  Running Loss: 2.608.. \n",
            "Epoch: 29/30..  Running Loss: 2.413.. \n",
            "Epoch: 29/30..  Running Loss: 2.463.. \n",
            "Epoch: 29/30..  Running Loss: 2.472.. \n",
            "Epoch: 29/30..  Running Loss: 2.267.. \n",
            "Epoch: 29/30..  Running Loss: 2.505.. \n",
            "Epoch: 29/30..  Running Loss: 2.113.. \n",
            "Epoch: 29/30..  Running Loss: 2.764.. \n",
            "Epoch: 29/30..  Running Loss: 2.352.. \n",
            "Epoch: 29/30..  Running Loss: 2.074.. \n",
            "Epoch: 29/30..  Running Loss: 1.927.. \n",
            "Epoch: 29/30..  Running Loss: 2.392.. \n",
            "Epoch: 29/30..  Running Loss: 2.459.. \n",
            "Epoch: 29/30..  Running Loss: 2.359.. \n",
            "Epoch: 29/30..  Running Loss: 2.361.. \n",
            "Epoch: 29/30..  Running Loss: 2.135.. \n",
            "Epoch: 29/30..  Running Loss: 2.680.. \n",
            "Epoch: 29/30..  Running Loss: 2.594.. \n",
            "Epoch: 29/30..  Running Loss: 2.493.. \n",
            "Epoch: 29/30..  Running Loss: 2.292.. \n",
            "Epoch: 29/30..  Running Loss: 2.402.. \n",
            "Epoch: 29/30..  Running Loss: 2.446.. \n",
            "Epoch: 29/30..  Running Loss: 2.150.. \n",
            "Epoch: 29/30..  Running Loss: 2.474.. \n",
            "Epoch: 29/30..  Running Loss: 2.367.. \n",
            "Epoch: 29/30..  Running Loss: 2.279.. \n",
            "Epoch: 29/30..  Running Loss: 2.426.. \n",
            "Epoch: 29/30..  Running Loss: 2.371.. \n",
            "Epoch: 29/30..  Running Loss: 2.363.. \n",
            "Epoch: 29/30..  Running Loss: 2.477.. \n",
            "Epoch: 29/30..  Running Loss: 2.369.. \n",
            "Epoch: 29/30..  Running Loss: 2.119.. \n",
            "Epoch: 29/30..  Running Loss: 2.216.. \n",
            "Epoch: 29/30..  Running Loss: 2.428.. \n",
            "Epoch: 29/30..  Running Loss: 2.444.. \n",
            "Epoch: 29/30..  Running Loss: 2.417.. \n",
            "Epoch: 29/30..  Running Loss: 2.287.. \n",
            "Epoch: 29/30..  Running Loss: 2.453.. \n",
            "Epoch: 29/30..  Running Loss: 2.366.. \n",
            "Epoch: 29/30..  Running Loss: 2.473.. \n",
            "Epoch: 29/30..  Running Loss: 2.723.. \n",
            "Epoch: 30/30..  Running Loss: 2.594.. \n",
            "Epoch: 30/30..  Running Loss: 2.410.. \n",
            "Epoch: 30/30..  Running Loss: 2.741.. \n",
            "Epoch: 30/30..  Running Loss: 2.319.. \n",
            "Epoch: 30/30..  Running Loss: 2.292.. \n",
            "Epoch: 30/30..  Running Loss: 2.059.. \n",
            "Epoch: 30/30..  Running Loss: 2.638.. \n",
            "Epoch: 30/30..  Running Loss: 2.544.. \n",
            "Epoch: 30/30..  Running Loss: 2.440.. \n",
            "Epoch: 30/30..  Running Loss: 2.639.. \n",
            "Epoch: 30/30..  Running Loss: 2.250.. \n",
            "Epoch: 30/30..  Running Loss: 2.141.. \n",
            "Epoch: 30/30..  Running Loss: 2.211.. \n",
            "Epoch: 30/30..  Running Loss: 2.648.. \n",
            "Epoch: 30/30..  Running Loss: 2.220.. \n",
            "Epoch: 30/30..  Running Loss: 2.456.. \n",
            "Epoch: 30/30..  Running Loss: 2.226.. \n",
            "Epoch: 30/30..  Running Loss: 2.185.. \n",
            "Epoch: 30/30..  Running Loss: 2.120.. \n",
            "Epoch: 30/30..  Running Loss: 2.133.. \n",
            "Epoch: 30/30..  Running Loss: 2.400.. \n",
            "Epoch: 30/30..  Running Loss: 2.389.. \n",
            "Epoch: 30/30..  Running Loss: 2.558.. \n",
            "Epoch: 30/30..  Running Loss: 2.286.. \n",
            "Epoch: 30/30..  Running Loss: 2.123.. \n",
            "Epoch: 30/30..  Running Loss: 2.263.. \n",
            "Epoch: 30/30..  Running Loss: 2.374.. \n",
            "Epoch: 30/30..  Running Loss: 2.352.. \n",
            "Epoch: 30/30..  Running Loss: 1.923.. \n",
            "Epoch: 30/30..  Running Loss: 2.010.. \n",
            "Epoch: 30/30..  Running Loss: 2.273.. \n",
            "Epoch: 30/30..  Running Loss: 2.019.. \n",
            "Epoch: 30/30..  Running Loss: 2.318.. \n",
            "Epoch: 30/30..  Running Loss: 2.076.. \n",
            "Epoch: 30/30..  Running Loss: 2.083.. \n",
            "Epoch: 30/30..  Running Loss: 2.720.. \n",
            "Epoch: 30/30..  Running Loss: 2.773.. \n",
            "Epoch: 30/30..  Running Loss: 1.921.. \n",
            "Epoch: 30/30..  Running Loss: 2.184.. \n",
            "Epoch: 30/30..  Running Loss: 2.200.. \n",
            "Epoch: 30/30..  Running Loss: 2.202.. \n",
            "Epoch: 30/30..  Running Loss: 2.455.. \n",
            "Epoch: 30/30..  Running Loss: 2.203.. \n",
            "Epoch: 30/30..  Running Loss: 2.682.. \n",
            "Epoch: 30/30..  Running Loss: 2.743.. \n",
            "Epoch: 30/30..  Running Loss: 2.193.. \n",
            "Epoch: 30/30..  Running Loss: 2.473.. \n",
            "Epoch: 30/30..  Running Loss: 2.363.. \n",
            "Epoch: 30/30..  Running Loss: 2.272.. \n",
            "Epoch: 30/30..  Running Loss: 2.477.. \n",
            "Epoch: 30/30..  Running Loss: 2.023.. \n",
            "Epoch: 30/30..  Running Loss: 2.260.. \n",
            "Epoch: 30/30..  Running Loss: 2.397.. \n",
            "Epoch: 30/30..  Running Loss: 2.412.. \n",
            "Epoch: 30/30..  Running Loss: 2.219.. \n",
            "Epoch: 30/30..  Running Loss: 2.376.. \n",
            "Epoch: 30/30..  Running Loss: 2.544.. \n",
            "Epoch: 30/30..  Running Loss: 2.372.. \n",
            "Epoch: 30/30..  Running Loss: 1.821.. \n",
            "Epoch: 30/30..  Running Loss: 2.316.. \n",
            "Epoch: 30/30..  Running Loss: 2.587.. \n",
            "Epoch: 30/30..  Running Loss: 2.370.. \n",
            "Epoch: 30/30..  Running Loss: 2.162.. \n",
            "Epoch: 30/30..  Running Loss: 2.164.. \n",
            "Epoch: 30/30..  Running Loss: 2.198.. \n",
            "Epoch: 30/30..  Running Loss: 1.956.. \n",
            "Epoch: 30/30..  Running Loss: 2.089.. \n",
            "Epoch: 30/30..  Running Loss: 2.616.. \n",
            "Epoch: 30/30..  Running Loss: 2.255.. \n",
            "Epoch: 30/30..  Running Loss: 2.199.. \n",
            "Epoch: 30/30..  Running Loss: 2.163.. \n",
            "Epoch: 30/30..  Running Loss: 2.267.. \n",
            "Epoch: 30/30..  Running Loss: 2.437.. \n",
            "Epoch: 30/30..  Running Loss: 2.575.. \n",
            "Epoch: 30/30..  Running Loss: 2.261.. \n",
            "Epoch: 30/30..  Running Loss: 2.491.. \n",
            "Epoch: 30/30..  Running Loss: 2.083.. \n",
            "Epoch: 30/30..  Running Loss: 2.019.. \n",
            "Epoch: 30/30..  Running Loss: 1.895.. \n",
            "Epoch: 30/30..  Running Loss: 2.238.. \n",
            "Epoch: 30/30..  Running Loss: 2.332.. \n",
            "Epoch: 30/30..  Running Loss: 2.200.. \n",
            "Epoch: 30/30..  Running Loss: 2.328.. \n",
            "Epoch: 30/30..  Running Loss: 2.243.. \n",
            "Epoch: 30/30..  Running Loss: 2.348.. \n",
            "Epoch: 30/30..  Running Loss: 2.227.. \n",
            "Epoch: 30/30..  Running Loss: 2.591.. \n",
            "Epoch: 30/30..  Running Loss: 2.781.. \n",
            "Epoch: 30/30..  Running Loss: 1.998.. \n",
            "Epoch: 30/30..  Running Loss: 2.700.. \n",
            "Epoch: 30/30..  Running Loss: 2.365.. \n",
            "Epoch: 30/30..  Running Loss: 2.596.. \n",
            "Epoch: 30/30..  Running Loss: 2.840.. \n",
            "Epoch: 30/30..  Running Loss: 2.247.. \n",
            "Epoch: 30/30..  Running Loss: 1.980.. \n",
            "Epoch: 30/30..  Running Loss: 2.525.. \n",
            "Epoch: 30/30..  Running Loss: 2.762.. \n",
            "Epoch: 30/30..  Running Loss: 2.336.. \n",
            "Epoch: 30/30..  Running Loss: 2.084.. \n",
            "Epoch: 30/30..  Running Loss: 2.828.. \n",
            "Epoch: 30/30..  Running Loss: 2.298.. \n",
            "Epoch: 30/30..  Running Loss: 2.272.. \n",
            "Epoch: 30/30..  Running Loss: 2.705.. \n",
            "Epoch: 30/30..  Running Loss: 2.483.. \n",
            "Epoch: 30/30..  Running Loss: 2.646.. \n",
            "Epoch: 30/30..  Running Loss: 2.358.. \n",
            "Epoch: 30/30..  Running Loss: 2.232.. \n",
            "Epoch: 30/30..  Running Loss: 2.622.. \n",
            "Epoch: 30/30..  Running Loss: 2.302.. \n",
            "Epoch: 30/30..  Running Loss: 3.087.. \n",
            "Epoch: 30/30..  Running Loss: 2.395.. \n",
            "Epoch: 30/30..  Running Loss: 2.433.. \n",
            "Epoch: 30/30..  Running Loss: 2.244.. \n",
            "Epoch: 30/30..  Running Loss: 2.012.. \n",
            "Epoch: 30/30..  Running Loss: 2.362.. \n",
            "Epoch: 30/30..  Running Loss: 2.561.. \n",
            "Epoch: 30/30..  Running Loss: 2.659.. \n",
            "Epoch: 30/30..  Running Loss: 2.368.. \n",
            "Epoch: 30/30..  Running Loss: 2.241.. \n",
            "Epoch: 30/30..  Running Loss: 2.145.. \n",
            "Epoch: 30/30..  Running Loss: 2.651.. \n",
            "Epoch: 30/30..  Running Loss: 2.340.. \n",
            "Epoch: 30/30..  Running Loss: 1.945.. \n",
            "Epoch: 30/30..  Running Loss: 2.443.. \n",
            "Epoch: 30/30..  Running Loss: 2.414.. \n",
            "Epoch: 30/30..  Running Loss: 2.713.. \n",
            "Epoch: 30/30..  Running Loss: 2.335.. \n",
            "Epoch: 30/30..  Running Loss: 2.802.. \n",
            "Epoch: 30/30..  Running Loss: 2.452.. \n",
            "Epoch: 30/30..  Running Loss: 2.346.. \n",
            "Epoch: 30/30..  Running Loss: 2.259.. \n",
            "Epoch: 30/30..  Running Loss: 2.634.. \n",
            "Epoch: 30/30..  Running Loss: 2.379.. \n",
            "Epoch: 30/30..  Running Loss: 2.401.. \n",
            "Epoch: 30/30..  Running Loss: 2.494.. \n",
            "Epoch: 30/30..  Running Loss: 2.826.. \n",
            "Epoch: 30/30..  Running Loss: 2.020.. \n",
            "Epoch: 30/30..  Running Loss: 2.610.. \n",
            "Epoch: 30/30..  Running Loss: 2.269.. \n",
            "Epoch: 30/30..  Running Loss: 2.301.. \n",
            "Epoch: 30/30..  Running Loss: 2.401.. \n",
            "Epoch: 30/30..  Running Loss: 2.099.. \n",
            "Epoch: 30/30..  Running Loss: 2.541.. \n",
            "Epoch: 30/30..  Running Loss: 2.259.. \n",
            "Epoch: 30/30..  Running Loss: 2.159.. \n",
            "Epoch: 30/30..  Running Loss: 2.437.. \n",
            "Epoch: 30/30..  Running Loss: 2.363.. \n",
            "Epoch: 30/30..  Running Loss: 2.482.. \n",
            "Epoch: 30/30..  Running Loss: 2.467.. \n",
            "Epoch: 30/30..  Running Loss: 2.540.. \n",
            "Epoch: 30/30..  Running Loss: 2.885.. \n",
            "Epoch: 30/30..  Running Loss: 2.343.. \n",
            "Epoch: 30/30..  Running Loss: 2.367.. \n",
            "Epoch: 30/30..  Running Loss: 2.439.. \n",
            "Epoch: 30/30..  Running Loss: 2.726.. \n",
            "Epoch: 30/30..  Running Loss: 2.421.. \n",
            "Epoch: 30/30..  Running Loss: 2.336.. \n",
            "Epoch: 30/30..  Running Loss: 2.330.. \n",
            "Epoch: 30/30..  Running Loss: 2.288.. \n",
            "Epoch: 30/30..  Running Loss: 2.279.. \n",
            "Epoch: 30/30..  Running Loss: 2.587.. \n",
            "Epoch: 30/30..  Running Loss: 2.288.. \n",
            "Epoch: 30/30..  Running Loss: 1.808.. \n",
            "Epoch: 30/30..  Running Loss: 2.230.. \n",
            "Epoch: 30/30..  Running Loss: 2.291.. \n",
            "Epoch: 30/30..  Running Loss: 2.113.. \n",
            "Epoch: 30/30..  Running Loss: 2.540.. \n",
            "Epoch: 30/30..  Running Loss: 2.334.. \n",
            "Epoch: 30/30..  Running Loss: 2.557.. \n",
            "Epoch: 30/30..  Running Loss: 2.102.. \n",
            "Epoch: 30/30..  Running Loss: 2.087.. \n",
            "Epoch: 30/30..  Running Loss: 2.241.. \n",
            "Epoch: 30/30..  Running Loss: 2.045.. \n",
            "Epoch: 30/30..  Running Loss: 2.210.. \n",
            "Epoch: 30/30..  Running Loss: 1.977.. \n",
            "Epoch: 30/30..  Running Loss: 2.171.. \n",
            "Epoch: 30/30..  Running Loss: 2.010.. \n",
            "Epoch: 30/30..  Running Loss: 1.865.. \n",
            "Epoch: 30/30..  Running Loss: 2.603.. \n",
            "Epoch: 30/30..  Running Loss: 2.145.. \n",
            "Epoch: 30/30..  Running Loss: 2.235.. \n",
            "Epoch: 30/30..  Running Loss: 2.454.. \n",
            "Epoch: 30/30..  Running Loss: 1.908.. \n",
            "Epoch: 30/30..  Running Loss: 2.069.. \n",
            "Epoch: 30/30..  Running Loss: 1.831.. \n",
            "Epoch: 30/30..  Running Loss: 2.178.. \n",
            "Epoch: 30/30..  Running Loss: 2.257.. \n",
            "Epoch: 30/30..  Running Loss: 2.208.. \n",
            "Epoch: 30/30..  Running Loss: 1.779.. \n",
            "Epoch: 30/30..  Running Loss: 2.190.. \n",
            "Epoch: 30/30..  Running Loss: 2.475.. \n",
            "Epoch: 30/30..  Running Loss: 2.421.. \n",
            "Epoch: 30/30..  Running Loss: 2.643.. \n",
            "Epoch: 30/30..  Running Loss: 2.357.. \n",
            "Epoch: 30/30..  Running Loss: 2.317.. \n",
            "Epoch: 30/30..  Running Loss: 2.468.. \n",
            "Epoch: 30/30..  Running Loss: 2.425.. \n",
            "Epoch: 30/30..  Running Loss: 2.096.. \n",
            "Epoch: 30/30..  Running Loss: 2.113.. \n",
            "Epoch: 30/30..  Running Loss: 2.274.. \n",
            "Epoch: 30/30..  Running Loss: 2.191.. \n",
            "Epoch: 30/30..  Running Loss: 2.064.. \n",
            "Epoch: 30/30..  Running Loss: 2.276.. \n",
            "Epoch: 30/30..  Running Loss: 1.838.. \n",
            "Epoch: 30/30..  Running Loss: 2.390.. \n",
            "Epoch: 30/30..  Running Loss: 2.204.. \n",
            "Epoch: 30/30..  Running Loss: 2.694.. \n",
            "Epoch: 30/30..  Running Loss: 2.339.. \n",
            "Epoch: 30/30..  Running Loss: 2.797.. \n",
            "Epoch: 30/30..  Running Loss: 2.380.. \n",
            "Epoch: 30/30..  Running Loss: 2.236.. \n",
            "Epoch: 30/30..  Running Loss: 2.093.. \n",
            "Epoch: 30/30..  Running Loss: 2.283.. \n",
            "Epoch: 30/30..  Running Loss: 2.503.. \n",
            "Epoch: 30/30..  Running Loss: 2.341.. \n",
            "Epoch: 30/30..  Running Loss: 2.446.. \n",
            "Epoch: 30/30..  Running Loss: 2.338.. \n",
            "Epoch: 30/30..  Running Loss: 2.059.. \n",
            "Epoch: 30/30..  Running Loss: 2.036.. \n",
            "Epoch: 30/30..  Running Loss: 2.538.. \n",
            "Epoch: 30/30..  Running Loss: 2.604.. \n",
            "Epoch: 30/30..  Running Loss: 2.626.. \n",
            "Epoch: 30/30..  Running Loss: 2.065.. \n",
            "Epoch: 30/30..  Running Loss: 1.969.. \n",
            "Epoch: 30/30..  Running Loss: 2.268.. \n",
            "Epoch: 30/30..  Running Loss: 1.900.. \n",
            "Epoch: 30/30..  Running Loss: 2.223.. \n",
            "Epoch: 30/30..  Running Loss: 2.535.. \n",
            "Epoch: 30/30..  Running Loss: 2.348.. \n",
            "Epoch: 30/30..  Running Loss: 2.489.. \n",
            "Epoch: 30/30..  Running Loss: 2.387.. \n",
            "Epoch: 30/30..  Running Loss: 2.349.. \n",
            "Epoch: 30/30..  Running Loss: 2.416.. \n",
            "Epoch: 30/30..  Running Loss: 2.467.. \n",
            "Epoch: 30/30..  Running Loss: 2.350.. \n",
            "Epoch: 30/30..  Running Loss: 2.225.. \n",
            "Epoch: 30/30..  Running Loss: 2.484.. \n",
            "Epoch: 30/30..  Running Loss: 2.315.. \n",
            "Epoch: 30/30..  Running Loss: 2.400.. \n",
            "Epoch: 30/30..  Running Loss: 2.236.. \n",
            "Epoch: 30/30..  Running Loss: 1.964.. \n",
            "Epoch: 30/30..  Running Loss: 2.169.. \n",
            "Epoch: 30/30..  Running Loss: 2.280.. \n",
            "Epoch: 30/30..  Running Loss: 2.423.. \n",
            "Epoch: 30/30..  Running Loss: 2.315.. \n",
            "Epoch: 30/30..  Running Loss: 2.645.. \n",
            "Epoch: 30/30..  Running Loss: 2.368.. \n",
            "Epoch: 30/30..  Running Loss: 2.159.. \n",
            "Epoch: 30/30..  Running Loss: 2.019.. \n",
            "Epoch: 30/30..  Running Loss: 2.276.. \n",
            "Epoch: 30/30..  Running Loss: 2.490.. \n",
            "Epoch: 30/30..  Running Loss: 2.607.. \n",
            "Epoch: 30/30..  Running Loss: 2.312.. \n",
            "Epoch: 30/30..  Running Loss: 2.207.. \n",
            "Epoch: 30/30..  Running Loss: 2.131.. \n",
            "Epoch: 30/30..  Running Loss: 2.429.. \n",
            "Epoch: 30/30..  Running Loss: 2.216.. \n",
            "Epoch: 30/30..  Running Loss: 2.007.. \n",
            "Epoch: 30/30..  Running Loss: 2.285.. \n",
            "Epoch: 30/30..  Running Loss: 2.428.. \n",
            "Epoch: 30/30..  Running Loss: 2.417.. \n",
            "Epoch: 30/30..  Running Loss: 1.964.. \n",
            "Epoch: 30/30..  Running Loss: 1.985.. \n",
            "Epoch: 30/30..  Running Loss: 3.010.. \n",
            "Epoch: 30/30..  Running Loss: 2.342.. \n",
            "Epoch: 30/30..  Running Loss: 1.981.. \n",
            "Epoch: 30/30..  Running Loss: 2.699.. \n",
            "Epoch: 30/30..  Running Loss: 2.178.. \n",
            "Epoch: 30/30..  Running Loss: 2.165.. \n",
            "Epoch: 30/30..  Running Loss: 2.431.. \n",
            "Epoch: 30/30..  Running Loss: 2.581.. \n",
            "Epoch: 30/30..  Running Loss: 2.732.. \n",
            "Epoch: 30/30..  Running Loss: 2.504.. \n",
            "Epoch: 30/30..  Running Loss: 2.620.. \n",
            "Epoch: 30/30..  Running Loss: 2.627.. \n",
            "Epoch: 30/30..  Running Loss: 2.422.. \n",
            "Epoch: 30/30..  Running Loss: 2.296.. \n",
            "Epoch: 30/30..  Running Loss: 1.816.. \n",
            "Epoch: 30/30..  Running Loss: 2.247.. \n",
            "Epoch: 30/30..  Running Loss: 2.295.. \n",
            "Epoch: 30/30..  Running Loss: 2.499.. \n",
            "Epoch: 30/30..  Running Loss: 2.381.. \n",
            "Epoch: 30/30..  Running Loss: 1.961.. \n",
            "Epoch: 30/30..  Running Loss: 2.610.. \n",
            "Epoch: 30/30..  Running Loss: 2.349.. \n",
            "Epoch: 30/30..  Running Loss: 2.430.. \n",
            "Epoch: 30/30..  Running Loss: 2.360.. \n",
            "Epoch: 30/30..  Running Loss: 2.287.. \n",
            "Epoch: 30/30..  Running Loss: 2.515.. \n",
            "Epoch: 30/30..  Running Loss: 2.391.. \n",
            "Epoch: 30/30..  Running Loss: 2.158.. \n",
            "Epoch: 30/30..  Running Loss: 2.024.. \n",
            "Epoch: 30/30..  Running Loss: 2.109.. \n",
            "Epoch: 30/30..  Running Loss: 2.284.. \n",
            "Epoch: 30/30..  Running Loss: 2.693.. \n",
            "Epoch: 30/30..  Running Loss: 1.992.. \n",
            "Epoch: 30/30..  Running Loss: 2.407.. \n",
            "Epoch: 30/30..  Running Loss: 1.816.. \n",
            "Epoch: 30/30..  Running Loss: 2.195.. \n",
            "Epoch: 30/30..  Running Loss: 1.993.. \n",
            "Epoch: 30/30..  Running Loss: 1.778.. \n",
            "Epoch: 30/30..  Running Loss: 2.125.. \n",
            "Epoch: 30/30..  Running Loss: 2.034.. \n",
            "Epoch: 30/30..  Running Loss: 2.047.. \n",
            "Epoch: 30/30..  Running Loss: 2.879.. \n",
            "Epoch: 30/30..  Running Loss: 2.293.. \n",
            "Epoch: 30/30..  Running Loss: 2.328.. \n",
            "Epoch: 30/30..  Running Loss: 2.332.. \n",
            "Epoch: 30/30..  Running Loss: 2.913.. \n",
            "Epoch: 30/30..  Running Loss: 2.513.. \n",
            "Epoch: 30/30..  Running Loss: 2.624.. \n",
            "Epoch: 30/30..  Running Loss: 2.409.. \n",
            "Epoch: 30/30..  Running Loss: 2.288.. \n",
            "Epoch: 30/30..  Running Loss: 2.643.. \n",
            "Epoch: 30/30..  Running Loss: 2.451.. \n",
            "Epoch: 30/30..  Running Loss: 2.540.. \n",
            "Epoch: 30/30..  Running Loss: 2.692.. \n",
            "Epoch: 30/30..  Running Loss: 2.492.. \n",
            "Epoch: 30/30..  Running Loss: 2.501.. \n",
            "Epoch: 30/30..  Running Loss: 2.529.. \n",
            "Epoch: 30/30..  Running Loss: 2.656.. \n",
            "Epoch: 30/30..  Running Loss: 2.659.. \n",
            "Epoch: 30/30..  Running Loss: 2.353.. \n",
            "Epoch: 30/30..  Running Loss: 2.912.. \n",
            "Epoch: 30/30..  Running Loss: 2.235.. \n",
            "Epoch: 30/30..  Running Loss: 2.537.. \n",
            "Epoch: 30/30..  Running Loss: 2.210.. \n",
            "Epoch: 30/30..  Running Loss: 2.704.. \n",
            "Epoch: 30/30..  Running Loss: 2.454.. \n",
            "Epoch: 30/30..  Running Loss: 2.734.. \n",
            "Epoch: 30/30..  Running Loss: 2.566.. \n",
            "Epoch: 30/30..  Running Loss: 2.511.. \n",
            "Epoch: 30/30..  Running Loss: 2.624.. \n",
            "Epoch: 30/30..  Running Loss: 2.553.. \n",
            "Epoch: 30/30..  Running Loss: 2.200.. \n",
            "Epoch: 30/30..  Running Loss: 2.793.. \n",
            "Epoch: 30/30..  Running Loss: 2.538.. \n",
            "Epoch: 30/30..  Running Loss: 2.087.. \n",
            "Epoch: 30/30..  Running Loss: 2.798.. \n",
            "Epoch: 30/30..  Running Loss: 2.632.. \n",
            "Epoch: 30/30..  Running Loss: 2.619.. \n",
            "Epoch: 30/30..  Running Loss: 2.515.. \n",
            "Epoch: 30/30..  Running Loss: 2.474.. \n",
            "Epoch: 30/30..  Running Loss: 2.114.. \n",
            "Epoch: 30/30..  Running Loss: 2.377.. \n",
            "Epoch: 30/30..  Running Loss: 2.089.. \n",
            "Epoch: 30/30..  Running Loss: 2.233.. \n",
            "Epoch: 30/30..  Running Loss: 2.203.. \n",
            "Epoch: 30/30..  Running Loss: 2.442.. \n",
            "Epoch: 30/30..  Running Loss: 2.335.. \n",
            "Epoch: 30/30..  Running Loss: 2.360.. \n",
            "Epoch: 30/30..  Running Loss: 2.509.. \n",
            "Epoch: 30/30..  Running Loss: 2.875.. \n",
            "Epoch: 30/30..  Running Loss: 2.304.. \n",
            "Epoch: 30/30..  Running Loss: 2.248.. \n",
            "Epoch: 30/30..  Running Loss: 2.009.. \n",
            "Epoch: 30/30..  Running Loss: 2.539.. \n",
            "Epoch: 30/30..  Running Loss: 2.893.. \n",
            "Epoch: 30/30..  Running Loss: 2.793.. \n",
            "Epoch: 30/30..  Running Loss: 2.446.. \n",
            "Epoch: 30/30..  Running Loss: 2.231.. \n",
            "Epoch: 30/30..  Running Loss: 2.132.. \n",
            "Epoch: 30/30..  Running Loss: 2.473.. \n",
            "Epoch: 30/30..  Running Loss: 2.167.. \n",
            "Epoch: 30/30..  Running Loss: 2.213.. \n",
            "Epoch: 30/30..  Running Loss: 2.090.. \n",
            "Epoch: 30/30..  Running Loss: 2.452.. \n",
            "Epoch: 30/30..  Running Loss: 2.152.. \n",
            "Epoch: 30/30..  Running Loss: 2.194.. \n",
            "Epoch: 30/30..  Running Loss: 2.441.. \n",
            "Epoch: 30/30..  Running Loss: 2.833.. \n",
            "Epoch: 30/30..  Running Loss: 2.415.. \n",
            "Epoch: 30/30..  Running Loss: 2.458.. \n",
            "Epoch: 30/30..  Running Loss: 2.382.. \n",
            "Epoch: 30/30..  Running Loss: 2.441.. \n",
            "Epoch: 30/30..  Running Loss: 2.576.. \n",
            "Epoch: 30/30..  Running Loss: 2.459.. \n",
            "Epoch: 30/30..  Running Loss: 2.240.. \n",
            "Epoch: 30/30..  Running Loss: 2.569.. \n",
            "Epoch: 30/30..  Running Loss: 2.343.. \n",
            "Epoch: 30/30..  Running Loss: 2.475.. \n",
            "Epoch: 30/30..  Running Loss: 2.521.. \n",
            "Epoch: 30/30..  Running Loss: 2.566.. \n",
            "Epoch: 30/30..  Running Loss: 2.789.. \n",
            "Epoch: 30/30..  Running Loss: 2.825.. \n",
            "Epoch: 30/30..  Running Loss: 2.412.. \n",
            "Epoch: 30/30..  Running Loss: 2.832.. \n",
            "Epoch: 30/30..  Running Loss: 2.493.. \n",
            "Epoch: 30/30..  Running Loss: 2.553.. \n",
            "Epoch: 30/30..  Running Loss: 2.411.. \n",
            "Epoch: 30/30..  Running Loss: 2.428.. \n",
            "Epoch: 30/30..  Running Loss: 2.292.. \n",
            "Epoch: 30/30..  Running Loss: 2.216.. \n",
            "Epoch: 30/30..  Running Loss: 2.618.. \n",
            "Epoch: 30/30..  Running Loss: 2.104.. \n",
            "Epoch: 30/30..  Running Loss: 2.202.. \n",
            "Epoch: 30/30..  Running Loss: 2.858.. \n",
            "Epoch: 30/30..  Running Loss: 2.509.. \n",
            "Epoch: 30/30..  Running Loss: 2.378.. \n",
            "Epoch: 30/30..  Running Loss: 2.456.. \n",
            "Epoch: 30/30..  Running Loss: 2.723.. \n",
            "Epoch: 30/30..  Running Loss: 2.361.. \n",
            "Epoch: 30/30..  Running Loss: 2.558.. \n",
            "Epoch: 30/30..  Running Loss: 2.075.. \n",
            "Epoch: 30/30..  Running Loss: 2.224.. \n",
            "Epoch: 30/30..  Running Loss: 2.438.. \n",
            "Epoch: 30/30..  Running Loss: 2.196.. \n",
            "Epoch: 30/30..  Running Loss: 2.666.. \n",
            "Epoch: 30/30..  Running Loss: 2.319.. \n",
            "Epoch: 30/30..  Running Loss: 2.250.. \n",
            "Epoch: 30/30..  Running Loss: 2.249.. \n",
            "Epoch: 30/30..  Running Loss: 2.195.. \n",
            "Epoch: 30/30..  Running Loss: 2.437.. \n",
            "Epoch: 30/30..  Running Loss: 2.251.. \n",
            "Epoch: 30/30..  Running Loss: 2.229.. \n",
            "Epoch: 30/30..  Running Loss: 2.553.. \n",
            "Epoch: 30/30..  Running Loss: 2.333.. \n",
            "Epoch: 30/30..  Running Loss: 2.489.. \n",
            "Epoch: 30/30..  Running Loss: 2.628.. \n",
            "Epoch: 30/30..  Running Loss: 2.053.. \n",
            "Epoch: 30/30..  Running Loss: 2.505.. \n",
            "Epoch: 30/30..  Running Loss: 2.273.. \n",
            "Epoch: 30/30..  Running Loss: 2.538.. \n",
            "Epoch: 30/30..  Running Loss: 2.062.. \n",
            "Epoch: 30/30..  Running Loss: 2.575.. \n",
            "Epoch: 30/30..  Running Loss: 2.445.. \n",
            "Epoch: 30/30..  Running Loss: 2.260.. \n",
            "Epoch: 30/30..  Running Loss: 2.289.. \n",
            "Epoch: 30/30..  Running Loss: 2.678.. \n",
            "Epoch: 30/30..  Running Loss: 2.188.. \n",
            "Epoch: 30/30..  Running Loss: 2.331.. \n",
            "Epoch: 30/30..  Running Loss: 2.551.. \n",
            "Epoch: 30/30..  Running Loss: 2.408.. \n",
            "Epoch: 30/30..  Running Loss: 2.474.. \n",
            "Epoch: 30/30..  Running Loss: 2.499.. \n",
            "Epoch: 30/30..  Running Loss: 2.256.. \n",
            "Epoch: 30/30..  Running Loss: 2.711.. \n",
            "Epoch: 30/30..  Running Loss: 1.997.. \n",
            "Epoch: 30/30..  Running Loss: 2.401.. \n",
            "Epoch: 30/30..  Running Loss: 2.215.. \n",
            "Epoch: 30/30..  Running Loss: 2.467.. \n",
            "Epoch: 30/30..  Running Loss: 2.396.. \n",
            "Epoch: 30/30..  Running Loss: 2.318.. \n",
            "Epoch: 30/30..  Running Loss: 2.830.. \n",
            "Epoch: 30/30..  Running Loss: 2.309.. \n",
            "Epoch: 30/30..  Running Loss: 2.723.. \n",
            "Epoch: 30/30..  Running Loss: 2.068.. \n",
            "Epoch: 30/30..  Running Loss: 2.239.. \n",
            "Epoch: 30/30..  Running Loss: 2.625.. \n",
            "Epoch: 30/30..  Running Loss: 2.212.. \n",
            "Epoch: 30/30..  Running Loss: 2.110.. \n",
            "Epoch: 30/30..  Running Loss: 2.648.. \n",
            "Epoch: 30/30..  Running Loss: 2.739.. \n",
            "Epoch: 30/30..  Running Loss: 2.490.. \n",
            "Epoch: 30/30..  Running Loss: 2.281.. \n",
            "Epoch: 30/30..  Running Loss: 2.561.. \n",
            "Epoch: 30/30..  Running Loss: 2.608.. \n",
            "Epoch: 30/30..  Running Loss: 2.220.. \n",
            "Epoch: 30/30..  Running Loss: 2.464.. \n",
            "Epoch: 30/30..  Running Loss: 2.093.. \n",
            "Epoch: 30/30..  Running Loss: 2.268.. \n",
            "Epoch: 30/30..  Running Loss: 2.427.. \n",
            "Epoch: 30/30..  Running Loss: 2.448.. \n",
            "Epoch: 30/30..  Running Loss: 2.642.. \n",
            "Epoch: 30/30..  Running Loss: 2.852.. \n",
            "Epoch: 30/30..  Running Loss: 2.549.. \n",
            "Epoch: 30/30..  Running Loss: 2.900.. \n",
            "Epoch: 30/30..  Running Loss: 2.649.. \n",
            "Epoch: 30/30..  Running Loss: 2.558.. \n",
            "Epoch: 30/30..  Running Loss: 2.264.. \n",
            "Epoch: 30/30..  Running Loss: 2.445.. \n",
            "Epoch: 30/30..  Running Loss: 2.340.. \n",
            "Epoch: 30/30..  Running Loss: 2.154.. \n",
            "Epoch: 30/30..  Running Loss: 2.678.. \n",
            "Epoch: 30/30..  Running Loss: 2.002.. \n",
            "Epoch: 30/30..  Running Loss: 2.242.. \n",
            "Epoch: 30/30..  Running Loss: 2.227.. \n",
            "Epoch: 30/30..  Running Loss: 2.017.. \n",
            "Epoch: 30/30..  Running Loss: 2.336.. \n",
            "Epoch: 30/30..  Running Loss: 2.384.. \n",
            "Epoch: 30/30..  Running Loss: 2.353.. \n",
            "Epoch: 30/30..  Running Loss: 2.707.. \n",
            "Epoch: 30/30..  Running Loss: 2.499.. \n",
            "Epoch: 30/30..  Running Loss: 2.400.. \n",
            "Epoch: 30/30..  Running Loss: 2.844.. \n",
            "Epoch: 30/30..  Running Loss: 2.279.. \n",
            "Epoch: 30/30..  Running Loss: 2.377.. \n",
            "Epoch: 30/30..  Running Loss: 2.387.. \n",
            "Epoch: 30/30..  Running Loss: 2.611.. \n",
            "Epoch: 30/30..  Running Loss: 2.825.. \n",
            "Epoch: 30/30..  Running Loss: 2.604.. \n",
            "Epoch: 30/30..  Running Loss: 2.293.. \n",
            "Epoch: 30/30..  Running Loss: 2.634.. \n",
            "Epoch: 30/30..  Running Loss: 2.099.. \n",
            "Epoch: 30/30..  Running Loss: 2.054.. \n",
            "Epoch: 30/30..  Running Loss: 2.132.. \n",
            "Epoch: 30/30..  Running Loss: 2.445.. \n",
            "Epoch: 30/30..  Running Loss: 2.609.. \n",
            "Epoch: 30/30..  Running Loss: 2.487.. \n",
            "Epoch: 30/30..  Running Loss: 2.420.. \n",
            "Epoch: 30/30..  Running Loss: 2.300.. \n",
            "Epoch: 30/30..  Running Loss: 2.831.. \n",
            "Epoch: 30/30..  Running Loss: 2.433.. \n",
            "Epoch: 30/30..  Running Loss: 2.513.. \n",
            "Epoch: 30/30..  Running Loss: 2.247.. \n",
            "Epoch: 30/30..  Running Loss: 2.616.. \n",
            "Epoch: 30/30..  Running Loss: 2.424.. \n",
            "Epoch: 30/30..  Running Loss: 2.090.. \n",
            "Epoch: 30/30..  Running Loss: 2.303.. \n",
            "Epoch: 30/30..  Running Loss: 2.058.. \n",
            "Epoch: 30/30..  Running Loss: 1.961.. \n",
            "Epoch: 30/30..  Running Loss: 2.279.. \n",
            "Epoch: 30/30..  Running Loss: 2.600.. \n",
            "Epoch: 30/30..  Running Loss: 1.947.. \n",
            "Epoch: 30/30..  Running Loss: 2.111.. \n",
            "Epoch: 30/30..  Running Loss: 2.143.. \n",
            "Epoch: 30/30..  Running Loss: 2.455.. \n",
            "Epoch: 30/30..  Running Loss: 2.174.. \n",
            "Epoch: 30/30..  Running Loss: 1.971.. \n",
            "Epoch: 30/30..  Running Loss: 2.099.. \n",
            "Epoch: 30/30..  Running Loss: 2.121.. \n",
            "Epoch: 30/30..  Running Loss: 2.270.. \n",
            "Epoch: 30/30..  Running Loss: 2.175.. \n",
            "Epoch: 30/30..  Running Loss: 2.298.. \n",
            "Epoch: 30/30..  Running Loss: 2.687.. \n",
            "Epoch: 30/30..  Running Loss: 2.430.. \n",
            "Epoch: 30/30..  Running Loss: 2.463.. \n",
            "Epoch: 30/30..  Running Loss: 2.242.. \n",
            "Epoch: 30/30..  Running Loss: 2.491.. \n",
            "Epoch: 30/30..  Running Loss: 2.183.. \n",
            "Epoch: 30/30..  Running Loss: 1.777.. \n",
            "Epoch: 30/30..  Running Loss: 2.188.. \n",
            "Epoch: 30/30..  Running Loss: 1.735.. \n",
            "Epoch: 30/30..  Running Loss: 2.199.. \n",
            "Epoch: 30/30..  Running Loss: 2.252.. \n",
            "Epoch: 30/30..  Running Loss: 2.770.. \n",
            "Epoch: 30/30..  Running Loss: 2.910.. \n",
            "Epoch: 30/30..  Running Loss: 2.108.. \n",
            "Epoch: 30/30..  Running Loss: 2.217.. \n",
            "Epoch: 30/30..  Running Loss: 2.577.. \n",
            "Epoch: 30/30..  Running Loss: 2.248.. \n",
            "Epoch: 30/30..  Running Loss: 2.385.. \n",
            "Epoch: 30/30..  Running Loss: 2.170.. \n",
            "Epoch: 30/30..  Running Loss: 2.409.. \n",
            "Epoch: 30/30..  Running Loss: 2.462.. \n",
            "Epoch: 30/30..  Running Loss: 2.198.. \n",
            "Epoch: 30/30..  Running Loss: 2.252.. \n",
            "Epoch: 30/30..  Running Loss: 2.293.. \n",
            "Epoch: 30/30..  Running Loss: 2.182.. \n",
            "Epoch: 30/30..  Running Loss: 2.291.. \n",
            "Epoch: 30/30..  Running Loss: 2.431.. \n",
            "Epoch: 30/30..  Running Loss: 2.376.. \n",
            "Epoch: 30/30..  Running Loss: 2.138.. \n",
            "Epoch: 30/30..  Running Loss: 2.170.. \n",
            "Epoch: 30/30..  Running Loss: 2.486.. \n",
            "Epoch: 30/30..  Running Loss: 2.993.. \n",
            "Epoch: 30/30..  Running Loss: 2.251.. \n",
            "Epoch: 30/30..  Running Loss: 2.245.. \n",
            "Epoch: 30/30..  Running Loss: 2.250.. \n",
            "Epoch: 30/30..  Running Loss: 2.089.. \n",
            "Epoch: 30/30..  Running Loss: 2.188.. \n",
            "Epoch: 30/30..  Running Loss: 2.480.. \n",
            "Epoch: 30/30..  Running Loss: 2.900.. \n",
            "Epoch: 30/30..  Running Loss: 2.833.. \n",
            "Epoch: 30/30..  Running Loss: 2.101.. \n",
            "Epoch: 30/30..  Running Loss: 2.320.. \n",
            "Epoch: 30/30..  Running Loss: 2.760.. \n",
            "Epoch: 30/30..  Running Loss: 2.102.. \n",
            "Epoch: 30/30..  Running Loss: 2.398.. \n",
            "Epoch: 30/30..  Running Loss: 2.559.. \n",
            "Epoch: 30/30..  Running Loss: 2.756.. \n",
            "Epoch: 30/30..  Running Loss: 1.871.. \n",
            "Epoch: 30/30..  Running Loss: 1.887.. \n",
            "Epoch: 30/30..  Running Loss: 2.130.. \n",
            "Epoch: 30/30..  Running Loss: 2.818.. \n",
            "Epoch: 30/30..  Running Loss: 2.605.. \n",
            "Epoch: 30/30..  Running Loss: 2.535.. \n",
            "Epoch: 30/30..  Running Loss: 2.687.. \n",
            "Epoch: 30/30..  Running Loss: 2.859.. \n",
            "Epoch: 30/30..  Running Loss: 2.890.. \n",
            "Epoch: 30/30..  Running Loss: 2.291.. \n",
            "Epoch: 30/30..  Running Loss: 2.476.. \n",
            "Epoch: 30/30..  Running Loss: 2.233.. \n",
            "Epoch: 30/30..  Running Loss: 2.058.. \n",
            "Epoch: 30/30..  Running Loss: 2.280.. \n",
            "Epoch: 30/30..  Running Loss: 2.734.. \n",
            "Epoch: 30/30..  Running Loss: 2.183.. \n",
            "Epoch: 30/30..  Running Loss: 1.942.. \n",
            "Epoch: 30/30..  Running Loss: 2.331.. \n",
            "Epoch: 30/30..  Running Loss: 2.257.. \n",
            "Epoch: 30/30..  Running Loss: 2.432.. \n",
            "Epoch: 30/30..  Running Loss: 2.388.. \n",
            "Epoch: 30/30..  Running Loss: 2.554.. \n",
            "Epoch: 30/30..  Running Loss: 2.459.. \n",
            "Epoch: 30/30..  Running Loss: 2.568.. \n",
            "Epoch: 30/30..  Running Loss: 2.529.. \n",
            "Epoch: 30/30..  Running Loss: 2.399.. \n",
            "Epoch: 30/30..  Running Loss: 2.332.. \n",
            "Epoch: 30/30..  Running Loss: 2.213.. \n",
            "Epoch: 30/30..  Running Loss: 2.410.. \n",
            "Epoch: 30/30..  Running Loss: 2.662.. \n",
            "Epoch: 30/30..  Running Loss: 2.620.. \n",
            "Epoch: 30/30..  Running Loss: 2.268.. \n",
            "Epoch: 30/30..  Running Loss: 2.195.. \n",
            "Epoch: 30/30..  Running Loss: 2.075.. \n",
            "Epoch: 30/30..  Running Loss: 2.178.. \n",
            "Epoch: 30/30..  Running Loss: 2.840.. \n",
            "Epoch: 30/30..  Running Loss: 2.680.. \n",
            "Epoch: 30/30..  Running Loss: 2.141.. \n",
            "Epoch: 30/30..  Running Loss: 2.485.. \n",
            "Epoch: 30/30..  Running Loss: 2.444.. \n",
            "Epoch: 30/30..  Running Loss: 2.733.. \n",
            "Epoch: 30/30..  Running Loss: 2.298.. \n",
            "Epoch: 30/30..  Running Loss: 2.351.. \n",
            "Epoch: 30/30..  Running Loss: 2.652.. \n",
            "Epoch: 30/30..  Running Loss: 2.666.. \n",
            "Epoch: 30/30..  Running Loss: 2.637.. \n",
            "Epoch: 30/30..  Running Loss: 2.030.. \n",
            "Epoch: 30/30..  Running Loss: 2.352.. \n",
            "Epoch: 30/30..  Running Loss: 2.643.. \n",
            "Epoch: 30/30..  Running Loss: 2.395.. \n",
            "Epoch: 30/30..  Running Loss: 1.909.. \n",
            "Epoch: 30/30..  Running Loss: 2.398.. \n",
            "Epoch: 30/30..  Running Loss: 2.606.. \n",
            "Epoch: 30/30..  Running Loss: 2.485.. \n",
            "Epoch: 30/30..  Running Loss: 2.383.. \n",
            "Epoch: 30/30..  Running Loss: 2.720.. \n",
            "Epoch: 30/30..  Running Loss: 2.276.. \n",
            "Epoch: 30/30..  Running Loss: 2.290.. \n",
            "Epoch: 30/30..  Running Loss: 2.193.. \n",
            "Epoch: 30/30..  Running Loss: 2.490.. \n",
            "Epoch: 30/30..  Running Loss: 2.512.. \n",
            "Epoch: 30/30..  Running Loss: 2.323.. \n",
            "Epoch: 30/30..  Running Loss: 2.465.. \n",
            "Epoch: 30/30..  Running Loss: 2.200.. \n",
            "Epoch: 30/30..  Running Loss: 2.339.. \n",
            "Epoch: 30/30..  Running Loss: 2.592.. \n",
            "Epoch: 30/30..  Running Loss: 2.644.. \n",
            "Epoch: 30/30..  Running Loss: 2.758.. \n",
            "Epoch: 30/30..  Running Loss: 2.136.. \n",
            "Epoch: 30/30..  Running Loss: 2.813.. \n",
            "Epoch: 30/30..  Running Loss: 2.585.. \n",
            "Epoch: 30/30..  Running Loss: 2.392.. \n",
            "Epoch: 30/30..  Running Loss: 2.623.. \n",
            "Epoch: 30/30..  Running Loss: 2.621.. \n",
            "Epoch: 30/30..  Running Loss: 2.366.. \n",
            "Epoch: 30/30..  Running Loss: 2.063.. \n",
            "Epoch: 30/30..  Running Loss: 2.192.. \n",
            "Epoch: 30/30..  Running Loss: 2.243.. \n",
            "Epoch: 30/30..  Running Loss: 2.759.. \n",
            "Epoch: 30/30..  Running Loss: 2.198.. \n",
            "Epoch: 30/30..  Running Loss: 2.274.. \n",
            "Epoch: 30/30..  Running Loss: 2.396.. \n",
            "Epoch: 30/30..  Running Loss: 2.365.. \n",
            "Epoch: 30/30..  Running Loss: 2.850.. \n",
            "Epoch: 30/30..  Running Loss: 2.207.. \n",
            "Epoch: 30/30..  Running Loss: 2.543.. \n",
            "Epoch: 30/30..  Running Loss: 2.371.. \n",
            "Epoch: 30/30..  Running Loss: 2.510.. \n",
            "Epoch: 30/30..  Running Loss: 2.973.. \n",
            "Epoch: 30/30..  Running Loss: 2.272.. \n",
            "Epoch: 30/30..  Running Loss: 2.364.. \n",
            "Epoch: 30/30..  Running Loss: 2.606.. \n",
            "Epoch: 30/30..  Running Loss: 2.351.. \n",
            "Epoch: 30/30..  Running Loss: 2.573.. \n",
            "Epoch: 30/30..  Running Loss: 2.298.. \n",
            "Epoch: 30/30..  Running Loss: 2.386.. \n",
            "Epoch: 30/30..  Running Loss: 2.529.. \n",
            "Epoch: 30/30..  Running Loss: 2.247.. \n",
            "Epoch: 30/30..  Running Loss: 2.786.. \n",
            "Epoch: 30/30..  Running Loss: 2.264.. \n",
            "Epoch: 30/30..  Running Loss: 2.147.. \n",
            "Epoch: 30/30..  Running Loss: 2.772.. \n",
            "Epoch: 30/30..  Running Loss: 2.297.. \n",
            "Epoch: 30/30..  Running Loss: 2.213.. \n",
            "Epoch: 30/30..  Running Loss: 2.259.. \n",
            "Epoch: 30/30..  Running Loss: 1.941.. \n",
            "Epoch: 30/30..  Running Loss: 2.677.. \n",
            "Epoch: 30/30..  Running Loss: 2.211.. \n",
            "Epoch: 30/30..  Running Loss: 2.661.. \n",
            "Epoch: 30/30..  Running Loss: 2.178.. \n",
            "Epoch: 30/30..  Running Loss: 2.100.. \n",
            "Epoch: 30/30..  Running Loss: 2.204.. \n",
            "Epoch: 30/30..  Running Loss: 2.447.. \n",
            "Epoch: 30/30..  Running Loss: 2.285.. \n",
            "Epoch: 30/30..  Running Loss: 2.425.. \n",
            "Epoch: 30/30..  Running Loss: 2.437.. \n",
            "Epoch: 30/30..  Running Loss: 2.583.. \n",
            "Epoch: 30/30..  Running Loss: 1.969.. \n",
            "Epoch: 30/30..  Running Loss: 1.617.. \n",
            "Epoch: 30/30..  Running Loss: 1.907.. \n",
            "Epoch: 30/30..  Running Loss: 2.080.. \n",
            "Epoch: 30/30..  Running Loss: 2.336.. \n",
            "Epoch: 30/30..  Running Loss: 2.080.. \n",
            "Epoch: 30/30..  Running Loss: 2.246.. \n",
            "Epoch: 30/30..  Running Loss: 2.380.. \n",
            "Epoch: 30/30..  Running Loss: 2.644.. \n",
            "Epoch: 30/30..  Running Loss: 2.495.. \n",
            "Epoch: 30/30..  Running Loss: 2.300.. \n",
            "Epoch: 30/30..  Running Loss: 2.157.. \n",
            "Epoch: 30/30..  Running Loss: 2.612.. \n",
            "Epoch: 30/30..  Running Loss: 2.038.. \n",
            "Epoch: 30/30..  Running Loss: 2.295.. \n",
            "Epoch: 30/30..  Running Loss: 2.225.. \n",
            "Epoch: 30/30..  Running Loss: 2.414.. \n",
            "Epoch: 30/30..  Running Loss: 2.414.. \n",
            "Epoch: 30/30..  Running Loss: 2.123.. \n",
            "Epoch: 30/30..  Running Loss: 2.188.. \n",
            "Epoch: 30/30..  Running Loss: 2.501.. \n",
            "Epoch: 30/30..  Running Loss: 2.416.. \n",
            "Epoch: 30/30..  Running Loss: 2.616.. \n",
            "Epoch: 30/30..  Running Loss: 2.555.. \n",
            "Epoch: 30/30..  Running Loss: 2.196.. \n",
            "Epoch: 30/30..  Running Loss: 2.284.. \n",
            "Epoch: 30/30..  Running Loss: 2.225.. \n",
            "Epoch: 30/30..  Running Loss: 2.107.. \n",
            "Epoch: 30/30..  Running Loss: 2.423.. \n",
            "Epoch: 30/30..  Running Loss: 2.298.. \n",
            "Epoch: 30/30..  Running Loss: 2.024.. \n",
            "Epoch: 30/30..  Running Loss: 1.827.. \n",
            "Epoch: 30/30..  Running Loss: 1.950.. \n",
            "Epoch: 30/30..  Running Loss: 2.261.. \n",
            "Epoch: 30/30..  Running Loss: 2.269.. \n",
            "Epoch: 30/30..  Running Loss: 1.236.. \n",
            "Epoch: 30/30..  Running Loss: 2.043.. \n",
            "Epoch: 30/30..  Running Loss: 2.133.. \n",
            "Epoch: 30/30..  Running Loss: 2.453.. \n",
            "Epoch: 30/30..  Running Loss: 1.138.. \n",
            "Epoch: 30/30..  Running Loss: 1.970.. \n",
            "Epoch: 30/30..  Running Loss: 1.672.. \n",
            "Epoch: 30/30..  Running Loss: 1.998.. \n",
            "Epoch: 30/30..  Running Loss: 1.074.. \n",
            "Epoch: 30/30..  Running Loss: 2.005.. \n",
            "Epoch: 30/30..  Running Loss: 2.171.. \n",
            "Epoch: 30/30..  Running Loss: 2.061.. \n",
            "Epoch: 30/30..  Running Loss: 1.371.. \n",
            "Epoch: 30/30..  Running Loss: 2.284.. \n",
            "Epoch: 30/30..  Running Loss: 2.260.. \n",
            "Epoch: 30/30..  Running Loss: 2.284.. \n",
            "Epoch: 30/30..  Running Loss: 2.495.. \n",
            "Epoch: 30/30..  Running Loss: 2.700.. \n",
            "Epoch: 30/30..  Running Loss: 2.402.. \n",
            "Epoch: 30/30..  Running Loss: 2.548.. \n",
            "Epoch: 30/30..  Running Loss: 2.043.. \n",
            "Epoch: 30/30..  Running Loss: 2.240.. \n",
            "Epoch: 30/30..  Running Loss: 2.083.. \n",
            "Epoch: 30/30..  Running Loss: 2.705.. \n",
            "Epoch: 30/30..  Running Loss: 2.017.. \n",
            "Epoch: 30/30..  Running Loss: 2.235.. \n",
            "Epoch: 30/30..  Running Loss: 2.419.. \n",
            "Epoch: 30/30..  Running Loss: 2.383.. \n",
            "Epoch: 30/30..  Running Loss: 1.932.. \n",
            "Epoch: 30/30..  Running Loss: 1.659.. \n",
            "Epoch: 30/30..  Running Loss: 2.621.. \n",
            "Epoch: 30/30..  Running Loss: 2.458.. \n",
            "Epoch: 30/30..  Running Loss: 1.773.. \n",
            "Epoch: 30/30..  Running Loss: 2.300.. \n",
            "Epoch: 30/30..  Running Loss: 2.647.. \n",
            "Epoch: 30/30..  Running Loss: 2.730.. \n",
            "Epoch: 30/30..  Running Loss: 2.558.. \n",
            "Epoch: 30/30..  Running Loss: 2.441.. \n",
            "Epoch: 30/30..  Running Loss: 2.531.. \n",
            "Epoch: 30/30..  Running Loss: 2.375.. \n",
            "Epoch: 30/30..  Running Loss: 2.497.. \n",
            "Epoch: 30/30..  Running Loss: 2.733.. \n",
            "Epoch: 30/30..  Running Loss: 2.122.. \n",
            "Epoch: 30/30..  Running Loss: 2.078.. \n",
            "Epoch: 30/30..  Running Loss: 2.383.. \n",
            "Epoch: 30/30..  Running Loss: 2.109.. \n",
            "Epoch: 30/30..  Running Loss: 2.835.. \n",
            "Epoch: 30/30..  Running Loss: 2.247.. \n",
            "Epoch: 30/30..  Running Loss: 2.312.. \n",
            "Epoch: 30/30..  Running Loss: 2.066.. \n",
            "Epoch: 30/30..  Running Loss: 2.008.. \n",
            "Epoch: 30/30..  Running Loss: 1.785.. \n",
            "Epoch: 30/30..  Running Loss: 2.456.. \n",
            "Epoch: 30/30..  Running Loss: 2.097.. \n",
            "Epoch: 30/30..  Running Loss: 2.623.. \n",
            "Epoch: 30/30..  Running Loss: 2.910.. \n",
            "Epoch: 30/30..  Running Loss: 2.214.. \n",
            "Epoch: 30/30..  Running Loss: 2.255.. \n",
            "Epoch: 30/30..  Running Loss: 2.170.. \n",
            "Epoch: 30/30..  Running Loss: 1.850.. \n",
            "Epoch: 30/30..  Running Loss: 1.622.. \n",
            "Epoch: 30/30..  Running Loss: 1.390.. \n",
            "Epoch: 30/30..  Running Loss: 2.315.. \n",
            "Epoch: 30/30..  Running Loss: 1.560.. \n",
            "Epoch: 30/30..  Running Loss: 1.887.. \n",
            "Epoch: 30/30..  Running Loss: 2.069.. \n",
            "Epoch: 30/30..  Running Loss: 2.095.. \n",
            "Epoch: 30/30..  Running Loss: 2.413.. \n",
            "Epoch: 30/30..  Running Loss: 2.831.. \n",
            "Epoch: 30/30..  Running Loss: 2.420.. \n",
            "Epoch: 30/30..  Running Loss: 2.502.. \n",
            "Epoch: 30/30..  Running Loss: 2.257.. \n",
            "Epoch: 30/30..  Running Loss: 2.442.. \n",
            "Epoch: 30/30..  Running Loss: 2.260.. \n",
            "Epoch: 30/30..  Running Loss: 2.688.. \n",
            "Epoch: 30/30..  Running Loss: 2.316.. \n",
            "Epoch: 30/30..  Running Loss: 2.215.. \n",
            "Epoch: 30/30..  Running Loss: 2.633.. \n",
            "Epoch: 30/30..  Running Loss: 2.613.. \n",
            "Epoch: 30/30..  Running Loss: 2.366.. \n",
            "Epoch: 30/30..  Running Loss: 2.079.. \n",
            "Epoch: 30/30..  Running Loss: 2.203.. \n",
            "Epoch: 30/30..  Running Loss: 2.819.. \n",
            "Epoch: 30/30..  Running Loss: 1.727.. \n",
            "Epoch: 30/30..  Running Loss: 2.029.. \n",
            "Epoch: 30/30..  Running Loss: 2.153.. \n",
            "Epoch: 30/30..  Running Loss: 2.372.. \n",
            "Epoch: 30/30..  Running Loss: 2.226.. \n",
            "Epoch: 30/30..  Running Loss: 2.060.. \n",
            "Epoch: 30/30..  Running Loss: 2.893.. \n",
            "Epoch: 30/30..  Running Loss: 2.379.. \n",
            "Epoch: 30/30..  Running Loss: 2.423.. \n",
            "Epoch: 30/30..  Running Loss: 2.345.. \n",
            "Epoch: 30/30..  Running Loss: 2.559.. \n",
            "Epoch: 30/30..  Running Loss: 2.161.. \n",
            "Epoch: 30/30..  Running Loss: 2.306.. \n",
            "Epoch: 30/30..  Running Loss: 2.137.. \n",
            "Epoch: 30/30..  Running Loss: 2.384.. \n",
            "Epoch: 30/30..  Running Loss: 2.639.. \n",
            "Epoch: 30/30..  Running Loss: 2.486.. \n",
            "Epoch: 30/30..  Running Loss: 2.313.. \n",
            "Epoch: 30/30..  Running Loss: 2.286.. \n",
            "Epoch: 30/30..  Running Loss: 2.102.. \n",
            "Epoch: 30/30..  Running Loss: 2.459.. \n",
            "Epoch: 30/30..  Running Loss: 2.794.. \n",
            "Epoch: 30/30..  Running Loss: 2.532.. \n",
            "Epoch: 30/30..  Running Loss: 2.131.. \n",
            "Epoch: 30/30..  Running Loss: 2.677.. \n",
            "Epoch: 30/30..  Running Loss: 2.069.. \n",
            "Epoch: 30/30..  Running Loss: 2.193.. \n",
            "Epoch: 30/30..  Running Loss: 2.031.. \n",
            "Epoch: 30/30..  Running Loss: 2.290.. \n",
            "Epoch: 30/30..  Running Loss: 1.658.. \n",
            "Epoch: 30/30..  Running Loss: 2.591.. \n",
            "Epoch: 30/30..  Running Loss: 2.607.. \n",
            "Epoch: 30/30..  Running Loss: 2.096.. \n",
            "Epoch: 30/30..  Running Loss: 2.534.. \n",
            "Epoch: 30/30..  Running Loss: 2.476.. \n",
            "Epoch: 30/30..  Running Loss: 2.517.. \n",
            "Epoch: 30/30..  Running Loss: 2.591.. \n",
            "Epoch: 30/30..  Running Loss: 2.176.. \n",
            "Epoch: 30/30..  Running Loss: 2.405.. \n",
            "Epoch: 30/30..  Running Loss: 2.352.. \n",
            "Epoch: 30/30..  Running Loss: 1.764.. \n",
            "Epoch: 30/30..  Running Loss: 2.436.. \n",
            "Epoch: 30/30..  Running Loss: 2.203.. \n",
            "Epoch: 30/30..  Running Loss: 2.531.. \n",
            "Epoch: 30/30..  Running Loss: 2.186.. \n",
            "Epoch: 30/30..  Running Loss: 2.482.. \n",
            "Epoch: 30/30..  Running Loss: 2.253.. \n",
            "Epoch: 30/30..  Running Loss: 2.620.. \n",
            "Epoch: 30/30..  Running Loss: 2.475.. \n",
            "Epoch: 30/30..  Running Loss: 2.379.. \n",
            "Epoch: 30/30..  Running Loss: 2.563.. \n",
            "Epoch: 30/30..  Running Loss: 2.246.. \n",
            "Epoch: 30/30..  Running Loss: 2.297.. \n",
            "Epoch: 30/30..  Running Loss: 2.032.. \n",
            "Epoch: 30/30..  Running Loss: 2.641.. \n",
            "Epoch: 30/30..  Running Loss: 2.508.. \n",
            "Epoch: 30/30..  Running Loss: 2.280.. \n",
            "Epoch: 30/30..  Running Loss: 2.363.. \n",
            "Epoch: 30/30..  Running Loss: 2.247.. \n",
            "Epoch: 30/30..  Running Loss: 2.573.. \n",
            "Epoch: 30/30..  Running Loss: 2.305.. \n",
            "Epoch: 30/30..  Running Loss: 2.496.. \n",
            "Epoch: 30/30..  Running Loss: 2.431.. \n",
            "Epoch: 30/30..  Running Loss: 2.702.. \n",
            "Epoch: 30/30..  Running Loss: 2.533.. \n",
            "Epoch: 30/30..  Running Loss: 2.037.. \n",
            "Epoch: 30/30..  Running Loss: 2.341.. \n",
            "Epoch: 30/30..  Running Loss: 2.443.. \n",
            "Epoch: 30/30..  Running Loss: 2.663.. \n",
            "Epoch: 30/30..  Running Loss: 2.017.. \n",
            "Epoch: 30/30..  Running Loss: 2.441.. \n",
            "Epoch: 30/30..  Running Loss: 2.641.. \n",
            "Epoch: 30/30..  Running Loss: 2.059.. \n",
            "Epoch: 30/30..  Running Loss: 1.890.. \n",
            "Epoch: 30/30..  Running Loss: 2.683.. \n",
            "Epoch: 30/30..  Running Loss: 2.405.. \n",
            "Epoch: 30/30..  Running Loss: 2.636.. \n",
            "Epoch: 30/30..  Running Loss: 2.244.. \n",
            "Epoch: 30/30..  Running Loss: 1.790.. \n",
            "Epoch: 30/30..  Running Loss: 2.346.. \n",
            "Epoch: 30/30..  Running Loss: 2.580.. \n",
            "Epoch: 30/30..  Running Loss: 2.018.. \n",
            "Epoch: 30/30..  Running Loss: 2.134.. \n",
            "Epoch: 30/30..  Running Loss: 2.302.. \n",
            "Epoch: 30/30..  Running Loss: 2.518.. \n",
            "Epoch: 30/30..  Running Loss: 2.355.. \n",
            "Epoch: 30/30..  Running Loss: 2.256.. \n",
            "Epoch: 30/30..  Running Loss: 2.350.. \n",
            "Epoch: 30/30..  Running Loss: 2.188.. \n",
            "Epoch: 30/30..  Running Loss: 2.018.. \n",
            "Epoch: 30/30..  Running Loss: 2.224.. \n",
            "Epoch: 30/30..  Running Loss: 2.259.. \n",
            "Epoch: 30/30..  Running Loss: 1.967.. \n",
            "Epoch: 30/30..  Running Loss: 2.117.. \n",
            "Epoch: 30/30..  Running Loss: 2.294.. \n",
            "Epoch: 30/30..  Running Loss: 2.175.. \n",
            "Epoch: 30/30..  Running Loss: 2.341.. \n",
            "Epoch: 30/30..  Running Loss: 2.605.. \n",
            "Epoch: 30/30..  Running Loss: 2.406.. \n",
            "Epoch: 30/30..  Running Loss: 2.362.. \n",
            "Epoch: 30/30..  Running Loss: 2.230.. \n",
            "Epoch: 30/30..  Running Loss: 2.527.. \n",
            "Epoch: 30/30..  Running Loss: 2.573.. \n",
            "Epoch: 30/30..  Running Loss: 2.438.. \n",
            "Epoch: 30/30..  Running Loss: 2.488.. \n",
            "Epoch: 30/30..  Running Loss: 2.325.. \n",
            "Epoch: 30/30..  Running Loss: 1.970.. \n",
            "Epoch: 30/30..  Running Loss: 2.303.. \n",
            "Epoch: 30/30..  Running Loss: 2.519.. \n",
            "Epoch: 30/30..  Running Loss: 2.403.. \n",
            "Epoch: 30/30..  Running Loss: 2.130.. \n",
            "Epoch: 30/30..  Running Loss: 2.554.. \n",
            "Epoch: 30/30..  Running Loss: 2.311.. \n",
            "Epoch: 30/30..  Running Loss: 1.817.. \n",
            "Epoch: 30/30..  Running Loss: 2.413.. \n",
            "Epoch: 30/30..  Running Loss: 2.552.. \n",
            "Epoch: 30/30..  Running Loss: 2.030.. \n",
            "Epoch: 30/30..  Running Loss: 2.515.. \n",
            "Epoch: 30/30..  Running Loss: 2.334.. \n",
            "Epoch: 30/30..  Running Loss: 2.570.. \n",
            "Epoch: 30/30..  Running Loss: 2.325.. \n",
            "Epoch: 30/30..  Running Loss: 2.686.. \n",
            "Epoch: 30/30..  Running Loss: 2.504.. \n",
            "Epoch: 30/30..  Running Loss: 2.329.. \n",
            "Epoch: 30/30..  Running Loss: 2.406.. \n",
            "Epoch: 30/30..  Running Loss: 2.205.. \n",
            "Epoch: 30/30..  Running Loss: 2.365.. \n",
            "Epoch: 30/30..  Running Loss: 2.500.. \n",
            "Epoch: 30/30..  Running Loss: 2.263.. \n",
            "Epoch: 30/30..  Running Loss: 2.420.. \n",
            "Epoch: 30/30..  Running Loss: 2.144.. \n",
            "Epoch: 30/30..  Running Loss: 2.363.. \n",
            "Epoch: 30/30..  Running Loss: 2.759.. \n",
            "Epoch: 30/30..  Running Loss: 2.664.. \n",
            "Epoch: 30/30..  Running Loss: 2.157.. \n",
            "Epoch: 30/30..  Running Loss: 2.119.. \n",
            "Epoch: 30/30..  Running Loss: 1.878.. \n",
            "Epoch: 30/30..  Running Loss: 2.843.. \n",
            "Epoch: 30/30..  Running Loss: 2.383.. \n",
            "Epoch: 30/30..  Running Loss: 2.555.. \n",
            "Epoch: 30/30..  Running Loss: 1.958.. \n",
            "Epoch: 30/30..  Running Loss: 1.917.. \n",
            "Epoch: 30/30..  Running Loss: 2.256.. \n",
            "Epoch: 30/30..  Running Loss: 2.290.. \n",
            "Epoch: 30/30..  Running Loss: 1.777.. \n",
            "Epoch: 30/30..  Running Loss: 1.835.. \n",
            "Epoch: 30/30..  Running Loss: 1.627.. \n",
            "Epoch: 30/30..  Running Loss: 2.545.. \n",
            "Epoch: 30/30..  Running Loss: 2.739.. \n",
            "Epoch: 30/30..  Running Loss: 2.609.. \n",
            "Epoch: 30/30..  Running Loss: 2.787.. \n",
            "Epoch: 30/30..  Running Loss: 2.376.. \n",
            "Epoch: 30/30..  Running Loss: 2.303.. \n",
            "Epoch: 30/30..  Running Loss: 2.677.. \n",
            "Epoch: 30/30..  Running Loss: 2.113.. \n",
            "Epoch: 30/30..  Running Loss: 2.495.. \n",
            "Epoch: 30/30..  Running Loss: 2.150.. \n",
            "Epoch: 30/30..  Running Loss: 2.515.. \n",
            "Epoch: 30/30..  Running Loss: 2.168.. \n",
            "Epoch: 30/30..  Running Loss: 2.227.. \n",
            "Epoch: 30/30..  Running Loss: 2.024.. \n",
            "Epoch: 30/30..  Running Loss: 2.581.. \n",
            "Epoch: 30/30..  Running Loss: 2.381.. \n",
            "Epoch: 30/30..  Running Loss: 2.525.. \n",
            "Epoch: 30/30..  Running Loss: 2.478.. \n",
            "Epoch: 30/30..  Running Loss: 2.224.. \n",
            "Epoch: 30/30..  Running Loss: 2.486.. \n",
            "Epoch: 30/30..  Running Loss: 2.316.. \n",
            "Epoch: 30/30..  Running Loss: 2.561.. \n",
            "Epoch: 30/30..  Running Loss: 2.000.. \n",
            "Epoch: 30/30..  Running Loss: 2.455.. \n",
            "Epoch: 30/30..  Running Loss: 2.502.. \n",
            "Epoch: 30/30..  Running Loss: 2.230.. \n",
            "Epoch: 30/30..  Running Loss: 2.398.. \n",
            "Epoch: 30/30..  Running Loss: 2.713.. \n",
            "Epoch: 30/30..  Running Loss: 2.772.. \n",
            "Epoch: 30/30..  Running Loss: 2.680.. \n",
            "Epoch: 30/30..  Running Loss: 2.279.. \n",
            "Epoch: 30/30..  Running Loss: 2.728.. \n",
            "Epoch: 30/30..  Running Loss: 2.255.. \n",
            "Epoch: 30/30..  Running Loss: 2.351.. \n",
            "Epoch: 30/30..  Running Loss: 2.501.. \n",
            "Epoch: 30/30..  Running Loss: 2.431.. \n",
            "Epoch: 30/30..  Running Loss: 2.159.. \n",
            "Epoch: 30/30..  Running Loss: 2.420.. \n",
            "Epoch: 30/30..  Running Loss: 2.293.. \n",
            "Epoch: 30/30..  Running Loss: 2.373.. \n",
            "Epoch: 30/30..  Running Loss: 2.615.. \n",
            "Epoch: 30/30..  Running Loss: 2.578.. \n",
            "Epoch: 30/30..  Running Loss: 2.583.. \n",
            "Epoch: 30/30..  Running Loss: 2.452.. \n",
            "Epoch: 30/30..  Running Loss: 2.688.. \n",
            "Epoch: 30/30..  Running Loss: 2.272.. \n",
            "Epoch: 30/30..  Running Loss: 2.552.. \n",
            "Epoch: 30/30..  Running Loss: 2.472.. \n",
            "Epoch: 30/30..  Running Loss: 2.269.. \n",
            "Epoch: 30/30..  Running Loss: 2.443.. \n",
            "Epoch: 30/30..  Running Loss: 2.798.. \n",
            "Epoch: 30/30..  Running Loss: 2.540.. \n",
            "Epoch: 30/30..  Running Loss: 2.398.. \n",
            "Epoch: 30/30..  Running Loss: 2.302.. \n",
            "Epoch: 30/30..  Running Loss: 2.692.. \n",
            "Epoch: 30/30..  Running Loss: 2.199.. \n",
            "Epoch: 30/30..  Running Loss: 2.253.. \n",
            "Epoch: 30/30..  Running Loss: 2.299.. \n",
            "Epoch: 30/30..  Running Loss: 2.358.. \n",
            "Epoch: 30/30..  Running Loss: 2.007.. \n",
            "Epoch: 30/30..  Running Loss: 1.963.. \n",
            "Epoch: 30/30..  Running Loss: 1.995.. \n",
            "Epoch: 30/30..  Running Loss: 2.164.. \n",
            "Epoch: 30/30..  Running Loss: 1.744.. \n",
            "Epoch: 30/30..  Running Loss: 1.711.. \n",
            "Epoch: 30/30..  Running Loss: 2.012.. \n",
            "Epoch: 30/30..  Running Loss: 2.177.. \n",
            "Epoch: 30/30..  Running Loss: 2.060.. \n",
            "Epoch: 30/30..  Running Loss: 2.456.. \n",
            "Epoch: 30/30..  Running Loss: 2.726.. \n",
            "Epoch: 30/30..  Running Loss: 2.312.. \n",
            "Epoch: 30/30..  Running Loss: 2.610.. \n",
            "Epoch: 30/30..  Running Loss: 2.195.. \n",
            "Epoch: 30/30..  Running Loss: 2.059.. \n",
            "Epoch: 30/30..  Running Loss: 2.159.. \n",
            "Epoch: 30/30..  Running Loss: 2.302.. \n",
            "Epoch: 30/30..  Running Loss: 2.603.. \n",
            "Epoch: 30/30..  Running Loss: 2.421.. \n",
            "Epoch: 30/30..  Running Loss: 2.305.. \n",
            "Epoch: 30/30..  Running Loss: 2.179.. \n",
            "Epoch: 30/30..  Running Loss: 2.339.. \n",
            "Epoch: 30/30..  Running Loss: 2.175.. \n",
            "Epoch: 30/30..  Running Loss: 2.319.. \n",
            "Epoch: 30/30..  Running Loss: 1.986.. \n",
            "Epoch: 30/30..  Running Loss: 2.160.. \n",
            "Epoch: 30/30..  Running Loss: 2.481.. \n",
            "Epoch: 30/30..  Running Loss: 2.655.. \n",
            "Epoch: 30/30..  Running Loss: 2.301.. \n",
            "Epoch: 30/30..  Running Loss: 2.203.. \n",
            "Epoch: 30/30..  Running Loss: 2.533.. \n",
            "Epoch: 30/30..  Running Loss: 2.252.. \n",
            "Epoch: 30/30..  Running Loss: 2.438.. \n",
            "Epoch: 30/30..  Running Loss: 2.488.. \n",
            "Epoch: 30/30..  Running Loss: 2.115.. \n",
            "Epoch: 30/30..  Running Loss: 2.039.. \n",
            "Epoch: 30/30..  Running Loss: 2.491.. \n",
            "Epoch: 30/30..  Running Loss: 2.617.. \n",
            "Epoch: 30/30..  Running Loss: 3.118.. \n",
            "Epoch: 30/30..  Running Loss: 2.064.. \n",
            "Epoch: 30/30..  Running Loss: 2.328.. \n",
            "Epoch: 30/30..  Running Loss: 1.976.. \n",
            "Epoch: 30/30..  Running Loss: 2.185.. \n",
            "Epoch: 30/30..  Running Loss: 2.065.. \n",
            "Epoch: 30/30..  Running Loss: 2.436.. \n",
            "Epoch: 30/30..  Running Loss: 2.445.. \n",
            "Epoch: 30/30..  Running Loss: 2.420.. \n",
            "Epoch: 30/30..  Running Loss: 2.339.. \n",
            "Epoch: 30/30..  Running Loss: 2.650.. \n",
            "Epoch: 30/30..  Running Loss: 2.595.. \n",
            "Epoch: 30/30..  Running Loss: 2.216.. \n",
            "Epoch: 30/30..  Running Loss: 2.459.. \n",
            "Epoch: 30/30..  Running Loss: 2.311.. \n",
            "Epoch: 30/30..  Running Loss: 2.305.. \n",
            "Epoch: 30/30..  Running Loss: 2.174.. \n",
            "Epoch: 30/30..  Running Loss: 2.422.. \n",
            "Epoch: 30/30..  Running Loss: 2.113.. \n",
            "Epoch: 30/30..  Running Loss: 2.444.. \n",
            "Epoch: 30/30..  Running Loss: 1.607.. \n",
            "Epoch: 30/30..  Running Loss: 2.429.. \n",
            "Epoch: 30/30..  Running Loss: 2.696.. \n",
            "Epoch: 30/30..  Running Loss: 1.605.. \n",
            "Epoch: 30/30..  Running Loss: 2.093.. \n",
            "Epoch: 30/30..  Running Loss: 2.048.. \n",
            "Epoch: 30/30..  Running Loss: 2.617.. \n",
            "Epoch: 30/30..  Running Loss: 1.543.. \n",
            "Epoch: 30/30..  Running Loss: 2.153.. \n",
            "Epoch: 30/30..  Running Loss: 2.291.. \n",
            "Epoch: 30/30..  Running Loss: 1.884.. \n",
            "Epoch: 30/30..  Running Loss: 2.350.. \n",
            "Epoch: 30/30..  Running Loss: 2.230.. \n",
            "Epoch: 30/30..  Running Loss: 2.300.. \n",
            "Epoch: 30/30..  Running Loss: 2.540.. \n",
            "Epoch: 30/30..  Running Loss: 2.476.. \n",
            "Epoch: 30/30..  Running Loss: 2.083.. \n",
            "Epoch: 30/30..  Running Loss: 1.730.. \n",
            "Epoch: 30/30..  Running Loss: 2.271.. \n",
            "Epoch: 30/30..  Running Loss: 2.682.. \n",
            "Epoch: 30/30..  Running Loss: 2.485.. \n",
            "Epoch: 30/30..  Running Loss: 2.415.. \n",
            "Epoch: 30/30..  Running Loss: 2.471.. \n",
            "Epoch: 30/30..  Running Loss: 2.554.. \n",
            "Epoch: 30/30..  Running Loss: 2.498.. \n",
            "Epoch: 30/30..  Running Loss: 2.035.. \n",
            "Epoch: 30/30..  Running Loss: 2.098.. \n",
            "Epoch: 30/30..  Running Loss: 2.331.. \n",
            "Epoch: 30/30..  Running Loss: 2.361.. \n",
            "Epoch: 30/30..  Running Loss: 2.255.. \n",
            "Epoch: 30/30..  Running Loss: 2.414.. \n",
            "Epoch: 30/30..  Running Loss: 2.383.. \n",
            "Epoch: 30/30..  Running Loss: 2.798.. \n",
            "Epoch: 30/30..  Running Loss: 2.133.. \n",
            "Epoch: 30/30..  Running Loss: 2.650.. \n",
            "Epoch: 30/30..  Running Loss: 1.969.. \n",
            "Epoch: 30/30..  Running Loss: 2.223.. \n",
            "Epoch: 30/30..  Running Loss: 1.812.. \n",
            "Epoch: 30/30..  Running Loss: 2.367.. \n",
            "Epoch: 30/30..  Running Loss: 2.397.. \n",
            "Epoch: 30/30..  Running Loss: 2.628.. \n",
            "Epoch: 30/30..  Running Loss: 1.744.. \n",
            "Epoch: 30/30..  Running Loss: 1.971.. \n",
            "Epoch: 30/30..  Running Loss: 1.399.. \n",
            "Epoch: 30/30..  Running Loss: 2.058.. \n",
            "Epoch: 30/30..  Running Loss: 2.412.. \n",
            "Epoch: 30/30..  Running Loss: 2.236.. \n",
            "Epoch: 30/30..  Running Loss: 2.365.. \n",
            "Epoch: 30/30..  Running Loss: 1.798.. \n",
            "Epoch: 30/30..  Running Loss: 2.447.. \n",
            "Epoch: 30/30..  Running Loss: 2.816.. \n",
            "Epoch: 30/30..  Running Loss: 2.537.. \n",
            "Epoch: 30/30..  Running Loss: 2.434.. \n",
            "Epoch: 30/30..  Running Loss: 2.166.. \n",
            "Epoch: 30/30..  Running Loss: 2.213.. \n",
            "Epoch: 30/30..  Running Loss: 2.409.. \n",
            "Epoch: 30/30..  Running Loss: 2.104.. \n",
            "Epoch: 30/30..  Running Loss: 2.385.. \n",
            "Epoch: 30/30..  Running Loss: 1.967.. \n",
            "Epoch: 30/30..  Running Loss: 2.269.. \n",
            "Epoch: 30/30..  Running Loss: 2.660.. \n",
            "Epoch: 30/30..  Running Loss: 2.223.. \n",
            "Epoch: 30/30..  Running Loss: 2.196.. \n",
            "Epoch: 30/30..  Running Loss: 2.460.. \n",
            "Epoch: 30/30..  Running Loss: 2.250.. \n",
            "Epoch: 30/30..  Running Loss: 2.561.. \n",
            "Epoch: 30/30..  Running Loss: 2.203.. \n",
            "Epoch: 30/30..  Running Loss: 2.796.. \n",
            "Epoch: 30/30..  Running Loss: 2.399.. \n",
            "Epoch: 30/30..  Running Loss: 2.741.. \n",
            "Epoch: 30/30..  Running Loss: 2.674.. \n",
            "Epoch: 30/30..  Running Loss: 1.974.. \n",
            "Epoch: 30/30..  Running Loss: 2.099.. \n",
            "Epoch: 30/30..  Running Loss: 2.195.. \n",
            "Epoch: 30/30..  Running Loss: 1.012.. \n",
            "Epoch: 30/30..  Running Loss: 2.304.. \n",
            "Epoch: 30/30..  Running Loss: 2.410.. \n",
            "Epoch: 30/30..  Running Loss: 2.267.. \n",
            "Epoch: 30/30..  Running Loss: 2.601.. \n",
            "Epoch: 30/30..  Running Loss: 2.371.. \n",
            "Epoch: 30/30..  Running Loss: 2.137.. \n",
            "Epoch: 30/30..  Running Loss: 2.249.. \n",
            "Epoch: 30/30..  Running Loss: 1.890.. \n",
            "Epoch: 30/30..  Running Loss: 1.710.. \n",
            "Epoch: 30/30..  Running Loss: 2.682.. \n",
            "Epoch: 30/30..  Running Loss: 2.597.. \n",
            "Epoch: 30/30..  Running Loss: 2.329.. \n",
            "Epoch: 30/30..  Running Loss: 2.551.. \n",
            "Epoch: 30/30..  Running Loss: 1.444.. \n",
            "Epoch: 30/30..  Running Loss: 2.395.. \n",
            "Epoch: 30/30..  Running Loss: 2.070.. \n",
            "Epoch: 30/30..  Running Loss: 2.257.. \n",
            "Epoch: 30/30..  Running Loss: 2.444.. \n",
            "Epoch: 30/30..  Running Loss: 2.536.. \n",
            "Epoch: 30/30..  Running Loss: 2.507.. \n",
            "Epoch: 30/30..  Running Loss: 2.637.. \n",
            "Epoch: 30/30..  Running Loss: 2.363.. \n",
            "Epoch: 30/30..  Running Loss: 2.715.. \n",
            "Epoch: 30/30..  Running Loss: 2.410.. \n",
            "Epoch: 30/30..  Running Loss: 2.007.. \n",
            "Epoch: 30/30..  Running Loss: 2.101.. \n",
            "Epoch: 30/30..  Running Loss: 2.510.. \n",
            "Epoch: 30/30..  Running Loss: 2.452.. \n",
            "Epoch: 30/30..  Running Loss: 2.203.. \n",
            "Epoch: 30/30..  Running Loss: 2.289.. \n",
            "Epoch: 30/30..  Running Loss: 2.285.. \n",
            "Epoch: 30/30..  Running Loss: 2.657.. \n",
            "Epoch: 30/30..  Running Loss: 2.318.. \n",
            "Epoch: 30/30..  Running Loss: 2.792.. \n",
            "Epoch: 30/30..  Running Loss: 2.143.. \n",
            "Epoch: 30/30..  Running Loss: 1.782.. \n",
            "Epoch: 30/30..  Running Loss: 2.130.. \n",
            "Epoch: 30/30..  Running Loss: 2.467.. \n",
            "Epoch: 30/30..  Running Loss: 2.014.. \n",
            "Epoch: 30/30..  Running Loss: 2.490.. \n",
            "Epoch: 30/30..  Running Loss: 2.487.. \n",
            "Epoch: 30/30..  Running Loss: 2.417.. \n",
            "Epoch: 30/30..  Running Loss: 2.869.. \n",
            "Epoch: 30/30..  Running Loss: 2.481.. \n",
            "Epoch: 30/30..  Running Loss: 2.218.. \n",
            "Epoch: 30/30..  Running Loss: 2.490.. \n",
            "Epoch: 30/30..  Running Loss: 1.841.. \n",
            "Epoch: 30/30..  Running Loss: 2.690.. \n",
            "Epoch: 30/30..  Running Loss: 2.315.. \n",
            "Epoch: 30/30..  Running Loss: 2.526.. \n",
            "Epoch: 30/30..  Running Loss: 2.198.. \n",
            "Epoch: 30/30..  Running Loss: 2.224.. \n",
            "Epoch: 30/30..  Running Loss: 2.292.. \n",
            "Epoch: 30/30..  Running Loss: 2.330.. \n",
            "Epoch: 30/30..  Running Loss: 2.286.. \n",
            "Epoch: 30/30..  Running Loss: 2.243.. \n",
            "Epoch: 30/30..  Running Loss: 2.575.. \n",
            "Epoch: 30/30..  Running Loss: 2.295.. \n",
            "Epoch: 30/30..  Running Loss: 2.352.. \n",
            "Epoch: 30/30..  Running Loss: 2.352.. \n",
            "Epoch: 30/30..  Running Loss: 2.524.. \n",
            "Epoch: 30/30..  Running Loss: 2.479.. \n",
            "Epoch: 30/30..  Running Loss: 2.311.. \n",
            "Epoch: 30/30..  Running Loss: 2.375.. \n",
            "Epoch: 30/30..  Running Loss: 2.253.. \n",
            "Epoch: 30/30..  Running Loss: 2.512.. \n",
            "Epoch: 30/30..  Running Loss: 2.659.. \n",
            "Epoch: 30/30..  Running Loss: 2.301.. \n",
            "Epoch: 30/30..  Running Loss: 2.795.. \n",
            "Epoch: 30/30..  Running Loss: 2.399.. \n",
            "Epoch: 30/30..  Running Loss: 2.161.. \n",
            "Epoch: 30/30..  Running Loss: 2.439.. \n",
            "Epoch: 30/30..  Running Loss: 2.840.. \n",
            "Epoch: 30/30..  Running Loss: 2.338.. \n",
            "Epoch: 30/30..  Running Loss: 2.630.. \n",
            "Epoch: 30/30..  Running Loss: 2.284.. \n",
            "Epoch: 30/30..  Running Loss: 2.125.. \n",
            "Epoch: 30/30..  Running Loss: 2.011.. \n",
            "Epoch: 30/30..  Running Loss: 0.656.. \n",
            "Epoch: 30/30..  Running Loss: 1.726.. \n",
            "Epoch: 30/30..  Running Loss: 2.000.. \n",
            "Epoch: 30/30..  Running Loss: 1.016.. \n",
            "Epoch: 30/30..  Running Loss: 1.613.. \n",
            "Epoch: 30/30..  Running Loss: 2.000.. \n",
            "Epoch: 30/30..  Running Loss: 2.097.. \n",
            "Epoch: 30/30..  Running Loss: 1.035.. \n",
            "Epoch: 30/30..  Running Loss: 2.216.. \n",
            "Epoch: 30/30..  Running Loss: 1.993.. \n",
            "Epoch: 30/30..  Running Loss: 2.075.. \n",
            "Epoch: 30/30..  Running Loss: 1.766.. \n",
            "Epoch: 30/30..  Running Loss: 2.125.. \n",
            "Epoch: 30/30..  Running Loss: 2.066.. \n",
            "Epoch: 30/30..  Running Loss: 2.118.. \n",
            "Epoch: 30/30..  Running Loss: 2.474.. \n",
            "Epoch: 30/30..  Running Loss: 2.795.. \n",
            "Epoch: 30/30..  Running Loss: 2.655.. \n",
            "Epoch: 30/30..  Running Loss: 2.509.. \n",
            "Epoch: 30/30..  Running Loss: 2.698.. \n",
            "Epoch: 30/30..  Running Loss: 2.445.. \n",
            "Epoch: 30/30..  Running Loss: 2.536.. \n",
            "Epoch: 30/30..  Running Loss: 2.607.. \n",
            "Epoch: 30/30..  Running Loss: 2.622.. \n",
            "Epoch: 30/30..  Running Loss: 2.485.. \n",
            "Epoch: 30/30..  Running Loss: 2.386.. \n",
            "Epoch: 30/30..  Running Loss: 2.164.. \n",
            "Epoch: 30/30..  Running Loss: 1.747.. \n",
            "Epoch: 30/30..  Running Loss: 1.612.. \n",
            "Epoch: 30/30..  Running Loss: 0.799.. \n",
            "Epoch: 30/30..  Running Loss: 1.353.. \n",
            "Epoch: 30/30..  Running Loss: 0.919.. \n",
            "Epoch: 30/30..  Running Loss: 0.696.. \n",
            "Epoch: 30/30..  Running Loss: 1.258.. \n",
            "Epoch: 30/30..  Running Loss: 0.903.. \n",
            "Epoch: 30/30..  Running Loss: 0.652.. \n",
            "Epoch: 30/30..  Running Loss: 0.818.. \n",
            "Epoch: 30/30..  Running Loss: 0.814.. \n",
            "Epoch: 30/30..  Running Loss: 1.856.. \n",
            "Epoch: 30/30..  Running Loss: 2.553.. \n",
            "Epoch: 30/30..  Running Loss: 2.230.. \n",
            "Epoch: 30/30..  Running Loss: 2.060.. \n",
            "Epoch: 30/30..  Running Loss: 2.502.. \n",
            "Epoch: 30/30..  Running Loss: 2.843.. \n",
            "Epoch: 30/30..  Running Loss: 2.467.. \n",
            "Epoch: 30/30..  Running Loss: 2.393.. \n",
            "Epoch: 30/30..  Running Loss: 2.396.. \n",
            "Epoch: 30/30..  Running Loss: 2.104.. \n",
            "Epoch: 30/30..  Running Loss: 2.747.. \n",
            "Epoch: 30/30..  Running Loss: 2.476.. \n",
            "Epoch: 30/30..  Running Loss: 2.145.. \n",
            "Epoch: 30/30..  Running Loss: 2.342.. \n",
            "Epoch: 30/30..  Running Loss: 2.273.. \n",
            "Epoch: 30/30..  Running Loss: 2.326.. \n",
            "Epoch: 30/30..  Running Loss: 2.527.. \n",
            "Epoch: 30/30..  Running Loss: 2.595.. \n",
            "Epoch: 30/30..  Running Loss: 2.083.. \n",
            "Epoch: 30/30..  Running Loss: 2.165.. \n",
            "Epoch: 30/30..  Running Loss: 1.916.. \n",
            "Epoch: 30/30..  Running Loss: 2.616.. \n",
            "Epoch: 30/30..  Running Loss: 2.339.. \n",
            "Epoch: 30/30..  Running Loss: 2.387.. \n",
            "Epoch: 30/30..  Running Loss: 2.617.. \n",
            "Epoch: 30/30..  Running Loss: 2.788.. \n",
            "Epoch: 30/30..  Running Loss: 2.198.. \n",
            "Epoch: 30/30..  Running Loss: 2.196.. \n",
            "Epoch: 30/30..  Running Loss: 2.236.. \n",
            "Epoch: 30/30..  Running Loss: 2.514.. \n",
            "Epoch: 30/30..  Running Loss: 2.408.. \n",
            "Epoch: 30/30..  Running Loss: 2.304.. \n",
            "Epoch: 30/30..  Running Loss: 2.680.. \n",
            "Epoch: 30/30..  Running Loss: 2.278.. \n",
            "Epoch: 30/30..  Running Loss: 2.689.. \n",
            "Epoch: 30/30..  Running Loss: 2.326.. \n",
            "Epoch: 30/30..  Running Loss: 2.510.. \n",
            "Epoch: 30/30..  Running Loss: 2.730.. \n",
            "Epoch: 30/30..  Running Loss: 2.482.. \n",
            "Epoch: 30/30..  Running Loss: 2.567.. \n",
            "Epoch: 30/30..  Running Loss: 2.375.. \n",
            "Epoch: 30/30..  Running Loss: 2.360.. \n",
            "Epoch: 30/30..  Running Loss: 2.612.. \n",
            "Epoch: 30/30..  Running Loss: 2.498.. \n",
            "Epoch: 30/30..  Running Loss: 2.217.. \n",
            "Epoch: 30/30..  Running Loss: 1.806.. \n",
            "Epoch: 30/30..  Running Loss: 2.252.. \n",
            "Epoch: 30/30..  Running Loss: 2.453.. \n",
            "Epoch: 30/30..  Running Loss: 2.165.. \n",
            "Epoch: 30/30..  Running Loss: 2.423.. \n",
            "Epoch: 30/30..  Running Loss: 2.485.. \n",
            "Epoch: 30/30..  Running Loss: 2.155.. \n",
            "Epoch: 30/30..  Running Loss: 2.426.. \n",
            "Epoch: 30/30..  Running Loss: 2.586.. \n",
            "Epoch: 30/30..  Running Loss: 2.696.. \n",
            "Epoch: 30/30..  Running Loss: 2.121.. \n",
            "Epoch: 30/30..  Running Loss: 2.782.. \n",
            "Epoch: 30/30..  Running Loss: 2.473.. \n",
            "Epoch: 30/30..  Running Loss: 2.557.. \n",
            "Epoch: 30/30..  Running Loss: 2.303.. \n",
            "Epoch: 30/30..  Running Loss: 2.359.. \n",
            "Epoch: 30/30..  Running Loss: 2.105.. \n",
            "Epoch: 30/30..  Running Loss: 2.633.. \n",
            "Epoch: 30/30..  Running Loss: 2.309.. \n",
            "Epoch: 30/30..  Running Loss: 2.324.. \n",
            "Epoch: 30/30..  Running Loss: 2.391.. \n",
            "Epoch: 30/30..  Running Loss: 2.799.. \n",
            "Epoch: 30/30..  Running Loss: 2.156.. \n",
            "Epoch: 30/30..  Running Loss: 2.236.. \n",
            "Epoch: 30/30..  Running Loss: 2.105.. \n",
            "Epoch: 30/30..  Running Loss: 2.116.. \n",
            "Epoch: 30/30..  Running Loss: 2.427.. \n",
            "Epoch: 30/30..  Running Loss: 2.327.. \n",
            "Epoch: 30/30..  Running Loss: 2.566.. \n",
            "Epoch: 30/30..  Running Loss: 2.590.. \n",
            "Epoch: 30/30..  Running Loss: 2.388.. \n",
            "Epoch: 30/30..  Running Loss: 2.290.. \n",
            "Epoch: 30/30..  Running Loss: 2.495.. \n",
            "Epoch: 30/30..  Running Loss: 1.808.. \n",
            "Epoch: 30/30..  Running Loss: 2.453.. \n",
            "Epoch: 30/30..  Running Loss: 2.672.. \n",
            "Epoch: 30/30..  Running Loss: 2.437.. \n",
            "Epoch: 30/30..  Running Loss: 2.343.. \n",
            "Epoch: 30/30..  Running Loss: 2.345.. \n",
            "Epoch: 30/30..  Running Loss: 2.330.. \n",
            "Epoch: 30/30..  Running Loss: 2.189.. \n",
            "Epoch: 30/30..  Running Loss: 2.231.. \n",
            "Epoch: 30/30..  Running Loss: 2.067.. \n",
            "Epoch: 30/30..  Running Loss: 2.215.. \n",
            "Epoch: 30/30..  Running Loss: 2.507.. \n",
            "Epoch: 30/30..  Running Loss: 2.903.. \n",
            "Epoch: 30/30..  Running Loss: 2.495.. \n",
            "Epoch: 30/30..  Running Loss: 2.483.. \n",
            "Epoch: 30/30..  Running Loss: 2.510.. \n",
            "Epoch: 30/30..  Running Loss: 2.507.. \n",
            "Epoch: 30/30..  Running Loss: 2.216.. \n",
            "Epoch: 30/30..  Running Loss: 2.332.. \n",
            "Epoch: 30/30..  Running Loss: 2.180.. \n",
            "Epoch: 30/30..  Running Loss: 2.179.. \n",
            "Epoch: 30/30..  Running Loss: 2.305.. \n",
            "Epoch: 30/30..  Running Loss: 2.334.. \n",
            "Epoch: 30/30..  Running Loss: 2.376.. \n",
            "Epoch: 30/30..  Running Loss: 2.636.. \n",
            "Epoch: 30/30..  Running Loss: 2.274.. \n",
            "Epoch: 30/30..  Running Loss: 2.398.. \n",
            "Epoch: 30/30..  Running Loss: 2.310.. \n",
            "Epoch: 30/30..  Running Loss: 2.153.. \n",
            "Epoch: 30/30..  Running Loss: 2.274.. \n",
            "Epoch: 30/30..  Running Loss: 2.346.. \n",
            "Epoch: 30/30..  Running Loss: 1.941.. \n",
            "Epoch: 30/30..  Running Loss: 2.270.. \n",
            "Epoch: 30/30..  Running Loss: 2.541.. \n",
            "Epoch: 30/30..  Running Loss: 2.546.. \n",
            "Epoch: 30/30..  Running Loss: 2.690.. \n",
            "Epoch: 30/30..  Running Loss: 2.218.. \n",
            "Epoch: 30/30..  Running Loss: 2.419.. \n",
            "Epoch: 30/30..  Running Loss: 2.145.. \n",
            "Epoch: 30/30..  Running Loss: 2.367.. \n",
            "Epoch: 30/30..  Running Loss: 2.243.. \n",
            "Epoch: 30/30..  Running Loss: 2.327.. \n",
            "Epoch: 30/30..  Running Loss: 2.485.. \n",
            "Epoch: 30/30..  Running Loss: 2.486.. \n",
            "Epoch: 30/30..  Running Loss: 2.299.. \n",
            "Epoch: 30/30..  Running Loss: 2.373.. \n",
            "Epoch: 30/30..  Running Loss: 2.086.. \n",
            "Epoch: 30/30..  Running Loss: 2.288.. \n",
            "Epoch: 30/30..  Running Loss: 2.237.. \n",
            "Epoch: 30/30..  Running Loss: 2.068.. \n",
            "Epoch: 30/30..  Running Loss: 2.024.. \n",
            "Epoch: 30/30..  Running Loss: 2.450.. \n",
            "Epoch: 30/30..  Running Loss: 2.267.. \n",
            "Epoch: 30/30..  Running Loss: 2.360.. \n",
            "Epoch: 30/30..  Running Loss: 2.242.. \n",
            "Epoch: 30/30..  Running Loss: 2.404.. \n",
            "Epoch: 30/30..  Running Loss: 1.851.. \n",
            "Epoch: 30/30..  Running Loss: 2.559.. \n",
            "Epoch: 30/30..  Running Loss: 2.204.. \n",
            "Epoch: 30/30..  Running Loss: 2.648.. \n",
            "Epoch: 30/30..  Running Loss: 2.269.. \n",
            "Epoch: 30/30..  Running Loss: 2.673.. \n",
            "Epoch: 30/30..  Running Loss: 2.651.. \n",
            "Epoch: 30/30..  Running Loss: 2.636.. \n",
            "Epoch: 30/30..  Running Loss: 2.021.. \n",
            "Epoch: 30/30..  Running Loss: 2.152.. \n",
            "Epoch: 30/30..  Running Loss: 2.370.. \n",
            "Epoch: 30/30..  Running Loss: 2.642.. \n",
            "Epoch: 30/30..  Running Loss: 2.284.. \n",
            "Epoch: 30/30..  Running Loss: 2.215.. \n",
            "Epoch: 30/30..  Running Loss: 2.410.. \n",
            "Epoch: 30/30..  Running Loss: 2.161.. \n",
            "Epoch: 30/30..  Running Loss: 2.197.. \n",
            "Epoch: 30/30..  Running Loss: 2.301.. \n",
            "Epoch: 30/30..  Running Loss: 2.281.. \n",
            "Epoch: 30/30..  Running Loss: 2.363.. \n",
            "Epoch: 30/30..  Running Loss: 2.195.. \n",
            "Epoch: 30/30..  Running Loss: 2.424.. \n",
            "Epoch: 30/30..  Running Loss: 2.386.. \n",
            "Epoch: 30/30..  Running Loss: 2.263.. \n",
            "Epoch: 30/30..  Running Loss: 2.504.. \n",
            "Epoch: 30/30..  Running Loss: 1.882.. \n",
            "Epoch: 30/30..  Running Loss: 2.258.. \n",
            "Epoch: 30/30..  Running Loss: 2.859.. \n",
            "Epoch: 30/30..  Running Loss: 2.136.. \n",
            "Epoch: 30/30..  Running Loss: 2.625.. \n",
            "Epoch: 30/30..  Running Loss: 2.273.. \n",
            "Epoch: 30/30..  Running Loss: 2.374.. \n",
            "Epoch: 30/30..  Running Loss: 2.355.. \n",
            "Epoch: 30/30..  Running Loss: 2.009.. \n",
            "Epoch: 30/30..  Running Loss: 2.229.. \n",
            "Epoch: 30/30..  Running Loss: 2.882.. \n",
            "Epoch: 30/30..  Running Loss: 2.551.. \n",
            "Epoch: 30/30..  Running Loss: 2.553.. \n",
            "Epoch: 30/30..  Running Loss: 2.185.. \n",
            "Epoch: 30/30..  Running Loss: 2.552.. \n",
            "Epoch: 30/30..  Running Loss: 2.364.. \n",
            "Epoch: 30/30..  Running Loss: 2.616.. \n",
            "Epoch: 30/30..  Running Loss: 2.430.. \n",
            "Epoch: 30/30..  Running Loss: 2.443.. \n",
            "Epoch: 30/30..  Running Loss: 2.346.. \n",
            "Epoch: 30/30..  Running Loss: 2.913.. \n",
            "Epoch: 30/30..  Running Loss: 2.539.. \n",
            "Epoch: 30/30..  Running Loss: 2.535.. \n",
            "Epoch: 30/30..  Running Loss: 2.237.. \n",
            "Epoch: 30/30..  Running Loss: 2.411.. \n",
            "Epoch: 30/30..  Running Loss: 2.570.. \n",
            "Epoch: 30/30..  Running Loss: 2.644.. \n",
            "Epoch: 30/30..  Running Loss: 2.841.. \n",
            "Epoch: 30/30..  Running Loss: 2.206.. \n",
            "Epoch: 30/30..  Running Loss: 2.369.. \n",
            "Epoch: 30/30..  Running Loss: 2.495.. \n",
            "Epoch: 30/30..  Running Loss: 2.372.. \n",
            "Epoch: 30/30..  Running Loss: 2.271.. \n",
            "Epoch: 30/30..  Running Loss: 2.193.. \n",
            "Epoch: 30/30..  Running Loss: 2.560.. \n",
            "Epoch: 30/30..  Running Loss: 2.077.. \n",
            "Epoch: 30/30..  Running Loss: 2.123.. \n",
            "Epoch: 30/30..  Running Loss: 2.992.. \n",
            "Epoch: 30/30..  Running Loss: 2.380.. \n",
            "Epoch: 30/30..  Running Loss: 2.203.. \n",
            "Epoch: 30/30..  Running Loss: 2.672.. \n",
            "Epoch: 30/30..  Running Loss: 2.266.. \n",
            "Epoch: 30/30..  Running Loss: 2.352.. \n",
            "Epoch: 30/30..  Running Loss: 2.469.. \n",
            "Epoch: 30/30..  Running Loss: 2.326.. \n",
            "Epoch: 30/30..  Running Loss: 2.468.. \n",
            "Epoch: 30/30..  Running Loss: 2.247.. \n",
            "Epoch: 30/30..  Running Loss: 2.342.. \n",
            "Epoch: 30/30..  Running Loss: 2.378.. \n",
            "Epoch: 30/30..  Running Loss: 2.092.. \n",
            "Epoch: 30/30..  Running Loss: 2.375.. \n",
            "Epoch: 30/30..  Running Loss: 2.257.. \n",
            "Epoch: 30/30..  Running Loss: 2.255.. \n",
            "Epoch: 30/30..  Running Loss: 2.279.. \n",
            "Epoch: 30/30..  Running Loss: 2.172.. \n",
            "Epoch: 30/30..  Running Loss: 2.176.. \n",
            "Epoch: 30/30..  Running Loss: 2.119.. \n",
            "Epoch: 30/30..  Running Loss: 2.310.. \n",
            "Epoch: 30/30..  Running Loss: 2.122.. \n",
            "Epoch: 30/30..  Running Loss: 2.119.. \n",
            "Epoch: 30/30..  Running Loss: 2.189.. \n",
            "Epoch: 30/30..  Running Loss: 2.377.. \n",
            "Epoch: 30/30..  Running Loss: 2.506.. \n",
            "Epoch: 30/30..  Running Loss: 1.939.. \n",
            "Epoch: 30/30..  Running Loss: 2.518.. \n",
            "Epoch: 30/30..  Running Loss: 2.276.. \n",
            "Epoch: 30/30..  Running Loss: 2.399.. \n",
            "Epoch: 30/30..  Running Loss: 2.305.. \n",
            "Epoch: 30/30..  Running Loss: 2.156.. \n",
            "Epoch: 30/30..  Running Loss: 2.199.. \n",
            "Epoch: 30/30..  Running Loss: 2.067.. \n",
            "Epoch: 30/30..  Running Loss: 2.467.. \n",
            "Epoch: 30/30..  Running Loss: 2.187.. \n",
            "Epoch: 30/30..  Running Loss: 2.630.. \n",
            "Epoch: 30/30..  Running Loss: 2.325.. \n",
            "Epoch: 30/30..  Running Loss: 2.262.. \n",
            "Epoch: 30/30..  Running Loss: 2.467.. \n",
            "Epoch: 30/30..  Running Loss: 2.230.. \n",
            "Epoch: 30/30..  Running Loss: 2.489.. \n",
            "Epoch: 30/30..  Running Loss: 2.422.. \n",
            "Epoch: 30/30..  Running Loss: 2.568.. \n",
            "Epoch: 30/30..  Running Loss: 2.578.. \n",
            "Epoch: 30/30..  Running Loss: 2.595.. \n",
            "Epoch: 30/30..  Running Loss: 2.255.. \n",
            "Epoch: 30/30..  Running Loss: 2.394.. \n",
            "Epoch: 30/30..  Running Loss: 2.368.. \n",
            "Epoch: 30/30..  Running Loss: 2.262.. \n",
            "Epoch: 30/30..  Running Loss: 2.486.. \n",
            "Epoch: 30/30..  Running Loss: 2.349.. \n",
            "Epoch: 30/30..  Running Loss: 1.927.. \n",
            "Epoch: 30/30..  Running Loss: 2.349.. \n",
            "Epoch: 30/30..  Running Loss: 2.438.. \n",
            "Epoch: 30/30..  Running Loss: 1.964.. \n",
            "Epoch: 30/30..  Running Loss: 2.459.. \n",
            "Epoch: 30/30..  Running Loss: 2.390.. \n",
            "Epoch: 30/30..  Running Loss: 2.386.. \n",
            "Epoch: 30/30..  Running Loss: 2.051.. \n",
            "Epoch: 30/30..  Running Loss: 2.090.. \n",
            "Epoch: 30/30..  Running Loss: 2.308.. \n",
            "Epoch: 30/30..  Running Loss: 2.427.. \n",
            "Epoch: 30/30..  Running Loss: 2.574.. \n",
            "Epoch: 30/30..  Running Loss: 2.310.. \n",
            "Epoch: 30/30..  Running Loss: 2.196.. \n",
            "Epoch: 30/30..  Running Loss: 2.789.. \n",
            "Epoch: 30/30..  Running Loss: 2.414.. \n",
            "Epoch: 30/30..  Running Loss: 2.522.. \n",
            "Epoch: 30/30..  Running Loss: 2.350.. \n",
            "Epoch: 30/30..  Running Loss: 2.325.. \n",
            "Epoch: 30/30..  Running Loss: 2.344.. \n",
            "Epoch: 30/30..  Running Loss: 2.415.. \n",
            "Epoch: 30/30..  Running Loss: 2.209.. \n",
            "Epoch: 30/30..  Running Loss: 2.226.. \n",
            "Epoch: 30/30..  Running Loss: 2.111.. \n",
            "Epoch: 30/30..  Running Loss: 2.259.. \n",
            "Epoch: 30/30..  Running Loss: 2.312.. \n",
            "Epoch: 30/30..  Running Loss: 2.072.. \n",
            "Epoch: 30/30..  Running Loss: 2.071.. \n",
            "Epoch: 30/30..  Running Loss: 2.315.. \n",
            "Epoch: 30/30..  Running Loss: 2.352.. \n",
            "Epoch: 30/30..  Running Loss: 2.662.. \n",
            "Epoch: 30/30..  Running Loss: 2.010.. \n",
            "Epoch: 30/30..  Running Loss: 2.952.. \n",
            "Epoch: 30/30..  Running Loss: 2.162.. \n",
            "Epoch: 30/30..  Running Loss: 2.454.. \n",
            "Epoch: 30/30..  Running Loss: 2.358.. \n",
            "Epoch: 30/30..  Running Loss: 2.308.. \n",
            "Epoch: 30/30..  Running Loss: 1.376.. \n",
            "Epoch: 30/30..  Running Loss: 2.545.. \n",
            "Epoch: 30/30..  Running Loss: 2.454.. \n",
            "Epoch: 30/30..  Running Loss: 2.365.. \n",
            "Epoch: 30/30..  Running Loss: 2.794.. \n",
            "Epoch: 30/30..  Running Loss: 2.151.. \n",
            "Epoch: 30/30..  Running Loss: 2.408.. \n",
            "Epoch: 30/30..  Running Loss: 2.604.. \n",
            "Epoch: 30/30..  Running Loss: 2.325.. \n",
            "Epoch: 30/30..  Running Loss: 2.426.. \n",
            "Epoch: 30/30..  Running Loss: 2.102.. \n",
            "Epoch: 30/30..  Running Loss: 2.776.. \n",
            "Epoch: 30/30..  Running Loss: 2.368.. \n",
            "Epoch: 30/30..  Running Loss: 2.595.. \n",
            "Epoch: 30/30..  Running Loss: 2.582.. \n",
            "Epoch: 30/30..  Running Loss: 2.233.. \n",
            "Epoch: 30/30..  Running Loss: 2.026.. \n",
            "Epoch: 30/30..  Running Loss: 2.201.. \n",
            "Epoch: 30/30..  Running Loss: 2.705.. \n",
            "Epoch: 30/30..  Running Loss: 2.418.. \n",
            "Epoch: 30/30..  Running Loss: 2.470.. \n",
            "Epoch: 30/30..  Running Loss: 2.050.. \n",
            "Epoch: 30/30..  Running Loss: 2.621.. \n",
            "Epoch: 30/30..  Running Loss: 2.367.. \n",
            "Epoch: 30/30..  Running Loss: 2.256.. \n",
            "Epoch: 30/30..  Running Loss: 2.759.. \n",
            "Epoch: 30/30..  Running Loss: 2.032.. \n",
            "Epoch: 30/30..  Running Loss: 2.371.. \n",
            "Epoch: 30/30..  Running Loss: 2.094.. \n",
            "Epoch: 30/30..  Running Loss: 2.505.. \n",
            "Epoch: 30/30..  Running Loss: 2.342.. \n",
            "Epoch: 30/30..  Running Loss: 2.174.. \n",
            "Epoch: 30/30..  Running Loss: 2.011.. \n",
            "Epoch: 30/30..  Running Loss: 2.333.. \n",
            "Epoch: 30/30..  Running Loss: 2.352.. \n",
            "Epoch: 30/30..  Running Loss: 2.535.. \n",
            "Epoch: 30/30..  Running Loss: 2.303.. \n",
            "Epoch: 30/30..  Running Loss: 2.126.. \n",
            "Epoch: 30/30..  Running Loss: 2.622.. \n",
            "Epoch: 30/30..  Running Loss: 2.214.. \n",
            "Epoch: 30/30..  Running Loss: 2.318.. \n",
            "Epoch: 30/30..  Running Loss: 2.302.. \n",
            "Epoch: 30/30..  Running Loss: 2.220.. \n",
            "Epoch: 30/30..  Running Loss: 2.430.. \n",
            "Epoch: 30/30..  Running Loss: 2.173.. \n",
            "Epoch: 30/30..  Running Loss: 2.249.. \n",
            "Epoch: 30/30..  Running Loss: 2.546.. \n",
            "Epoch: 30/30..  Running Loss: 2.231.. \n",
            "Epoch: 30/30..  Running Loss: 2.621.. \n",
            "Epoch: 30/30..  Running Loss: 2.244.. \n",
            "Epoch: 30/30..  Running Loss: 2.543.. \n",
            "Epoch: 30/30..  Running Loss: 2.362.. \n",
            "Epoch: 30/30..  Running Loss: 2.417.. \n",
            "Epoch: 30/30..  Running Loss: 2.431.. \n",
            "Epoch: 30/30..  Running Loss: 2.220.. \n",
            "Epoch: 30/30..  Running Loss: 2.443.. \n",
            "Epoch: 30/30..  Running Loss: 2.068.. \n",
            "Epoch: 30/30..  Running Loss: 2.709.. \n",
            "Epoch: 30/30..  Running Loss: 2.328.. \n",
            "Epoch: 30/30..  Running Loss: 2.002.. \n",
            "Epoch: 30/30..  Running Loss: 1.910.. \n",
            "Epoch: 30/30..  Running Loss: 2.325.. \n",
            "Epoch: 30/30..  Running Loss: 2.412.. \n",
            "Epoch: 30/30..  Running Loss: 2.320.. \n",
            "Epoch: 30/30..  Running Loss: 2.321.. \n",
            "Epoch: 30/30..  Running Loss: 2.079.. \n",
            "Epoch: 30/30..  Running Loss: 2.617.. \n",
            "Epoch: 30/30..  Running Loss: 2.539.. \n",
            "Epoch: 30/30..  Running Loss: 2.446.. \n",
            "Epoch: 30/30..  Running Loss: 2.258.. \n",
            "Epoch: 30/30..  Running Loss: 2.326.. \n",
            "Epoch: 30/30..  Running Loss: 2.380.. \n",
            "Epoch: 30/30..  Running Loss: 2.070.. \n",
            "Epoch: 30/30..  Running Loss: 2.444.. \n",
            "Epoch: 30/30..  Running Loss: 2.293.. \n",
            "Epoch: 30/30..  Running Loss: 2.227.. \n",
            "Epoch: 30/30..  Running Loss: 2.370.. \n",
            "Epoch: 30/30..  Running Loss: 2.315.. \n",
            "Epoch: 30/30..  Running Loss: 2.300.. \n",
            "Epoch: 30/30..  Running Loss: 2.429.. \n",
            "Epoch: 30/30..  Running Loss: 2.314.. \n",
            "Epoch: 30/30..  Running Loss: 2.059.. \n",
            "Epoch: 30/30..  Running Loss: 2.192.. \n",
            "Epoch: 30/30..  Running Loss: 2.363.. \n",
            "Epoch: 30/30..  Running Loss: 2.400.. \n",
            "Epoch: 30/30..  Running Loss: 2.365.. \n",
            "Epoch: 30/30..  Running Loss: 2.220.. \n",
            "Epoch: 30/30..  Running Loss: 2.388.. \n",
            "Epoch: 30/30..  Running Loss: 2.323.. \n",
            "Epoch: 30/30..  Running Loss: 2.417.. \n",
            "Epoch: 30/30..  Running Loss: 2.670.. \n",
            "-----------------------------------------------------\n",
            " TRAINING END \n",
            "-----------------------------------------------------\n",
            "Training Took 155 Minutes\n",
            "Highest Loss Value: 8.976813983917236 / Lowest Loss Value: 0.6524521310441196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwNuUJFuoO7k"
      },
      "source": [
        "# **Save Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUy3YfBxoRZW"
      },
      "source": [
        "checkpoint_url = '/content/drive/My Drive/StoryTellerAI/checkpoint2.pth'\n",
        "\n",
        "checkpoint = {'model': model,\n",
        "              'state_dict': model.state_dict(),\n",
        "              'word_to_idx': word_to_idx,\n",
        "              'idx_to_word': idx_to_word,\n",
        "              'epochs': epochs,\n",
        "              'average_loss': average_loss,\n",
        "              'device': device,\n",
        "              'optimizer_state': optimizer.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, checkpoint_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DyoYf0qT__G"
      },
      "source": [
        "# **Load Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UarVOe0WTYEq",
        "outputId": "5a29f816-0ff1-49a9-b71d-a35096d6c62b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "checkpoint_url = '/content/drive/My Drive/StoryTellerAI/checkpoint2.pth'\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.optimizer_state = checkpoint['optimizer_state']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model.device = checkpoint['device']\n",
        "    model.word_to_index = checkpoint['word_to_idx']\n",
        "    model.index_to_word = checkpoint['idx_to_word']\n",
        "    model.average_loss = checkpoint['average_loss']\n",
        "    return model\n",
        "\n",
        "model = load_checkpoint(checkpoint_url)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StoryTeller(\n",
              "  (embeddings): Embedding(7923, 15)\n",
              "  (linear1): Linear(in_features=75, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=768, bias=True)\n",
              "  (linear3): Linear(in_features=768, out_features=7923, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXnfIAhyNNn1",
        "outputId": "ca622842-2651-4f33-9cd3-552a9daad8b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "loss_plot = pd.DataFrame(model.average_loss)\n",
        "loss_plot.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb21888a7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgJKcqqCUp6I"
      },
      "source": [
        "# **Predict Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ess7PHw-UswI"
      },
      "source": [
        "def predict(model, first_words ,story_len ,top_k):\n",
        "    '''\n",
        "    param model: trained model\n",
        "    param first_words: a string of 5 (n_feature) words to begin the story\n",
        "    param story_len: an integer symbolizing the number of words you'd like the story to have\n",
        "    param top_k: the number of top probabilities per word that the network will randomly select from\n",
        "    '''\n",
        "    feature = (first_words.lower()).split(\" \")\n",
        "    for i in feature:\n",
        "        story.append(i)\n",
        "    for i in range(story_len):\n",
        "        feature_idx = torch.tensor([word_to_idx[word] for word in feature], dtype=torch.long)\n",
        "        feature_idx = feature_idx.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model.double().forward(feature_idx)\n",
        "        ps = torch.exp(output)\n",
        "        topk_combined = ps.topk(top_k, sorted=True)\n",
        "        #top kk probabilities\n",
        "        topk_ps = topk_combined[0][0]\n",
        "        #top kk classes\n",
        "        topk_class = topk_combined[1][0]\n",
        "        topk_class = [idx_to_word[int(i)] for i in topk_class]\n",
        "        next_word = random.choice(topk_class)\n",
        "        feature = feature[1:]\n",
        "        feature.append(next_word)\n",
        "        story.append(next_word)\n",
        "    return story"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg6KWKpeU0GB"
      },
      "source": [
        "# **Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLdMEMOqU2rn",
        "outputId": "a916fb0e-673c-45ad-f4bb-ed61045b2a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "word_to_idx = model.word_to_index\n",
        "idx_to_word = model.index_to_word\n",
        "first_words = input('Type the first {} words to start the story:\\nexample: A lovely day at the\\n'.format(batch_size))\n",
        "\n",
        "top_k = 3\n",
        "story_len = 50\n",
        "story = []\n",
        "device = 'cuda:0'\n",
        "\n",
        "#Predicting and Handling User-Input Errors\n",
        "try:      \n",
        "    prediction = predict(model, first_words, story_len, top_k)\n",
        "except KeyError as error:\n",
        "    print('Oops, looks like you\\'ve selected a word that the network does not understand yet: ', error)\n",
        "    if story[0] != \"\":\n",
        "        story = story[len(first_words):]\n",
        "    first_words = input('please select a different word:\\nexample: A lovely day at the\\n')\n",
        "    prediction = predict(model, first_words, story_len, top_k)\n",
        "except KeyError and RuntimeError:\n",
        "    if story[0] != \"\":\n",
        "        story = story[len(first_words):]\n",
        "    first_words = input('Oops, looks like you\\'ve typed {} words instead of {}!\\n\\nType the first 5 words to start the story:\\nexample: A lovely day at the\\n'.format(len(first_words.split(\" \")), n_features))\n",
        "    prediction = predict(model, first_words, story_len, top_k)\n",
        "\n",
        "print('-----------------------------------------------------\\n The STORY \\n-----------------------------------------------------')\n",
        "print(\" \".join(story))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type the first 5 words to start the story:\n",
            "example: A lovely day at the\n",
            "there was a lovely princess\n",
            "-----------------------------------------------------\n",
            " The STORY \n",
            "-----------------------------------------------------\n",
            "there was a lovely princess for her mother coming to their children and they found was at an end his turn beautiful that he was now and when they had sung my of his money court like of that the bear was gone from and gathered in the cinders so come with me and had\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIKJrOv8dkRn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}